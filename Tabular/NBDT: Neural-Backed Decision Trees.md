# NBDT: Neural-Backed Decision Trees

**핵심 주장 및 주요 기여**  
Neural-Backed Decision Trees(NBDT)는 딥러닝 모델의 마지막 선형 계층을 *분화 가능한 결정 트리*로 대체함으로써 **정확도와 해석 가능성**을 동시에 향상시킨다.  
1. **정확도 보존·개선**: CIFAR10/100, TinyImageNet, ImageNet에서 기존 신경망과 동등하거나 최대 1% 이상 성능 향상.[1]
2. **일반화 능력 강화**: 미지의 클래스에 대해 최대 16% 높은 제로샷 초개념(zero-shot superclass) 분류 정확도 달성.[1]
3. **해석 가능성 제공**: 각 중간 결정 노드를 고수준 개념으로 매핑(예: Animal vs. Vehicle)하여 사람의 신뢰도 향상 및 데이터셋 디버깅 지원.[1]

***

## 1. 해결하고자 하는 문제  
딥러닝은 의료·재무 등 고위험 분야에서 ‘블랙박스’로 인식되어 채택이 어려웠다.  
- 기존 융합 모델은  
  - **높은 정확도**지만 **해석 불가능** (impure leaves, 앙상블)[1]
  - **높은 해석 가능성**지만 **정확도 저하** (단순 결정 트리)  
이 두 가지 목표를 동시에 달성하지 못했다.

***

## 2. 제안 방법

### 2.1. 모형 구조  
- **백본**: ResNet, WideResNet, EfficientNet 등 기존 분류 신경망  
- **결정 트리 계층**: 마지막 완전연결층을 *binary oblique decision tree*로 교체  
  1. **잎 노드(leaf)**: 기존 weight 행렬 $$W\in\mathbb{R}^{D\times K}$$의 각 행 $$w_k$$ 사용  
  2. **내부 노드**: 잎 노드들의 weight 벡터 평균  
  3. **추론(inference)**: 각 노드에서 자식 확률을 소프트맥스 내적으로 계산 후, **경로 확률(path probability)**

$$  
     p(k) = \prod_{i\in P_k} p\bigl(C_k(i)\mid i\bigr)  
     $$ 
     
  로 잎 선택[1]

### 2.2. 유도된 계층(induced hierarchy)  
- **가중치 기반 계층 구성**: 사전학습된 완전연결층의 행 벡터 $$w_k$$들을 L2 정규화 후 계층적 군집화로 묶음  
- 시맨틱 계층(WordNet)·데이터 기반(정보 이득)보다 **시각적 유사성에 부합**하며 과적합 감소[1]

### 2.3. 트리 감독 손실(tree supervision loss)  
- 표준 교차 엔트로피 손실 외에 **경로 확률 분포** $$D_{\text{nbdt}}=\{p(k)\}$$에 대한 보조 손실 추가:  

$$  
  \mathcal{L} = \beta_t\,\mathrm{CE}(D_{\text{pred}},D_{\text{label}}) + \omega_t\,\mathrm{CE}(D_{\text{nbdt}},D_{\text{label}})  
  $$  

- $$\omega_t$$는 학습 초기에 0에서 최댓값(0.5∼5)으로 선형 증가, $$\beta_t$$는 선형 감소  
- 계층별 개념 구분력을 향상시켜 **고수준 결정**(예: Animal vs. Vehicle)에 집중 유도[1]

***

## 3. 성능 향상 및 한계

### 3.1. 성능  
- **CIFAR100**: +1% 절대 향상  
- **TinyImageNet**: +0.15% 동등 성능  
- **ImageNet**: 기존 결합 모델 대비 +15%[1]
- **제로샷 초개념 일반화**: Animal vs. Vehicle 노드에서 +8~16%[1]

### 3.2. 해석 가능성  
- **실험**:  
  - 오분류 식별 정확도(NBDT 설명 39.5% → 19.5%↑)  
  - 흐릿 이미지 분류 시 신뢰도(모델 시각화) 선택 비율 NBDT 52% vs. Saliency 28%[1]
- **제한**:  
  - 최종 잎 엉뚱한 결정은 중간 경로만으로 식별 불가(전체 오분류 중 37%)[1]
  - WordNet 라벨링 한계: 시각 속성·추상 개념 미반영

***

## 4. 일반화 성능 향상 가능성  
- **경로 확률 손실**은 트리 상단(고수준) 결정에 가중을 둠으로써 **고수준 개념 학습** 강화  
- **가중치 기반 계층**은 과적합 방지 및 시각적 유사성 포착으로 **미지 클래스 적응력** 상승[1]
- **모델 규모·정확도**가 높아질수록 계층의 시맨틱 일관성↑ → 더 나은 일반화

***

## 5. 향후 연구 영향 및 고려점  
- **통합 해석 모델**: NBDT는 해석 가능성과 정확성 양립 가능성을 제시하므로, 해석형 AI 연구의 기준이 될 수 있음  
- **계층 구성 확장**: 단순 군집화 대신 **컨셉 기반 라벨링**·**언어 모델** 활용 연구  
- **응용 분야 확대**: 의료·금융·자동차 등 **고위험 영역의 실시간 해석**에 적용  
- **한계 보완**:  
  - 더 복잡한 의사결정(다진화된 노드) 지원  
  - WordNet 외 **비객체적 개념** 라벨링 기법 강화  

---  

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/53276444-248e-4c74-a6c8-c72c672b972c/2004.00221v3.pdf)

