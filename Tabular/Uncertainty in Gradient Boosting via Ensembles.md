# Uncertainty in Gradient Boosting via Ensembles

# 핵심 주장 및 주요 기여 요약

**Uncertainty in Gradient Boosting via Ensembles** 논문은 탁월한 성능을 보이는 그라디언트 부스팅 결정 트리(GBDT) 모델에도 불확실성 추정이 필요함을 제시하며, 앙상블 기반 확률론적 프레임워크를 통해 GBDT 분류·회귀 모델의 예측 불확실성을 정량화하는 방법을 제안한다. 주요 기여는 다음과 같다.[1]

- **SGB 및 SGLB 앙상블**: 고전적 확률적 부스팅(Stochastic Gradient Boosting, SGB)과 스토캐스틱 그라디언트 랑주뱅 부스팅(Stochastic Gradient Langevin Boosting, SGLB)을 이용해 GBDT 모델 앙상블을 생성하고, SGLB가 진정한 베이지안 사후분포에서 표본을 추출함을 보인다.[1]
- **가상 앙상블(Virtual Ensemble)**: 단일 SGLB 모델에서 매 K 번째 반복 파라미터를 취해 앙상블을 시뮬레이션함으로써 계산·메모리 복잡도를 크게 줄이는 가상 앙상블 기법을 제안한다.[1]
- **합성 및 실제 데이터 분석**: 심장형·나선형 합성 데이터에서 총불확실성 및 지식불확실성(학습 데이터 외 영역 검출) 특성을 분석하고, 광범위한 분류·회귀 데이터셋에서 오류 검출 및 도메인 외 입력 감지 성능을 평가한다.[1]

# 문제 정의 및 제안 방법

## 해결하고자 하는 문제  
GBDT 분류 모델은 클래스 확률 분포를 제공하지만, 회귀 모델은 평균 예측만 제공하여 데이터 불확실성(aleatoric uncertainty)만을 반영한다. 모델이 훈련 데이터 영역 밖 입력에 대해 얼마나 “모른다”는 지식 불확실성(epistemic uncertainty)은 반영되지 않는다.[1]

## 제안 방법  
1. **베이지안 앙상블 프레임워크**  
   모델 파라미터 θ에 사전분포 $$p(\theta)$$를 두고 사후분포 $$p(\theta|D)$$를 유도한다[1].  
   예측 분포는  

$$
   P(y|x,D) \approx \frac{1}{M}\sum_{m=1}^M P(y|x;\theta^{(m)}),\quad \theta^{(m)}\sim p(\theta|D).
   $$  
   
   총불확실성은 예측 분포 엔트로피  

$$
   H\bigl[P(y|x,D)\bigr] = -\sum_y P(y|x,D)\ln P(y|x,D),
   $$  
   
   지식불확실성은 상호정보  

$$
   I(y,\theta|x,D) = H\bigl[P(y|x,D)\bigr] - \mathbb{E}_{p(\theta|D)}\bigl[H\bigl[P(y|x;\theta)\bigr]\bigr].
   $$  

2. **SGB 앙상블**  
   매 반복마다 데이터 서브샘플링을 통해 θ를 불확정하게 추정하여 여러 GBDT 모델을 독립 생성한다.[1]
3. **SGLB 앙상불**  
   그래디언트에 가우시안 노이즈 ν를 추가하고  

$$
   F^{(t)}(x) = (1-\gamma\epsilon)F^{(t-1)}(x) + \epsilon\,h^{(t)}(x),
   $$  
   
   α = |D|, γ = 1/(2|D|)로 설정 시 사후분포에서 표본 추출이 보장됨을 증명한다[1].

4. **가상 앙상블(vSGLB)**  
   하나의 SGLB 트레이닝 과정을 통해 생성된 θ(t)를 매 K번째마다 보존하여 앙상블을 구성함으로써 복잡도를 M배가 아닌 단일 모델 수준으로 유지한다.[1]

## 모델 구조  
- 기본 모델: CatBoost 기반 GBDT  
- 회귀 모델은 평균 µ, 로그 표준편차 $$\log\sigma$$를 동시에 예측하여 정규분포 매개변수화  
- 분류 모델은 로지스틱 손실로 클래스 확률 분포 출력  

# 성능 향상 및 한계

## 성능 향상  
- **이상 입력 검출**: SGLB 앙상블 및 vSGLB 모두 지식불확실성으로 훈련 데이터 범위 밖 인스턴스를 효과적으로 구별(www AUC-ROC 최대 100%).[1]
- **오류 검출**: 총불확실성 기준 예측-제거 비율(PRR)에서 앙상블이 단일 모델 대비 유사하거나 약간 우수한 성과를 보임.[1]

## 한계  
- **지식불확실성 기여 미미**: 총불확실성에서 지식불확실성이 차지하는 비중이 작아, 회귀·분류 모두 추가적 오류 검출 효과가 제한적임.[1]
- **가상 앙상블 성능 저하**: vSGLB는 모델 간 높은 상관으로 인해 SGLB 앙상블 대비 지식불확실성 추정 품질이 떨어짐.[1]
- **연속형 특성 경계 효과**: 실수형 특성일수록 결정경계 ‘진동’으로 지식불확실성 추정이 불안정해질 수 있음.[1]

# 일반화 성능 향상 가능성

앙상블 기법은 모델 불확실성을 해석 가능하게 분해하고, 특히 훈련 분포 외 영역 검출에 유리하여 **모델의 신뢰도**를 높인다. 이는 배경 분포가 변화하거나 드문 샘플을 만날 때 **일반화 실패**를 조기에 경고할 수 있음을 의미한다. 특히 의료·자율주행 분야처럼 고위험 응용에서 모델이 모르는 영역을 구분하는 능력은 시스템 전반의 **안전성**과 **일반화 강건성**을 크게 향상시킬 수 있다.

# 향후 연구 영향 및 고려점

향후 연구에서는 다음 사항을 고려해야 한다.

- **고차원 연속 데이터**: 결정경계 진동 문제를 완화하기 위한 고차 모멘트 기반 지표나 스케일 불변적 불확실성 추정 기법 개발  
- **효율적 베이지안 부스팅**: SGLB 가상 앙상블의 상관 문제를 해결하기 위한 샘플링 간격 최적화 및 노이즈 스케줄링 연구  
- **하이브리드 모델**: GBDT와 딥러닝 앙상블 결합을 통한 구조적·분포적 일반화 성능 증대  
- **실제 OOD 시나리오 평가**: 합성 데이터가 아닌 실제 분포 이동 및 이상값 발생 환경에서의 검증  
- **리소스-성능 균형**: 대규모 산업 응용에서 계산·메모리 비용과 불확실성 추정 품질 간 트레이드오프 최적화  

위 방향성은 GBDT 기반 시스템의 신뢰성과 **실제 일반화 성능**을 더욱 강화하는 데 기여할 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/55ce9e84-4206-4375-b92f-762ae3050089/2006.10562v4.pdf)
