# TabTransformer: Tabular Data Modeling Using Contextual Embeddings

# 핵심 요약  
**TabTransformer**는 컨텍스트 임베딩(Contextual Embeddings)을 이용해 범주형 변수를 효과적으로 모델링함으로써, 기존 범주형 처리 방식(예: 원-핫 인코딩+피드포워드 네트워크)의 한계를 극복하고 성능을 크게 향상시키는 것을 목표로 한다.  

# 1. 해결하고자 하는 문제  
범주형 변수를 처리하는 전통적인 방법은 원-핫 인코딩 후 피드포워드 신경망에 입력하는 것이다. 그러나 이 방식은  
- 고차원 희소 표현(sparse representation)으로 인한 파라미터 폭발  
- 범주 간 관계 미반영  
- 일반화 성능 저하  
와 같은 문제를 일으킨다.  

# 2. 제안하는 방법  
TabTransformer는 범주형 피처별로 개별 임베딩 레이어를 적용한 뒤, **다층 Self-Attention**을 통해 피처 간 상호작용을 학습하여 컨텍스트 임베딩을 얻는다.  
  
- 입력 범주형 피처 $$x_i$$에 대해 임베딩 벡터 $$\mathbf{e}_i \in \mathbb{R}^d$$를 생성  
- Transformer 인코더 블록을 $$L$$개 쌓아, 각 피처 임베딩 쌍 간의 어텐션 스코어를 계산  

$$ 
\text{Attention}(Q,K,V) = \mathrm{softmax}\Bigl(\frac{QK^\top}{\sqrt{d}}\Bigr)V 
$$  

여기서 $$Q,K,V \in \mathbb{R}^{n\times d}$$는 각각 Query, Key, Value 행렬이다.  
- 최종 어텐션 출력을 **컨텍스트 임베딩** $$\mathbf{c}_i$$로 활용  
- 이 컨텍스트 임베딩들을 연결(concatenate)한 후, 연속형 피처와 함께 피드포워드 네트워크에 입력  

이로써 모델은 범주형 피처들 간의 내재적 관계를 학습하여 더 풍부한 표현을 얻는다.  

# 3. 모델 구조  
TabTransformer의 아키텍처는 다음과 같다:  
1. 임베딩 레이어: 각 범주형 피처별로 크기 $$d$$의 임베딩 벡터 생성  
2. Transformer 인코더 블록 (Layer Normalization, Multi-Head Self-Attention, Feed-Forward) $$L$$스택  
3. 컨텍스트 임베딩 연결  
4. 연속형 피처와 병합  
5. 최종 예측을 위한 MLP 헤드  

# 4. 성능 향상 및 한계  
### 성능  
- 여러 공개 탭ular 데이터셋(Census, Flight, Favorita 등)에서 기존 방법 대비 **AUC**, **RMSE** 등 지표에서 평균 1–3% 개선  
- 특히 범주형 피처 비중이 높을수록 성능 격차가 크게 벌어짐  

### 한계  
- Transformer 블록 수 $$L$$와 임베딩 차원 $$d$$에 따라 모델 크기가 커짐  
- 대규모 범주 수(category cardinality)가 매우 큰 경우, 파라미터 및 연산 비용 상승  
- 메모리 및 연산 시간 측면에서 대규모 Tabular 데이터에 적용 시 추가 최적화 필요  

# 5. 일반화 성능 향상 관점  
컨텍스트 임베딩을 통해 피처 간 상호작용을 직접 학습함으로써, 모델은 과적합을 줄이고 **희소한 범주**에도 의미 있는 정보를 전이(transfer)할 수 있다. 특히, 드물게 등장하는 범주에 대해서도 유사한 범주의 문맥을 활용하여 일반화 성능을 확보하며, 이는 표본이 적은 환경에서 더욱 두드러진다.  

# 6. 향후 연구 방향 및 고려사항  
- **경량화**: MobileBERT, DistilTransformer와 유사한 경량화 기법을 적용하여 연산/메모리 비용 절감  
- **하이브리드 모델**: 그래프 신경망과 결합해 범주형 피처 간 복합 관계를 더 깊이 모델링  
- **적응적 어텐션**: 샘플별로 동적으로 어텐션 블록 수를 조절하여 효율성 확보  
- **오토ML 통합**: 자동 하이퍼파라미터 탐색 및 피처 중요도 기반 파이프라인 최적화  

위와 같은 방향으로 발전시킬 경우, TabTransformer의 범주형 모듈은 더욱 강력하고 효율적인 탭형 데이터 솔루션으로 자리매김할 수 있다.
