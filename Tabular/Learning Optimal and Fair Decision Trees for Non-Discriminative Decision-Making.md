# Learning Optimal and Fair Decision Trees for Non-Discriminative Decision-Making

# 핵심 요약 및 주요 기여

**핵심 주장**  
“Learning Optimal and Fair Decision Trees for Non-Discriminative Decision-Making” 논문은 **혼합정수최적화(MIP)** 기반의 통합 프레임워크를 통해 **분류 및 회귀** 작업에서 **최적성**과 **공정성(fairness)**을 동시에 보장하는 의사결정 트리를 학습할 수 있음을 보인다.[1]

**주요 기여**  
- **공정성 정의의 통합**: 분류(classification)·회귀(regression) 모두에 걸쳐 **직접 차별(disparate treatment)** 및 **간접 차별(disparate impact)** 지표를 수학적으로 통일 정의.  
- **MIP 기반 최적 트리 설계**: 예측 정확도 손실과 공정성 손실 간의 가중치 λ를 이용해 **목적함수**  

$$ \ell(T,\hat y) + \lambda \,\ell_{\text{fair}}(T,\hat y) $$  
  
  를 선형화하여 **정확도·공정성** 간 균형 조절 가능.  
- **회귀용 공정 트리**: 기존 연구가 분류에 치중된 반면, 회귀에서도 **두 종류의 차별**을 모두 완화할 수 있는 최초의 MIP 모델 제안.  
- **확장된 모델 구조**: 전통적 단일 특성 분기를 넘어 “선형 분기(linear branching)” 및 “선형 예측(leafing)” 규칙을 결합하여 **유연성**과 **해석 가능성** 강화.  
- **해석 가능성 맞춤**: 트리 깊이, 특성 사용 횟수 등을 제약 변수로 추가하여 의사결정자 요구에 따른 **모델 복잡도 제어** 지원.  
- **경쟁적 성능**: 기존 CART·heuristic·로지스틱 회귀 기반 공정 모델 대비 **차별 지표를 낮추면서 정확도 손실 최소화**함을 실험으로 입증.  

# 문제 정의 및 제안 방법

## 해결하고자 하는 문제  
사회적 의사결정(입학·대출·형량 결정 등)에서 기계학습 시스템이  
- **훈련 데이터 편향** 또는  
- **오류의 그룹별 불균등 분포**  
로 인해 **직접·간접 차별**을 야기하는 문제를 다룬다.  

## 공정성 지표 수학적 정의  
1. **간접 차별(Disparate Impact)**  
   - 분류: $$P(\hat y \mid x_p) = P(\hat y)$$ 보장[1]
   - 회귀: $$\mathbb{E}[\hat y \mid x_p] = \mathbb{E}[\hat y]$$ 보장[1]
2. **직접 차별(Disparate Treatment)**  
   - 분류: $$P(\hat y \mid x_p, x_{-p}) = P(\hat y \mid x_{-p})$$ 보장   
   - 회귀: $$\mathbb{E}[\hat y \mid x_p, x_{-p}] = \mathbb{E}[\hat y \mid x_{-p}]$$ 보장  

## MIP 프레임워크  

### 목적함수  

```math
\min_{T} \; \underbrace{\ell_{\text{acc}}(T)}_{\substack{\text{misclassification}\\\text{rate or MAE}}}
+ \lambda \underbrace{\ell_{\text{fair}}(T)}_{\substack{\text{DTDI or DIDI}\\\text{차별 지표}}}
```

여기서 λ로 **정확도-공정성** 간 트레이드오프 조절.

### 모델 구조  
- **고전적 트리**: 각 내부 노드에서 단일 특성 분기  
- **선형 분기**: 각 노드에서 다수 특성의 선형결합 기반 분기  
- **선형 리핑(leafing)**: 각 리프에서 선형 회귀식으로 예측  
- **조합 모델**: 선형 분기+선형 리핑 적용으로 유연도 극대화  

### 제약 및 변수  
- **p<sub>νj</sub>**: 노드 ν에서 특성 j 사용 여부 (0/1 또는 실수)  
- **z<sub>iℓ</sub>**: 데이터 i가 리프 ℓ에 속할지 여부  
- **유도 변수**: q<sub>ν</sub>, w<sub>iν</sub><sup>q</sup>, etc.로 분기 판정  
- **해석 가능성 제어**: 트리 깊이·특성 사용 횟수 상한 제약  

# 성능 향상 및 한계

## 성능 향상  
실험 결과, **Default, Adult, COMPAS** 분류 데이터와 **Crime** 회귀 데이터에서  
- **차별 지표(DTDI/DIDI)**를 기존 CART·heuristic·공정 로지스틱 대비 **더 낮추면서**  
- **정확도 손실**은 최소화(혹은 개선)  
- 특히 회귀용 공정 트리에서는 MAE 감소가 두드러짐  

## 한계  
- **학습 시간**: MIP 해석에 수시간~수만 초 소요  
- **확장성**: 대규모 데이터셋·고차원 특성 활용 시 계산 부담  
- **λ 선택**: 의사결정자 선호 반영 위한 **하이퍼파라미터 튜닝** 필요  

# 일반화 성능 관점

- **선형 분기·리핑** 구조로 트리 경계가 더 유연해져 **과소적합 방지**  
- λ 조정으로 차별 완화 목표에 따라 **과적합·과소적합** 균형  
- **MIP 최적화**로 전역 최적 트리 탐색 → 검증 데이터 일반화 성능 향상  

# 향후 연구 영향 및 고려 사항

## 연구 영향  
- **사회적 의사결정 지원**: 분석·제약 조건 추가로 다양한 윤리 규범 반영 가능  
- **공정성 연구 통합 플랫폼**: 새로운 차별 지표·공정성 개념 수용  
- **해석 가능 ML**: 복합 분·예 규칙 설계 방법론에 기여  

## 향후 고려 사항  
- **연산 효율화**: 근사 알고리즘·휴리스틱과 MIP 결합  
- **다중 공정성 목표**: 여러 보호 변수 동시 제약  
- **온라인 학습**: 실시간 업데이트 환경 적용 방안  
- **다양한 손실 함수**: 비선형 손실·확률적 예측 모델과의 결합  
- **실세계 배포**: 법적·윤리적 기준 준수 점검 및 사용자 인터페이스 설계  

***

 파일: “Learning Optimal and Fair Decision Trees…” 의 Abstract 및 1.2절.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/6d7e7420-d232-434c-829d-a23967bc95e0/1903.10598v1.pdf)
