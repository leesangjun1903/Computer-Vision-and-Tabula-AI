# DART: Dropouts meet Multiple Additive Regression Trees

**핵심 주장 및 주요 기여**  
DART는 기존의 부스팅 기반 회귀 트리(MART)가 후반부에 추가된 트리들이 소수의 인스턴스에만 기여하고 나머지에서는 거의 기여하지 않는 *over-specialization* 문제를 해결하기 위해, 트리 드롭아웃(dropout) 기법을 도입한 알고리즘이다. 학습 시 기존 앙상블에서 무작위로 일부 트리를 제거하고 새로운 트리를 학습한 뒤, 제거된 트리들과 함께 기여도를 정규화하여 재결합함으로써 모든 트리가 보다 고르게 기여하도록 유도한다. 이로써 모델의 일반화 성능이 크게 향상되며, 랭킹, 회귀, 분류 세 가지 주요 학습 과제에서 MART와 랜덤 포레스트를 일관되게 능가하는 성능을 보인다.[1]

***

## 1. 해결하고자 하는 문제  
MART(Gradient Boosted Regression Trees)는  
- 각 반복(iteration)에서 손실 함수의 음(negative) 그래디언트를 예측하는 트리를 추가하는 방식으로 학습  
- 초기 트리가 전체 데이터의 편향(bias)을 대부분 학습하고, 이후 트리들은 극히 일부 인스턴스만 보정하는 *over-specialization* 현상을 보임  
- 결과적으로 앙상블 크기 증가에도 불구하고 일반화 성능이 제한되고, 특정 트리에 과도하게 의존하게 됨.[1]

***

## 2. 제안하는 방법  
### 2.1 MART 기반 수식  
- 데이터 $$(x_i,y_i)$$와 손실 함수 $$L(y_i,\hat y_i)$$가 주어질 때,  
- 각 단계 $$t$$에서 음의 그래디언트 $$-\frac{\partial L}{\partial M(x)}\big|_{M=M_{t-1}}$$를 타깃으로 하는 회귀 트리 $$T_t$$를 학습하고,  
- 모델을 $$M_t(x)=M_{t-1}(x)+T_t(x)$$로 업데이트.[1]

### 2.2 트리 드롭아웃 기법  
1. **드롭아웃 단계**: 앙상블에 포함된 $$n$$개의 트리 중 확률 $$p_{\mathrm{drop}}$$로 무작위 선택하여 제거(최소 한 개는 드롭)  
2. **그래디언트 계산**: 남은 트리만으로 구성된 임시 모델 $$\hat M(x)$$에 대해 음의 그래디언트를 계산  
3. **트리 학습**: 해당 그래디언트를 예측하는 신규 트리 $$T$$를 학습  
4. **정규화(Normalization)**: 드롭된 $$k$$개의 트리와 신규 트리의 기여도를  
   - 신규 트리는 $$\tfrac{1}{k}$$ 배 축소  
   - 드롭된 트리들과 신규 트리 전체를 $$\tfrac{k}{k+1}$$ 배 재조정  
5. **재결합**: 정규화된 트리들을 앙상블에 추가하여 모델을 업데이트.[1]

이 과정을 통해 드롭된 트리들이 보정하던 손실을 새로운 트리와 분산시켜, 모든 트리가 균등하게 기여하도록 유도한다.

***

## 3. 모델 구조  
- **앙상블 형식**: 트리 부스팅과 랜덤 포레스트의 중간 형태  
- **드롭 비율**: $$p_{\mathrm{drop}}$$ 조절로 과도한 부스팅(=MART)과 과도한 무작위성(=랜덤 포레스트) 사이 최적점 탐색 가능  
- **하이퍼파라미터**: 트리 수, 리프 개수, 드롭아웃 확률, 특징 샘플링 비율 등  

***

## 4. 성능 향상 및 한계  
### 4.1 랭킹 (MSLR-WEB10K)  
- NDCG@3 기준 MART 대비 +0.4 포인트 향상  
- NDCG@1,2에서도 각각 +0.2, +0.38 포인트 개선  
- 학습 순위 대회 상위권 격차(0.35)보다 큰 성능 차이[1]

### 4.2 회귀 (CT Slices)  
- 앙상블 크기(25~1000) 전 구간에서 MART 대비 L2 오차 3~1.3 단위 절감  
- 랜덤 포레스트 대비도 일관되게 우수  
- 단일 드롭(드롭율 ≈0)만 적용해도 성능 이득 관찰[1]

### 4.3 분류 (Pascal face-detection)  
- 250개 트리 기준 MART 대비 정확도 소폭 개선(0.9707→0.9714)  
- 불균형 데이터셋에서 리콜 0.665→0.672로 유의미한 증대 (p<0.0001)  
- 트리 수 조정에 따른 최적점 유연성 확보[1]

**한계 및 고려사항**  
- 드롭아웃 확률과 정규화 방식에 대한 추가 실험 필요  
- 대규모 데이터·높은 차원 특성에서 최적 하이퍼파라미터 탐색 비용  
- 앙상블 해석력 감소 가능성  

***

## 5. 일반화 성능 향상 관점  
드롭아웃을 통한 *무차별적 트리 제거 및 정규화*는 부스팅 모델이 특정 트리에 과도하게 의존하는 현상을 억제하여,  
- 모든 트리가 더 균등하게 손실 감소에 기여  
- 과도한 적합(overfitting)을 방지하여 미지 데이터에 대한 예측 안정성 향상  
- MART와 랜덤 포레스트의 성향을 조절하며 과적합·과소적합 간 최적 균형 달성 가능[1]

***

## 6. 앞으로의 연구 방향 및 고려 사항  
- **다른 부스팅 알고리즘 적용**: AdaBoost, Gradient Boosting Machines 등에 드롭아웃 기법 확장  
- **드롭아웃 셋 선정 전략 실험**: 확률 이외의 중요도 기반·쌍별 상관관계 기반 드롭핑  
- **정규화 방식 최적화**: 스케일링 인자 및 재조정 순서 변경  
- **드리프트 학습(Drifting Targets)**: 주기적 드롭과 신규 학습으로 시계열 변화 대응  
- **이론적 분석**: 드롭아웃이 갖는 정규화 효과에 대한 일반화 경계(bound) 규명  

이 논문은 **부스팅 모델에 드롭아웃이라는 간단하면서도 강력한 정규화 기법**을 접목함으로써, 앙상블 학습 전반에 새로운 연구 가능성을 제시했다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/48400530-cb83-4f03-acea-247e385fc2af/1505.01866v1.pdf)
