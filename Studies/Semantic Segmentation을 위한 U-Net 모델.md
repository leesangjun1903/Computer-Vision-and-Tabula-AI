# U-Net을 활용한 의미론적 분할 입문

## 1. 의미론적 분할(Semantic Segmentation)이란?
의미론적 분할은 이미지 내 **모든 픽셀**에 대해 “이 픽셀은 어떤 클래스에 속하는가?”를 예측하는 작업입니다.  
- 이미지 분류(Image Classification): 이미지 내 객체 존재 여부를 예측  
- 객체 탐지(Object Detection): 이미지 내 객체의 경계 상자를 예측  
- 의미론적 분할: 픽셀 단위로 객체의 **경계**와 **문맥**을 모두 파악  

보다 세밀한 객체 경계를 보존하고, 전체 이미지 문맥을 이해해야 하기 때문에 어려운 과제입니다.

***

## 2. U-Net 모델의 등장 배경
U-Net은 2015년 의료 영상 분야(Biomedical imaging)를 위해 제안된 의미론적 분할 모델입니다.  
- **양방향 구조(U-shaped architecture)**: 인코더(Contracting path)로 문맥 정보를 수집하고, 디코더(Expanding path)로 세밀한 위치 정보를 복원  
- **스킵 연결(skip connections)**: 인코더 단계의 피처를 디코더에 직접 연결하여 경계 정보 손실을 최소화  

이 구조 덕분에 적은 데이터로도 높은 분할 성능을 낼 수 있어, 특히 의료 영상에서:
- 조직 및 병변 분할(MRI, CT)  
- 세포 구조 분석  
등에 널리 쓰이고 있습니다.

***

## 3. U-Net의 주요 특장점
1. **데이터 증강(Data Augmentation)**  
   적은 수의 의료 이미지를 증강해 학습 데이터를 확장함으로써 과적합을 방지  
2. **커스텀 손실 함수**  
   클래스 불균형이 심한 세그멘테이션 과제에 맞춰 Dice 계수, IoU 기반 손실 함수를 활용  
3. **스킵 연결**  
   하위 단계에서 획득한 고해상도 피처를 상위 단계로 전달, 미세 구조 복원  

***

## 4. U-Net과 최신 SOTA 모델 비교
의미론적 분할 분야의 벤치마크 데이터셋 성능(mIoU 기준):
- PASCAL VOC 2012 test: 90.5%  
- Cityscapes val: 86.95%  
- 최신 모델(예: DeepLabv3+ 등): 90% 이상  

U-Net은 여전히 의료 분야 논문에서 가장 많이 인용되며 전체 세그멘테이션 연구의 10% 이상을 차지할 만큼 영향력이 큽니다.

***

## 5. 주요 활용 사례
- **의료 영상 (Biomedical)**: 암 병변 분할, 장기 구조 인식  
- **자율주행**: 도로, 보행자, 차선 등 픽셀 단위 분할  
- **위성/항공사진**: 지형, 건물, 수역 분할  
- **산업 검사**: 제조 공정 중 결함 영역 분리  

***

## 6. 결론 및 다음 스텝
U-Net은 의미론적 분할 과제의 **문제 정의**, **네트워크 구조**, **학습 기법** 측면에서 훌륭한 학습 사례를 제공합니다.  

[1](https://dacon.io/forum/405807)

# U-Net 모델 구조 심층 해설

## 1. FCN(Fully Convolutional Network) 복습  
U-Net 구조를 이해하기 전, 의미론적 분할을 위해 분류 모델을 개조한 **FCN**의 주요 아이디어를 짚어봅니다.  
- **완전 연결층 제거:** VGG-16 같은 분류 모델은 마지막에 FC(완전 연결)층을 거치면서 공간 정보가 사라지고, 입력 크기가 고정됩니다.  
- **Convolution 대체:** FC층을 1×1 Conv로 바꾸면 위치 정보가 보존되고, 다양한 크기의 입력을 처리할 수 있습니다.  
- **업샘플링(Deconvolution):** 풀링으로 줄어든 피처맵을 원본 해상도로 복원하는 방법으로 학습 가능한 deconvolution(전치 컨볼루션)을 도입했습니다.  
- **스킵 커넥션:** 풀링 전 고해상도 피처맵을 업샘플링 단계에 더해 경계 정보를 보강(FCN-32s→FCN-16s→FCN-8s).  

이로써 FCN은 “Dense Prediction” 기술의 토대를 마련했지만, 여전히 픽셀마다 1회성 Conv만 수행해 세밀한 경계 복원에는 한계가 있었습니다.

***

## 2. U-Net U자형 구조  
U-Net은 FCN의 개념을 확장하여 **U자형(수축-팽창) 경로**를 가진 네트워크를 제안합니다.  

1. **수축 경로(Encoder)**  
   - 3×3 Conv → ReLU → 3×3 Conv → ReLU  
   - 2×2 Max pooling으로 해상도 절반, 채널은 두 배  
   - 반복 반복하며 문맥(context) 정보를 점진적으로 추출  

2. **확장 경로(Decoder)**  
   - 2×2 Transposed Conv(deconvolution)로 해상도 두 배 복원  
   - 인코더 대응 레이어의 피처맵 스킵 연결(skip connection)  
   - 스킵된 피처와 합성 후 3×3 Conv → ReLU → 3×3 Conv → ReLU로 정교하게 복원  

→ 이러한 구조가 U자 모양을 이루며, **위치 정보와 문맥 정보를 동시에 유지**합니다.

***

## 3. 핵심 구성 요소 비교  

| 구성 요소             | FCN                                     | U-Net                                              |
|-----------------------|-----------------------------------------|-----------------------------------------------------|
| 업샘플링 방법         | 학습 가능한 Transposed Conv (한 번)      | Transposed Conv + 두 번의 3×3 Conv 연속 적용        |
| 스킵 연결 활용        | 풀링 단계별 간단 합산(FCN-x)              | 대응하는 인코더 피처맵과 정교하게 연결 후 합성       |
| 연속 Conv 블록        | 분할 단계에서 1회성 Conv                | 업샘플링 전후 모두 두 번의 Conv 블록 구성           |
| 데이터 증강           | 별도 언급 없음                          | 과적합 방지를 위한 다양한 증강(회전, 이동, 반전 등) |
| 출력 해상도 정밀도    | 상대적으로 거칠음                       | 경계 정보가 풍부한 고해상도 분할 결과               |

***

## 4. 학습 시 특이점  
- **과적합 방지:** 의료 영상처럼 작은 데이터셋에 강력한 성능을 유지하기 위해 *over-tile* 전략과 강력한 증강 기법을 적용  
- **손실 함수:** 클래스 불균형 완화를 위한 Dice 계수, IoU 기반 손실 함수를 주로 사용  
- **경량화 변형:** 모바일·엣지 환경을 위해 필터 수를 줄이거나 심층 잔차 연결을 더해 경량화 모델도 활발히 연구  

***

## 5. 시각화 예시  
아래는 U-Net의 **수축-팽창 경로**와 **스킵 연결** 구성을 단순화해 나타낸 다이어그램입니다.

```
Input → [Conv×2 → Pool] × 4 → Bottleneck → [UpConv → Skip+Conv×2] × 4 → Output
```

- 왼쪽 절반은 해상도 ↓, 채널 ↑  
- 오른쪽 절반은 해상도 ↑, 채널 ↓  
- 중간 Bottleneck 블록에서 최심층 피처 학습  

***

## 6. 결론  
U-Net은 FCN이 제시한 “학습 가능한 업샘플링”과 “스킵 연결” 아이디어를 확장하여,  
- 세밀한 경계 복원  
- 위치와 문맥 정보 동시 유지  
- 작은 데이터셋에서도 강력한 일반화  

를 실현한 모델입니다. 

[1](https://dacon.io/forum/405845)

# U-Net 훈련 과정 특이점 심층 해설

## 1. Overlap-Tile 전략  
고해상도 의료 이미지를 네트워크에 바로 투입하면 GPU 메모리 과부하가 발생합니다. U-Net은 이를 해결하기 위해 입력 이미지를 겹치도록(tile) 잘라서 처리하는 **overlap-tile** 방식을 사용합니다.  
- 전체 이미지를 작은 타일로 분할할 때, 예측 경계에서 필요한 주변 문맥 정보를 손실 없이 유지하도록 각 타일에 **미러링(mirroring)** 기법을 적용해 테두리를 확장합니다.  
- 타일 예측 후에는 겹치는(overlap) 영역끼리 부드럽게 이어 붙여 전체 이미지를 원본 크기로 재구성합니다.  
- 이를 통해 한정된 메모리 환경에서도 고해상도 이미지를 **온전하게 분할**할 수 있습니다.

## 2. 강력한 데이터 증폭(Data Augmentation)  
의료 영상 데이터는 수집과 라벨링이 모두 비용이 높아, 학습 가능한 이미지가 제한적입니다. U-Net 논문에서는 다음과 같은 증폭 기법을 활용해 데이터 다양성을 확보합니다.  
- **기하학적 변환:** 회전, 이동, 반전(flipping), 스케일링  
- **강도 변환:** 밝기·대비 조절, 노이즈 추가  
- **Elastic Deformation:** 조직이나 세포 형태의 변형을 흉내 내기 위한 탄성 변환  
  
이들 증폭 기법은 네트워크가 다양한 외형 변이에 강인하도록 학습시키고, 과적합(overfitting)을 크게 줄여 줍니다.

## 3. 경계 강조 Weight Map 손실 함수  
인접한 세포나 병변이 붙어 있을 때는 픽셀 단위 분할 경계가 가장 어려운 부분입니다. U-Net은 예측 오류에 더 민감하도록 **weight map** 기반 손실 함수를 도입합니다.  
- 각 픽셀에 할당된 가중치 맵(weight map)은 “가장 가까운 객체 경계”와 “두 번째로 가까운 객체 경계” 사이 거리의 합을 이용해 계산됩니다.  
- 경계 픽셀일수록 가중치를 크게 부여하여, 모델이 경계 구획을 학습할 때 **더 큰 페널티**를 받도록 만듭니다.  
- 결국 두 인스턴스 사이에 명확한 배경(틈)이 예측되도록 유도해, **인접 객체 분리** 성능을 높입니다.

***

U-Net의 overlap-tile 처리, 폭넓은 데이터 증폭, 그리고 경계 강조 손실 함수는 모두 “고해상도·소량 데이터”라는 의료 영상 분할 과제의 특수조건을 극복하기 위해 설계된 핵심 기법입니다. 

[1](https://dacon.io/forum/405849)
