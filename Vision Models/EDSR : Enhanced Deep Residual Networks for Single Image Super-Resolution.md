# EDSR : Enhanced Deep Residual Networks for Single Image Super-Resolution | Super resolution

# 핵심 요약

“Enhanced Deep Residual Networks for Single Image Super-Resolution”(Lim et al., 2017)는 **불필요한 모듈 제거**와 **잔차 스케일링**을 통해 기존의 딥 잔차 네트워크를 단순화·확장함으로써, 단일 및 다중 배율(×2, ×3, ×4) 초해상화에서 **최신 기법 대비 PSNR 최대 0.7 dB 향상**을 증명한다. 제안된 단일규모 모델(EDSR)과 다중규모 모델(MDSR)는 배치 정규화를 제거해 메모리 사용량을 40% 절감하면서, self-ensemble 기법을 더해 대회에서 1·2위를 차지했다.

# 1. 해결하고자 하는 문제

전통적 SR(초해상화) 네트워크는  
1) ResNet 구조를 그대로 차용해 저수준 영상 처리에 과잉 설계된 모듈(배치 정규화 등)이 포함되며,  
2) 각 배율별로 별도 네트워크를 학습해야 해 모델 수·파라미터가 기하급수적으로 늘어난다.  
이로 인해 학습이 비효율적이고 일반화 능력 검증이 어려웠다.

# 2. 제안 방법

## 2.1 모델 구조

– **잔차 블록 개선**  
  - 기존 ResNet/SRResNet의 배치 정규화(BN) 제거 → 학습 안정성·표현력↑, 메모리↓  
  - 블록 내 마지막 합산 단계 직전 **잔차 스케일링**(0.1×) 도입 → 폭넓은 채널 확장 시 수치 불안정 해소  

– **EDSR(단일규모)**  
  - 깊이 B=32, 너비 F=256 구성  
  - 업샘플링 모듈(픽셀 셔플)으로 ×2,×3,×4 대응  
  - 초기 ×2 모델로 사전 학습 후, 그 가중치로 ×3·×4 모델을 **전이 학습**[수식 (1)]

  $$
    \mathcal{L}\_{L1} = \frac{1}{N}\sum_{i=1}^N \bigl|I_{SR}(x_i) - I_{HR}(x_i)\bigr|
  $$

  $$
    \theta_{×s} \leftarrow \theta_{×(s-1)}\quad (s=3,4)
  $$

– **MDSR(다중규모)**  
  - 공통 메인 브랜치(B=80, F=64), 배율별 전처리(5×5 필터 2개)·후처리(픽셀 셔플) 모듈 통합  
  - 단일 모델로 ×2·×3·×4 모두 지원, 파라미터 3.2M으로 단일규모 3개 합(4.5M)보다 경량  

## 2.2 학습 기법

- 손실 함수: L2 → **L1** 전환으로 수치적 수렴·성능 소폭 향상  
- 옵티마이저: Adam(β₁=0.9, β₂=0.999, ε=10⁻⁸)  
- 학습률 10⁻⁴ 시작, 2×10⁵회 반복마다 1/2 감소  
- **기하학적 Self-ensemble**: 8가지 조합(회전·뒤집기) 평균화로 추가 PSNR↑  

# 3. 성능 향상

| 모델               | DIV2K val ×4 PSNR/SSIM |
|--------------------|-------------------------|
| SRResNet (L2)      | 28.92 / 0.8960          |
| SRResNet (L1)      | 28.92 / 0.8961          |
| EDSR               | 29.25 / 0.9017          |
| MDSR               | 29.26 / 0.9016          |
| EDSR+ (Self-ens.)  | **29.38 / 0.9032**      |
| MDSR+ (Self-ens.)  | 29.36 / 0.9029          |

– EDSR는 SRResNet 대비 **PSNR +0.33 dB**, EDSR+는 +0.46 dB 증가.  
– Set5–Urban100 등 모든 벤치마크에서 일관된 성능 우위 확인.

# 4. 일반화 성능 및 한계

**일반화 향상 요인**  
- **전이학습(사전 학습)**: 낮은 배율에서 학습된 가중치로 고배율 초기화 → 빠른 수렴·과적합 억제  
- **공유 파라미터 구조(MDSR)**: 서로 다른 배율 간 특징 학습 상호 보강  
- **BatchNorm 제거**: 트레이닝·테스트 도메인 불일치 감소

**제한점**  
- **블라인드 노이즈/블러**: 본 논문은 주로 ‘bicubic 다운샘플링’ 기반이며, 실제 노이즈·블러에는 추가 모듈 필요  
- **계산 비용**: EDSR 규모(43M 파라미터) 학습에 8일 소요, 경량화 연구 필수  
- **지표 편향**: L1 최적화는 PSNR·SSIM 지표 개선에 유리하나, 주관적 화질(예: 텍스처 자연스러움) 측정은 별도 검증 필요

# 5. 향후 연구에의 영향 및 고려 사항

**영향**  
- Residual 블록 최적화(배치정규화 제거·스케일링) 아이디어는 영상 복원, deblurring, denoising 등 광범위한 저수준 비전 과제에 적용 가능  
- 단일 네트워크 다중배율 처리(MDSR)는 다중 해상도 영상처리 효율화 전략으로 자리잡음  

**고려 사항**  
- **비선형·실제 열화 모델**(Motion blur, JPEG artifact 등) 대응을 위한 블라인드 SR 통합  
- **무손실 품질 평가**(Perceptual loss, GAN) 도입으로 주관적 화질·텍스처 재현력 강화  
- **경량화 구조 탐색**(NAS, 효율적 컨볼루션) 및 하드웨어 최적화로 실생활 적용성 확보  

---  
위 논문은 **잔차 네트워크 구조의 불필요성 제거**와 **효율적 다중배율 학습**으로 SISR 분야의 최상위 성능을 달성하며, 후속 연구의 핵심 설계 원칙을 제시했다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/cf2af6cf-f321-4986-a0a2-f2d792a9e25b/1707.02921v1.pdf
