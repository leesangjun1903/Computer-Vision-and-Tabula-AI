# YOLOr : You Only Learn One Representation: Unified Network for Multiple Tasks | Object detection, Semantic segmentation, Keypoint detection, Image classification

## 핵심 주장 및 주요 기여  
이 논문은 **명시적 지식(explicit knowledge)**과 **암묵적 지식(implicit knowledge)**을 하나의 통합 표현으로 결합하여, 단일 신경망이 객체 검출, 분할, 키포인트 탐지, 이미지 분류 등 **복수의 컴퓨터 비전 및 자연어 처리 과제**를 동시에 수행할 수 있음을 보인다. 주요 기여는 다음과 같다.  
1. 명시적·암묵적 지식을 통합해 **범용 표현(unified representation)**을 학습하고, 각 과제별로 서브표현을 분리·활용하는 네트워크 구조를 제안.  
2. 커널 공간 정렬(kernel space alignment), 예측 세분화(prediction refinement), 다중 과제 학습(multi-task learning)을 암묵적 지식 학습 과정에 도입하여 성능 향상을 검증.  
3. 벡터, 신경망, 행렬 분해(matrix factorization) 방식으로 암묵적 지식을 모델링하는 세 가지 접근법을 제시하고, 각각의 효과를 실험적으로 분석.  
4. 학습된 암묵적 표현이 물리적 의미(예: 객체 중심 좌표, 앵커 스케일)를 포착함을 시각적으로 분석.  
5. Scaled-YOLOv4-P7 수준의 정확도를 유지하면서 추론 속도를 88% 증가시킨 객체 검출 모델을 구현.  

***

## 해결하고자 하는 문제  
- **단일 CNN 모델의 과제 특이성**: 기존 CNN은 한 가지 과제에 최적화된 표현만 학습하며, 다른 과제로 일반화되기 어려움.  
- **암묵적 지식 활용 부재**: 인간의 두뇌처럼 명시적 경험과 잠재적(암묵적) 경험을 결합하여 다양한 문제에 대응하는 메커니즘이 부재.  

***

## 제안 방법  
### 모델 수식  
1. 기존 네트워크:  

$$ y = f_\theta(x) + \epsilon, \text{ minimize } \epsilon $$  

2. 통합 네트워크:  

$$ y = f_\theta(x) + \epsilon + g_\phi(\epsilon_{ex}(x), \epsilon_{im}(z)), \quad \min \bigl[\epsilon + g_\phi(\epsilon_{ex}(x), \epsilon_{im}(z))\bigr] $$  
   
   간소화하여  

$$ y = f_\theta(x)\,\star\,g_\phi(z), $$  
   
   여기서 $$\star$$는 덧셈, 곱셈, 이어붙이기(concatenation) 연산을 의미.  

3. 다중 과제 확장:  

   $$F(x, \theta, Z, \Phi, Y, \Psi) = 0, \quad Z=\{z_1,\dots,z_T\} $$  

   $$d_\Psi\bigl(f_\theta(x), g_\Phi(z), y\bigr)=0 \quad (\forall z\in Z) $$  

### 암묵적 지식 모델링  
- 벡터 방식: $$z\in\mathbb{R}^k$$  
- 신경망 방식: $$g_\phi(z)=W z$$ 또는 MLP  
- 행렬 분해 방식: $$g_\phi(z)=Z_c\,c$$ (비음수 제약, 희소성 제어 가능)  

### 네트워크 구조  
- YOLOv4-CSP 기반 백본에 암묵적 표현 모듈을 삽입  
- FPN 단계별 **커널 공간 정렬(iFA)**: 특징 맵 간 정렬 개선  
- 출력 레이어 **예측 세분화(iPR)**: 위치·크기·객체성 확률 보정  
- **다중 과제 분기**에 암묵적 표현 추가(iJDC, iJDE)  

***

## 성능 향상  
- **단일 과제 객체 검출**: AP +0.5% (47.8→48.3)  
- **FPN 정렬(iFA)**: APS +0.5%, APM +0.6%, APL +0.6%  
- **예측 세분화(iPR)**: APM +0.8%, APL –0.5%  
- **다중 과제(iJDC, iJDE)**: 통합 학습 성능이 단일 과제 대비 우월  
- **행렬 분해 방식**이 AP +0.2%, AP50 +0.4%, AP75 +0.5%로 최고 성능  
- **추론 부하 제어**: 파라미터·FLOPs 증가율 <0.01%  
- **최종 객체 검출**: Scaled-YOLOv4-P7와 유사 정확도(55.4% AP) 유지하며 속도 88% 개선  

***

## 한계 및 고려 사항  
- **암묵적 표현 차원 설정**: 지나치게 크면 과적합, 작으면 표현력 부족  
- **연산 연산자 선택**: 레이어 물리적 의미에 맞춰 덧셈·곱셈·이어붙이기 선택 필요  
- **다중 과제 편향**: 특정 과제 손해 없이 균형 유지 위한 손실 가중치 재조정 필요  
- **비전 외 도메인 적용**: 자연어·음성 등 타 분야 일반화 검증 미흡  

***

## 모델의 일반화 성능 향상 방향  
암묵적 지식이 **공통 기반 표현**을 풍부히 하여, 데이터 분포 차이가 큰 신규 과제에서도 빠른 적응과 안정적 성능을 기대할 수 있다. 특히,  
- **제로샷 도메인 전이**: unseen 도메인에 대한 내성 강화  
- **소량 샷 학습**: 임베딩된 암묵적 벡터로 소량 레이블만으로도 효과적 파인튜닝  
- **멀티모달 융합**: 시각·언어·음성 등 다양한 정보원 암묵적 결합  

을 통해 모델 일반화 능력을 더욱 제고할 수 있다.

***

## 향후 연구 영향 및 고려 사항  
이 접근은 **범용 인지형 신경망** 개발에 기여하여, 자율주행·로보틱스·의료 진단·지능형 에이전트 등의 다양한 멀티태스크 환경에 적용 가능하다.  
- **암묵적 지식 학습 기법 확장**: 강화학습, 메타러닝과 결합하여 자율 학습 능력 확보  
- **효율적 임베딩 압축**: 실시간·엣지 디바이스 적용을 위한 경량화  
- **과제 간 상충 조정 메커니즘**: 적대적 최적화 및 동적 손실 가중치 설계  

등을 고려함으로써, 차세대 다중 과제 신경망 연구에 중요한 토대를 제공할 것이다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/d2ddeffd-00f7-4e4e-9fce-a7de79b41cd4/2105.04206v1.pdf
