# Three things everyone should know to improve object retrieval | Image retrieval

## 1. 핵심 주장 및 주요 기여 (간결 요약)
- **RootSIFT 도입**: SIFT 디스크립터를 L1 정규화 후 요소별 제곱근 처리하여 Hellinger 커널과 동등한 유사도 측정 방식 구현. 간단한 변환만으로 모든 단계에서 일관된 성능 향상.  
- **Discriminative Query Expansion (DQE)**: 양성(**+)·음성(**–**) 데이터를 활용해 선형 SVM으로 BoW 가중치 학습, 평균 기법 대비 질의 확장 정확도 및 대규모 데이터셋에서 향상된 mAP 달성.  
- **Spatial Database-side Feature Augmentation (SPAUG)**: 기존 데이터베이스 측 특성 확장 시 모든 이웃 이미지의 특징을 사용하는 대신, 호모그래피로 가시 영역을 검증하여 불필요한 시각 단어 제거. 정밀도 유지하면서 재현율 대폭 향상.  

## 2. 문제 정의 및 제안 방법 상세
### 2.1 해결하고자 하는 문제
- 대규모 이미지 데이터셋에서 쿼리 이미지와 동일한 객체를 **실시간**으로 검색할 때  
  - SIFT 비교에서의 양자화 손실  
  - 낮은 재현율(recall) 및 정밀도(precision)  
  - 쿼리 확장 및 데이터베이스 특성 확장의 한계  

### 2.2 제안하는 방법
#### 2.2.1 RootSIFT
- 원본 SIFT $$x$$를 L1 정규화 후 요소별 제곱근 처리:  

$$
    \hat{x}_i = \sqrt{\frac{x_i}{\sum_j x_j}}
  $$

- 이렇게 변환된 벡터는 L2 정규화되어,  

$$
    \|\hat{x}\|_2 = 1,\quad
    d_E(\hat{x}, \hat{y})^2 = 2 - 2\sum_i \sqrt{x_i y_i}
  $$  
  
  를 만족하며, 원본 SIFT에 대한 Hellinger 커널과 동일한 유사도 측정 가능.

#### 2.2.2 Discriminative Query Expansion (DQE)
- **양성 샘플**: 초기 tf–idf 상위, 공간 검증된 결과에서 얻은 BoW 벡터  
- **음성 샘플**: tf–idf 점수가 낮은(그러나 0은 아닌) 하위 200개 이미지의 BoW 벡터  
- 각 벡터를 IDF 가중치 및 L2 정규화 후, 선형 SVM 학습:

$$
    \min_w \tfrac12\|w\|^2 + C\sum_i \max\bigl(0,1 - y_i w^T x_i\bigr)
  $$

- 재쿼리 시 $$w^T x$$로 이미지 순위 매김. 평균 확장(AQE) 대비 음·양성 단어 가중치 학습으로 더욱 정교한 확장.

#### 2.2.3 Spatial Database-side Feature Augmentation (SPAUG)
- **기존 AUG 한계**: 인접 그래프 이웃 모두의 시각 단어를 무차별 확장 → 불필요 단어 포함  
- **SPAUG 제안**:  
  1. 이미지 그래프에서 공간 검증 시 추정된 호모그래피 $$H$$ 사용  
  2. 이웃 이미지의 단어 중 $$H$$로 원본 이미지 영역 내로 투영되는 시각 단어만 선택 확장  
- 확장된 BoW로 IDF 재계산 후 인덱스 구축 → 평균 대비 약 28% 적은 불필요 단어 삽입, mAP 대폭 향상  

### 2.3 모델 구조 및 파이프라인
1. **오프라인**  
   - RootSIFT 벡터로 시각 어휘(Vocabulary) 생성  
   - 데이터베이스 각 이미지로 쿼리 수행 → 공간 검증 이미지 그래프 구축  
   - SPAUG 적용하여 BoW 재구성 및 IDF 재계산  
2. **온라인**  
   - 입력 쿼리: 관심 영역에서 RootSIFT 추출 → BoW 인코딩 → 첫 번째 tf–idf 검색  
   - 상위 결과 공간 재검증 → 양·음성 샘플 확보 → DQE용 선형 SVM 학습  
   - SVM 가중치로 재쿼리 → 최종 공간 재검증 및 순서 결정  

### 2.4 성능 향상
- Oxford 105k 기준:  
  - **기본 tf–idf**에서 RootSIFT 적용 시 mAP 0.515→0.581  
  - **AQE** 대비 DQE로 0.726→0.752 (RootSIFT)  
  - **SPAUG** 적용 시 0.642→0.767  
  - 모든 기법 결합 후 mAP 0.823 → 최고 수준[Perˇdoch et al. 대비 +1.8%]  

### 2.5 한계
- **저장 비용 증가**: SPAUG로 인해 인덱스 크기 확장  
- **그래프 구축 시간**: 데이터베이스 측 전처리 복잡도  
- **작거나 극단적 조명/시점 쿼리**: 특징점 부재로 재현율 저하  

## 3. 일반화 성능 향상 가능성
- **RootSIFT의 범용성**  
  - SIFT 기반 모든 응용 분야(분류·검출)에서 비선형 맵 활용 가능  
- **DQE의 데이터 확장성**  
  - 대규모 · 다양한 도메인에서 음성 샘플 추가로 **보다 견고한** 가중치 학습  
- **SPAUG의 가시성 검증**  
  - 호모그래피 추정 기반 확장은 **다양한 뷰·환경**에서도 불필요 노이즈 억제  
- **결합 효과**: 파이프라인 전 단계에 걸친 개선이 상호 보완하며 **강건한 일반화** 달성  

## 4. 향후 연구에 미치는 영향 및 고려할 점
- RootSIFT와 DQE 기법은 **즉시 도입 가능**한 저비용·고효율 솔루션으로, 차세대 객체 검색·인식 시스템의 **기본 구성 요소**로 자리잡을 전망.  
- SPAUG의 저장 및 계산 오버헤드를 줄이기 위한 **효율적 인덱싱·그래프 압축 기법** 연구가 필요.  
- **딥러닝 기반 디스크립터**와의 결합을 통해 RootSIFT 변환 및 DQE 가중치 학습을 **엔드 투 엔드 학습** 가능한 구조로 확장하면, 더욱 우수한 일반화 성능을 기대할 수 있음.  
- 소수 특징점·극단적 조건에서는 여전히 성능 한계가 존재하므로, **특징 증강**이나 **조건별 보정 모듈** 개발이 향후 과제로 남음.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/cc0b328d-d391-42f0-a102-ae8fe5e9b1c3/arandjelovic12.pdf
