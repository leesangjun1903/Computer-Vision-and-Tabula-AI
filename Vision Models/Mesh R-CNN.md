# Mesh R-CNN | 3D segmentation

## 핵심 주장과 주요 기여

**Mesh R-CNN**은 현실 세계 이미지에서 객체를 탐지하고 각 탐지된 객체의 완전한 3D 삼각형 메쉬를 생성하는 통합 시스템입니다. 이 연구의 핵심 주장은 2D 인식의 발전과 3D 형태 예측 기술을 통합하여 현실 세계의 복잡한 환경에서도 작동하는 시스템을 구축해야 한다는 것입니다.[1]

**주요 기여:**
- **Mask R-CNN의 확장**: 기존의 2D 인식 시스템인 Mask R-CNN에 3D 메쉬 예측 브랜치를 추가[1]
- **하이브리드 표현 방법**: 복셀 예측과 메쉬 세밀화를 결합하여 임의의 토폴로지를 가진 고해상도 메쉬 출력 가능[1]
- **종단간 학습**: 전체 시스템을 end-to-end로 훈련 가능한 구조 제공[1]

## 해결하고자 하는 문제

기존의 2D 인식 시스템들은 세계가 3D 구조를 가진다는 사실을 무시하고 있으며, 3D 형태 예측 연구들은 주로 ShapeNet과 같은 합성 벤치마크에서 격리된 객체들에 집중해왔습니다. 특히 기존의 메쉬 예측 방법들은 고정된 메쉬 템플릿에서 변형하는 방식으로 제한되어 있어 고정된 토폴로지만 표현할 수 있었습니다.[1]

## 제안하는 방법 및 모델 구조

### 전체 아키텍처
Mesh R-CNN은 **복셀 브랜치(Voxel Branch)**와 **메쉬 세밀화 브랜치(Mesh Refinement Branch)**로 구성된 새로운 메쉬 예측기를 포함합니다.[1]

### 복셀 브랜치
복셀 브랜치는 각 탐지된 객체의 거친 3D 복셀화된 형태를 예측합니다. 픽셀별 대응을 유지하기 위해 카메라의 고유 행렬을 사용하여 절두체 모양의 복셀을 예측합니다.[1]

**Cubify 연산**: 복셀 점유 확률을 입력으로 받아 삼각형 메쉬로 변환합니다. 각 점유된 복셀은 8개의 꼭짓점, 18개의 모서리, 12개의 면을 가진 육면체 삼각형 메쉬로 대체됩니다.[1]

### 메쉬 세밀화 브랜치
Cubify된 메쉬는 거친 3D 형태만 제공하므로, 메쉬 세밀화 브랜치에서 여러 세밀화 단계를 거쳐 꼭짓점 위치를 조정합니다.[1]

각 세밀화 단계는 세 가지 연산으로 구성됩니다:
- **꼭짓점 정렬(Vertex Alignment)**: 각 메쉬 꼭짓점에 대해 이미지 정렬된 특징 벡터 추출
- **그래프 합성곱(Graph Convolution)**: 메쉬 모서리를 따라 정보 전파
- **꼭짓점 세밀화(Vertex Refinement)**: 꼭짓점 위치 업데이트

**그래프 합성곱 수식:**

$$f'\_i = \text{ReLU}(W_0 f_i + \sum_{j \in N_i} W_1 f_j) $$ [1]

**꼭짓점 세밀화 수식:**

$$v'\_i = v_i + \tanh(W_{\text{vert}} [f_i; v_i]) $$ [1]

### 손실 함수
메쉬에서 직접 작동하는 손실 함수 정의가 어려우므로, 메쉬 표면에서 균일하게 샘플링된 점군을 사용합니다.[1]

**Chamfer Distance:**

$$L_{\text{cham}}(P, Q) = \frac{1}{|P|} \sum_{(p,q) \in P \leftrightarrow Q} ||p - q||^2 + \frac{1}{|Q|} \sum_{(q,p) \in Q \leftrightarrow P} ||q - p||^2 $$ [1]

**Normal Distance:**

$$L_{\text{norm}}(P, Q) = \frac{1}{|P|} \sum_{(p,q) \in P \leftrightarrow Q} |u_p - u_q| + \frac{1}{|Q|} \sum_{(q,p) \in Q \leftrightarrow P} |u_q - u_p| $$ [1]

**Edge Loss:**

$$L_{\text{edge}}(V, E) = \sum_{(v,v') \in E} ||v - v'||^2 $$ [1]

## 성능 향상 결과

### ShapeNet 벤치마크
- **Chamfer Distance**: 0.306 (기존 최고 성능 0.463 대비 크게 개선)[1]
- **F1@0.1**: 74.84% (기존 67.89% 대비 향상)[1]
- **F1@0.2**: 85.75% (기존 79.88% 대비 향상)[1]

### Pix3D 데이터셋
현실 세계 이미지에서 객체 탐지와 3D 형태 예측을 동시에 수행하는 최초의 시스템으로, **APmesh 51.1%**를 달성했습니다.[1]

## 일반화 성능 향상 가능성

### 토폴로지 다양성
기존 방법들과 달리 Mesh R-CNN은 **임의의 토폴로지**를 가진 메쉬를 생성할 수 있습니다. 이는 구멍이 있는 객체(책장, 테이블 등)나 복잡한 구조를 가진 실제 객체들을 더 정확하게 표현할 수 있게 합니다.[1]

### 하이브리드 접근법의 장점
복셀 예측과 메쉬 세밀화를 결합한 하이브리드 접근법은:
- **복셀 단계**: 다양한 토폴로지 구조 포착 가능
- **메쉬 세밀화 단계**: 의자 다리, 테이블 상판과 같은 세밀한 구조 표현 가능[1]

### 현실 세계 적용성
Pix3D에서의 성공적인 결과는 시스템이 **클러터, 가려짐, 다양한 조명 조건**을 가진 현실 세계 환경에서도 효과적으로 작동할 수 있음을 보여줍니다.[1]

## 한계점

1. **데이터 의존성**: 현재 완전 지도학습 방식으로, 대규모 3D 주석 데이터가 필요합니다[1]
2. **객체 중심 접근**: 개별 객체 형태 예측에 집중하여 3D 장면의 전체적인 레이아웃 추론은 고려하지 않습니다[1]
3. **계산 복잡성**: 복셀과 메쉬 두 단계의 처리로 인한 계산 비용 증가
4. **깊이 범위 예측의 어려움**: 단일 이미지에서 객체의 깊이 범위 예측은 본질적으로 ill-posed 문제입니다[1]

## 향후 연구에 미치는 영향

### 연구 방향 확장
- **멀티모달 입력**: RGB-D 이미지나 포인트클라우드 등 3D 입력을 통합하여 형태 예측 정확도 향상 가능성[1]
- **비지도 학습**: 3D 주석 없이도 3D 형태를 재구성하는 방향으로의 확장[1]
- **장면 수준 이해**: 개별 객체를 넘어 전체 3D 장면의 레이아웃과 객체 간의 상대적 포즈 추론[1]

### 앞으로 연구 시 고려사항

1. **평가 메트릭 개선**: 표준 메트릭들이 메쉬 품질과 잘 상관되지 않는 문제 해결 필요[1]
2. **형태 정규화 균형**: 정량적 성능과 메쉬 품질 사이의 균형점 찾기[1]
3. **대규모 데이터셋**: COCO 수준의 대규모 3D 주석 데이터셋 구축의 중요성[1]
4. **실시간 처리**: 실제 응용을 위한 계산 효율성 개선[1]

이 연구는 2D 인식과 3D 형태 예측을 성공적으로 통합한 첫 번째 시도로, **컴퓨터 비전 분야에서 2D에서 3D로의 패러다임 전환**을 이끄는 중요한 기여를 했습니다. 특히 현실 세계 이미지에서의 3D 이해를 위한 새로운 연구 방향을 제시했다는 점에서 향후 관련 연구들의 기준점이 될 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/49384a53-378c-47a4-b252-f473d4c45756/1906.02739v2.pdf)
