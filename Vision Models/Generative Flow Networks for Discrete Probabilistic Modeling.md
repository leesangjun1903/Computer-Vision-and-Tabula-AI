# Generative Flow Networks for Discrete Probabilistic Modeling | 2022 · 134회 인용, Image generation

## 핵심 주장과 주요 기여

**Energy-based Generative Flow Networks (EB-GFN)**은 고차원의 이산 데이터에 대한 새로운 확률적 모델링 알고리즘입니다. 이 논문의 핵심 주장은 기존 MCMC 방법들의 모드 간 믹싱 문제를 해결하기 위해, GFlowNet을 사용하여 에너지 함수와 샘플러를 동시에 학습한다는 것입니다.[1]

주요 기여는 다음과 같습니다:

1. **비자동회귀적 순차 생성 모델**을 GFlowNet으로 구현하여 고차원 이산 데이터 생성 문제를 해결[1]
2. **GFlowNet 기반 MCMC 제안 메커니즘**을 도입하여 낮은 거부 확률로 효율적인 대규모 점프를 가능하게 함[1]
3. **공동 훈련 프레임워크**를 제안하여 GFlowNet 샘플러와 에너지 모델을 동시에 학습하는 방법론 개발[1]
4. **다양한 합성 및 실제 데이터셋**에서 경쟁력 있는 성능을 달성[1]

## 문제 설정과 제안 방법

### 해결하고자 하는 문제

이산 공간에서의 확률적 모델링, 특히 구성적 구조를 가진 고차원 데이터 분포 모델링은 다음과 같은 문제들이 있습니다:[1]

- **조합적 성장**: 모드의 수가 급격히 증가하며, 이들 모드가 서로 잘 분리되어 있음[1]
- **MCMC 믹싱 문제**: 전통적인 MCMC 방법들은 모드 간 이동이 느리고, 분포의 잠재 구조에 대한 사전 지식이 없으면 혼합이 어려움[1]
- **가짜 모드 문제**: MCMC의 에너지 경관 탐색 실패로 인해 실제 데이터 분포에 없는 새로운 모드가 학습된 분포에 나타남[1]

### 제안하는 방법론

#### 1. GFlowNet 생성 과정

데이터 공간을 $$X = \{0, 1\}^D$$로 정의하고, 상태 공간을 다음과 같이 구성합니다:[1]

$$S = \{(s_1, \ldots, s_D) | s_d \in \{0, 1, \varnothing\}, d = 1, \ldots, D\}$$

여기서 $$\varnothing$$는 아직 지정되지 않은 엔트리를 나타냅니다.[1]

#### 2. 궤도 균형 목적 함수

GFlowNet 훈련을 위해 다음 궤도 균형 목적 함수를 사용합니다:[1]

$$L_\theta(\tau) = \left[\log \frac{Z_\theta \prod_{t=0}^{n-1} P_F(s_{t+1} | s_t; \theta)}{R(s_n) \prod_{t=0}^{n-1} P_B(s_t | s_{t+1}; \theta)}\right]^2$$

#### 3. 에너지 함수 공동 훈련

에너지 함수 $$E_\phi(x)$$와 GFlowNet을 공동으로 훈련하며, 근사 MLE 방식으로 업데이트합니다:[1]

$$\mathbb{E}_{x \sim p_{data}(x)}[\nabla_\phi E_\phi(x)] - \mathbb{E}_{x' \sim P_T(x')}[\nabla_\phi E_\phi(x')]$$

#### 4. Back-and-forth 제안 메커니즘

MCMC 전이 커널로서의 GFlowNet 활용을 위해 다음과 같은 메트로폴리스-해스팅스 수용 확률을 제안합니다:[1]

$$A_{\tau,\tau'}(x \to x') = \min\left(1, \frac{e^{-E_\phi(x')}}{e^{-E_\phi(x)}} \frac{P_B(\tau|x)P_F(\tau')}{P_B(\tau'|x')P_F(\tau)}\right)$$

## 모델 구조

### 신경망 아키텍처

- **정책 네트워크**: 다층 퍼셉트론(MLP) 구조로 구현[1]
- **입력 인코딩**: $$\{0, 1, \varnothing\}$$ 벡터를 -1, 0, 1로 인코딩하여 $$\varnothing$$ 표현[1]
- **가중치 공유**: 전진 정책과 후진 정책이 마지막 가중치 행렬을 제외하고 모든 가중치를 공유[1]
- **정규화 상수**: $$Z_\theta$$를 로그 도메인에서 매개변수화[1]

### 훈련 전략

Algorithm 1에 따른 공동 훈련 프레임워크:[1]
1. 베르누이 분포에서 샘플링하여 전진/후진 궤도 선택
2. 궤도 균형 목적 함수로 GFlowNet 업데이트
3. Algorithm 2로 에너지 함수 업데이트
4. 수렴까지 반복

## 성능 향상 및 실험 결과

### 정량적 성능

**Ising 모델 실험**에서 EB-GFN은 Gibbs 및 GWG 방법 대비 우수한 성능을 보였습니다:[1]
- σ = 0.1에서 negative log-RMSE: EB-GFN 6.1 vs Gibbs/GWG 4.8
- σ = 0.5에서 모든 방법이 유사한 성능 (2.3) 달성

**합성 데이터 실험**에서 7개의 2D 합성 문제에 대해:[1]
- NLL 기준으로 대부분의 데이터셋에서 최고 성능 달성
- MMD 메트릭에서도 경쟁력 있는 결과 (예: checkerboard에서 1.206×10⁻⁴)

**이산 이미지 모델링**에서 4개의 바이너리 이미지 데이터셋에 대해:[1]
- Omniglot: 112.59 NLL (GWG 114.96 대비 개선)
- Silhouettes: 185.57 NLL (GWG 188.82 대비 개선)

### 정성적 분석

실험 결과는 **멀티모달 태스크**에서 GFlowNet이 기준선보다 모드와 구조를 훨씬 잘 포착함을 보여줍니다. 특히 checkerboard와 8gaussians 같은 복잡한 분포에서 우수한 성능을 나타냅니다.[1]

## 일반화 성능 향상

### 구성적 구조 학습

GFlowNet의 핵심 장점은 **구성적 생성 구조**를 통한 일반화 능력입니다. 저에너지 구성을 학습하여 데이터 분포의 학습 가능한 규칙성이 있다면 아직 방문하지 않은 모드를 추측하고 샘플링할 수 있습니다.[1]

### 모드 간 점프 능력

기존 MCMC 방법과 달리, GFlowNet은 모드 사이의 긴 저확률 경로를 거치지 않고도 **구조를 발견하여 모드 간 점프**가 가능합니다. 이는 분포 구조가 명시적으로 알려지지 않은 경우에도 효과적입니다.[1]

### 최대 엔트로피 속성

Proposition 1에 따르면, 균등한 후진 정책을 사용할 때 결과적인 마르코프 플로우는 **보상 매칭 제약을 만족하는 모든 마르코프 플로우 중 최대 엔트로피**를 가집니다. 이는 모델의 일반화 성능을 향상시키는 중요한 이론적 기초입니다.[1]

## 한계점

### 계산 비용

에너지 함수와 샘플러를 모두 훈련해야 하므로 **추가적인 계산 비용**이 발생합니다. 그러나 이 비용은 이후 샘플러를 사용할 때 상각될 수 있으며, GFlowNet에서 샘플을 생성하는 것이 모드를 잘 커버하려는 경우 MCMC보다 훨씬 저렴합니다.[1]

### 방법론적 제약

현재 구현에서는 **이진 공간에 제한**되어 있으며, 더 복잡한 이산 구조로의 확장이 필요합니다. 또한 완전한 궤도(K = D) 샘플링이 아닌 **반복적인 제안 사용**에 대한 추가 연구가 필요합니다.[1]

## 향후 연구에 미치는 영향

### 이론적 기여

이 연구는 **생성 순서 학습을 전진(구성)과 후진(소거) 마르코프 과정의 공동 추론**으로 해석한 최초의 연구입니다. 이는 새로운 이론적 프레임워크를 제공하며, 향후 순차 생성 모델 연구에 중요한 기반이 됩니다.[1]

### 방법론적 확장성

EB-GFN 접근법은 **다양한 다른 유형의 생성 작업**으로 확장될 수 있을 것으로 예상됩니다. 특히 이산 공간에서의 확률적 추론 문제에서 새로운 해결책을 제시할 수 있습니다.[1]

### 실용적 응용

**자연어 처리**나 **기호적 추론** 같은 이산 데이터 구조가 보편적으로 사용되는 응용 분야에서 중요한 의미를 가집니다. 구성적 구조를 가진 복잡한 이산 분포 모델링에서 실질적인 개선을 제공할 수 있습니다.[1]

## 향후 연구 고려사항

### 반복적 제안 메커니즘

완전한 궤도 샘플링 대신 **훈련된 GFlowNet으로부터 반복적 제안**을 사용하여 공간의 효율적 탐색을 고려해야 합니다. 이는 계산 효율성과 탐색 능력 사이의 균형을 맞추는 중요한 연구 방향입니다.[1]

### 확장성 개선

현재 이진 공간 제약을 넘어서 **더 일반적인 이산 구조**로의 확장 연구가 필요합니다. 또한 더 큰 규모의 데이터와 더 복잡한 분포에서의 성능 검증이 요구됩니다.

### 이론적 분석 심화

**수렴성 보장**과 **근사 오차 분석** 등 이론적 기반을 더욱 강화하는 연구가 필요합니다. 특히 공동 훈련 과정에서의 안정성과 최적성에 대한 더 깊은 이해가 요구됩니다.

이 논문은 이산 확률적 모델링 분야에서 GFlowNet의 새로운 응용을 제시하며, 특히 구성적 구조를 가진 복잡한 분포 학습에서 상당한 진전을 보여줍니다. 모드 간 점프 능력과 일반화 성능 향상은 향후 이산 생성 모델 연구에 중요한 방향성을 제시합니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/ce9f19fb-39c2-4de8-b41f-02d1eadb7f0c/2202.01361v2.pdf)
