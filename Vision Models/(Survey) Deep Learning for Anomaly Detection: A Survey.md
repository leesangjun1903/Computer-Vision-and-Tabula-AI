# Deep Learning for Anomaly Detection: A Survey 

## 1. 핵심 주장 및 주요 기여  
이 논문은 **딥러닝 기반 이상 탐지(Deep Anomaly Detection, DAD)** 기법들을 체계적으로 분류·정리하고, 다양한 응용 분야에서의 성능·한계를 비교·분석한 종합적 리뷰를 제시한다.  
- 주요 기여  
  1. DAD 기법을 **감독(Supervised), 준감독(Semi-supervised), 비감독(Unsupervised), 하이브리드(Hybrid), 원클래스(One-Class NN)** 다섯 범주로 분류  
  2. 각각의 기법별 **기본 원리, 네트워크 구조, 계산 복잡도, 장단점**을 상세 비교  
  3. **컨텍스추얼(contextual), 포인트(point), 그룹(group)** 이상 탐지 유형을 DAD 기법 관점에서 재분류  
  4. **Hybrid 모델**과 **One-Class Neural Network(OC-NN)**을 새로운 범주로 포함시켜, DAD 모델 학습 목표에 따른 구분 제안  
  5. 주요 **응용 분야**(네트워크 침입, 금융·의료·산업 이상, 시계열, 영상 감시 등)별 사례·성능 분석  

## 2. 해결 과제 및 제안 방법  

### 2.1 해결하고자 하는 문제  
- 전통적 통계·머신러닝 이상 탐지는 고차원·비선형 데이터 처리에 한계  
- 라벨링된 이상 데이터 확보가 어렵고, 이상 패턴이 지속적으로 변화  
- 응용 도메인별 특성(시계열·이미지·로그·그래프 등) 차이에 따른 범용적 프레임워크 부재  

### 2.2 제안하는 DAD 기법 분류  
1. **감독(Section 10.1)**  
   - 일반 이진/다중 클래스 분류기로 이상 탐지  
   - 손실 함수: 교차 엔트로피  
2. **준감독(Section 10.2)**  
   - 정상 클래스만 라벨 사용, Autoencoder 기반 재구성 오류 활용  
   - 손실: $$\mathcal{L} = \|x - \hat x\|^2$$  
3. **비감독(Section 10.5)**  
   - 데이터 내재 속성(거리·밀도)만 이용  
   - 대표적 모델: Autoencoder, Variational AE, GAN  
4. **하이브리드(Section 10.3)**  
   - Deep 네트워크로 특징 추출 후 전통 기법(SVM, OC-SVM, SVDD)에 연결  
   - 예: Autoencoder+OC-SVM  
5. **원클래스 신경망(OC-NN, Section 10.4)**  
   - 네트워크 내부 표현 학습과 원클래스 목적함수(하이퍼플레인·하이퍼스피어) 결합  
   - Objective 예:  

$$
       \min_{w,b} \tfrac{1}{2}\|w\|^2 + \tfrac{1}{\nu n}\sum_i \max\{0,\,b - f(x_i)\} - b  
     $$  
     
  (Chalapathy et al. 2018)

### 2.3 모델 구조  
- **Autoencoder 계열**: 입력→인코더(FC/CNN/RNN)→잠복공간→디코더→재구성  
- **Variational AE**: 잠복 공간 분포 학습을 위해 KL 발산 항 추가  
- **GAN-AD**: Generator/Discriminator로 정상 분포 모델링, 이상 점수는 재구성·판별 결과 활용  
- **OC-NN**: 네트워크 끝단에 원클래스 판별 층(거리 기반) 삽입  

### 2.4 성능 향상 기법  
- **하이브리드 모델**: 딥 특징+SVM 결합으로 차원 축소와 경계 학습 분리  
- **OC-NN**: 표시 학습(objective-driven representation)으로 이상 탐지 특화된 특징 학습  
- **GAN-AD**: 복잡한 정상 분포 모델링으로 고차원 데이터 이상점 검출 강화  
- **구조적 변형**(Spatio-Temporal, Sequence, Attention)으로 시계열·영상의 컨텍스트 보존  

### 2.5 한계  
- **라벨 부족**: 감독·준감독 기법은 비정상 라벨 획득 어려움  
- **계산 비용**: 딥 네트워크와 전통 기법 결합 시 이중 학습 부담  
- **과적합 위험**: 이상이 희소한 상황에서 복잡 모델이 노이즈 학습  
- **해석성 부족**: 블랙박스 특성으로 탐지 근거 설명 어려움  

## 3. 일반화 성능 향상 관점  
- **One-Class Objective**: OC-NN은 잠복층 표현이 이상 탐지 목적함수에 직접 연결되어, 도메인 변화에 대한 **표현력 강화**  
- **정규화·가중치 공유**: Variational AE, Adversarial AE 등 분포 정규화 항 추가로 모델 **적응성** 증가  
- **Ensemble 기법**: Autoencoder 앙상블로 과적합 저감 및 노이즈 견고성 확보  
- **Transfer Learning**: 대규모 사전학습 모델 특징 전이로 **데이터 희소성** 극복  
- **Attention Mechanism**: 시계열·로그 등 순차 데이터에서 중요한 시점 강조로 **노이즈 민감도**↓  

## 4. 향후 연구 영향 및 고려 사항  
- **표현 학습 vs. 탐지 목표 통합**: OC-NN과 같이 목표 지향적 표현 학습이 이상 탐지 성능을 크게 향상  
- **설명 가능성 강화**: 이상 탐지 판단 근거를 제공하는 해석 가능한 딥모델 연구 필요  
- **적은 라벨·도메인 변화**: 준/비감독·제로샷 학습을 결합한 라벨 적은 환경에서의 적응형 프레임워크 개발  
- **실시간·임베디드 적용**: 계산 효율성을 고려한 경량·온디바이스 DAD 모델 설계  
- **멀티모달 통합**: 이미지·시계열·그래프 등 다양한 데이터 속성 결합으로 복합 이상 시나리오 대응  

> 본 설문은 DAD 분야의 **다양한 딥러닝 기법**을 명확히 분류·비교하고, 특히 **목표함수와 표현 학습의 통합**이 일반화 성능을 결정짓는 핵심임을 강조함으로써, 향후 연구 방향의 이정표를 제시한다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/ab199c69-276e-44b9-b6d4-95c62e2f1b0e/1901.03407v2.pdf

# 10. Deep Anomaly Detection (DAD) Models

이 장에서는 **라벨 유무**와 **학습 목적**에 따라 DAD 기법을 다섯 가지 범주로 나누어, 각 모델의 전제·아키텍처·계산 복잡도·장단점을 상세히 설명한다.

***

## 10.1 감독(슈퍼바이즈드) DAD  
*전제*  
- 정상·이상 양쪽 클래스에 대한 **충분한 라벨**이 존재  
- 다중 클래스 분류를 통해 “이상”을 하나의 클래스 또는 소수 클래스 집합으로 학습  
- **교차엔트로피 손실**로 경계 학습  

*아키텍처*  
- 일반적 분류망(CNN/RNN/FC)  
- 입력→특징추출층(여러 합성곱·순환·완전연결 층)→소프트맥스 출력(이상·정상)  

*계산 복잡도*  
- 학습: $$O(N \times D \times L)$$,  
  - $$N$$: 라벨 샘플 수, $$D$$: 입력 차원, $$L$$: 층 수  
- 추론: $$\approx O(D \times L)$$  

*장점*  
- 충분한 라벨 확보 시 **최고 성능**  
- 학습 후 **실시간 분류 속도** 우수  

*단점*  
- 이상 라벨 수집이 **사실상 불가능**한 도메인 많음  
- **불균형**(정상≫이상) 시 과적합 및 성능 저하  

***

## 10.2 준감독(세미슈퍼바이즈드) DAD  
*전제*  
- **정상 클래스** 라벨만 다수 확보 가능  
- 정상만 재구성·특징 학습 → 재구성 오류가 큰 샘플을 이상으로 판별  
- 대표 모델: Autoencoder 기반  

*아키텍처*  
- 입력→인코더(FC/CNN/RNN)→잠복공간 코드→디코더→재구성  
- 손실: $$\mathcal{L}_{rec} = \|\,x - \hat x\,\|^2$$  

*계산 복잡도*  
- 학습: $$O(N_{norm}\times D\times L)$$  
- 추론: 재구성 오류 계산 $$\approx O(D\times L)$$  

*장점*  
- 이상 라벨 없어도 정상 모델 학습만으로 **높은 탐지율**  
- 라벨 수집 부담 완화  

*단점*  
- 정상 경계 정의 오류 시 **높은 오탐률**  
- 잠복공간 축소 차원 수 하이퍼파라미터 **민감**  

***

## 10.3 하이브리드 DAD  
*전제*  
- 딥 네트워크를 **특징 추출기**로 활용  
- 추출된 특징을 **전통적 이상 탐지**(OC-SVM, SVDD) 기법에 입력  

*아키텍처*  
1. **Autoencoder+OC-SVM**  
2. **CNN→특징벡터→One-Class SVM**  
3. **사전학습된 전이모델(ResNet)→SVDD**  

*계산 복잡도*  
- 딥 특징 추출: $$O(D\times L)$$  
- SVM 예측: $$O(d\times n_{sv})$$ ($$d$$: 특징 차원, $$n_{sv}$$: 서포트벡터 수)  

*장점*  
- 고차원 데이터를 저차원 특징 공간으로 **효율적 축소**  
- 기존 SVM 성능 레버리지  

*단점*  
- 특징 학습과 이상탐지 목표가 **분리** → 표현력 최적화 불가  
- 하이퍼파라미터 탐색 비용 이중  

***

## 10.4 원클래스 신경망(OC-NN)  
*전제*  
- 정상 데이터 분포 경계 학습을 위한 **원클래스 목적함수**와 딥 표현 학습을 **통합**  
- 하이퍼스피어(Deep SVDD) 또는 하이퍼플레인(Deep One-Class)  

*아키텍처*  
- 입력→다중 은닉층→출력 뉴런 하나  
- 손실(Deep SVDD 예시):  

$$
    \min_{W}\;\tfrac{1}{n}\sum_{i=1}^n \bigl\|\,\phi_W(x_i)-c\bigr\|^2
    \quad+\;\lambda\|W\|^2
  $$  
  
  - $$\phi_W$$: 네트워크 매핑, $$c$$: 중심, $$\lambda$$: 정규화  

*계산 복잡도*  
- 학습: $$O(N\times D\times L)$$  
- 추론: $$O(D\times L)$$  

*장점*  
- 표현 학습과 **이상 경계 학습의 동시 최적화**  
- 정상 분포에 특화된 특징 추출  

*단점*  
- 고차원 데이터일수록 학습·업데이트 **시간 증가**  
- 경계 초기화(초기 $$c$$) 민감  

***

## 10.5 비감독(Unsupervised) DAD  
*전제*  
- 데이터 자체 속성만(밀도·거리) 사용  
- 대다수가 정상이라는 **희소성 가정**  
- 대표 모델: Autoencoder, VAE, GAN, SPN 등  

*아키텍처*  
- **Autoencoder**: 입력↔재구성  
- **VAE**: KL 발산 항 추가  
- **GAN-AD**: Generator/Discriminator 공동 학습  
- **SPN**: 합·곱 노드 그래프  

*계산 복잡도*  
- 비선형 최적화(비볼록) → 딥 모델 레이어 수·매개변수에 비례  

*장점*  
- **라벨 없이** 학습 가능  
- 다양한 데이터 특성 내재적 활용  

*단점*  
- 노이즈 민감 → **오탐률 ↑**  
- 잠복공간 차원 선택 어려움  

***

## 10.6 기타 유망 기법  
1. **전이학습(Transfer Learning)**  
   - 대용량 사전학습 특징 전이로 **라벨 부족** 극복  
2. **제로샷 학습(Zero-Shot)**  
   - 속성·메타데이터로 사전 정의되지 않은 이상 탐지  
3. **앙상블(Ensemble)**  
   - 랜덤 연결 Autoencoder 다수 결합 → **과적합 저감**  
4. **클러스터기반**  
   - Deep 특징+클러스터링 → **새로운 이상 패턴** 탐지  
5. **강화학습(DRL)**  
   - 보상 지표로 이상 탐지 에이전트 자기 학습  
6. **통계적 기법**  
   - 웨이블릿+힐버트 변환+NN 순차 결합 → **실시간 이상 감지**  

***

### 결론  
- **라벨 가용성**, **탐지 목적**에 맞춰 모델 선택  
- **OC-NN**처럼 표현 학습과 탐지 목표 통합이 일반화 성능 핵심  
- 향후 **해석 가능성**, **실시간·경량화**, **라벨 적은 환경** 대응 연구 필요

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/ab199c69-276e-44b9-b6d4-95c62e2f1b0e/1901.03407v2.pdf

