# RIS-GAN: Explore Residual and Illumination with Generative Adversarial Networks for Shadow Removal | Shadow removal

**핵심 주장**  
RIS-GAN은 그림자 제거 과제에서 잔차(residual)와 역조명(inverse illumination) 정보를 동시에 학습·활용함으로써, 기존 방식보다 더욱 정교하고 일관된 그림자 없는 이미지 복원을 달성할 수 있음을 보인다.

**주요 기여**  
1. **잔차와 조명의 통합적 활용**: 그림자 이미지로부터 음(negative) 잔차 $$I_{res}=G_{res}(I)$$와 역조명 맵 $$S_{inv}=G_{illum}(I)$$을 추정한 뒤, 이를 입력 그림자 이미지 $$I$$와 곱셈·덧셈 연산으로 결합하여 간접 제거 결과를 생성하고 최종 정교화(refinement) 단계에서 통합함.  
2. **코스 투 파인(coarse-to-fine) 구조**:  
   - **잔차 생성기** $$G_{res}$$  
   - **조명 생성기** $$G_{illum}$$  
   - **일차 제거 생성기** $$G_{rem}$$  
   - **정교화 생성기** $$G_{ref}$$  
   네 개의 동일한 DenseUNet 기반 인코더-디코더 구조로 구성.  
3. **교차 손실(cross loss) 설계**: 음 잔차 및 역조명과 제거 결과 간 일관성을 유도하는 손실  

```math
   L_{cross} = \|I_{gt} - (G_{res}(I)\oplus I)\|_1 + \beta_2\,\|I_{gt} - (G_{illum}(I)\otimes I)\|_1.
``` 

4. **공유 파라미터 기반 공동 판별자(joint discriminator)**: 잔차, 제거 결과, 조명 생성 결과를 동시에 판별하도록 설계하여 생성물 전반의 질을 균일하게 향상.

***

## 1. 해결 문제와 제안 방법

### 1.1 해결하고자 하는 문제  
- 기존 전통 기법은 경계부 아티팩트가 심하고, 딥러닝 방식은 색상 변환에만 집중하여 경계 불일치나 잔여 그림자가 남는 한계가 있음.  
- 그림자 제거 과정에서 *잔차*와 *조명* 정보를 별도로 추정·활용하지 않는 한계를 극복.

### 1.2 제안 방법  
1. **음 잔차 및 역조명 예측**  
   - Residual generator: $$I_{res}=G_{res}(I)$$,  
   - Illumination generator: $$S_{inv}=G_{illum}(I)$$.  
2. **간접 그림자 제거**  

```math
     I^{(1)}_{rem} = I \oplus I_{res}, 
     \quad
     I^{(2)}_{rem} = I \otimes S_{inv}.
```

3. **중간 제거 및 정교화**  
   - Coarse removal: $$I_{coarse}=G_{rem}(I)$$.  
   - Refinement: $$I_{fine}=G_{ref}(I_{coarse}, I^{(1)}\_{rem}, I^{(2)}_{rem})$$.  
4. **손실 함수**  

$$
   L = \lambda_1 L_{res} + \lambda_2 L_{rem} + \lambda_3 L_{illum} + \lambda_4 L_{cross} + L_{adv},
   $$
   
   - $$L_{res}=\|I^{gt}\_{res}-G_{res}(I)\|_1$$,  
   - $$L_{illum}=\|S^{gt}\_{inv}-G_{illum}(I)\|_1$$,  
   - $$L_{rem}=L_{vis} + \beta_1 L_{percept}$$,  
   - $$L_{adv}$$: 잔차·조명·제거 생성물에 대한 joint discriminator의 적대적 손실.

***

## 2. 모델 구조  

- **공통 구조**: 모든 생성기는 DenseUNet(인코더-디코더 + Dense Block) 사용.  
- **판별기**: 4×4 커널, 5개 합성곱층, 스펙트럴 정규화, Leaky ReLU, 공유 파라미터로 잔차·조명·제거 결과 판별.

***

## 3. 성능 향상 및 한계  

### 3.1 성능 향상  
- **SRD 데이터셋**: 전체 RMSE 6.78 (기존 최고 7.83 대비 개선)  
- **ISTD 데이터셋**: 전체 RMSE 6.95 (기존 최고 7.10 대비 개선)  
- **사용자 연구**: 29.65% 선호율로, 경쟁 기법 대비 1.5배 이상 높은 선택률 기록.  

### 3.2 한계  
- **프레임 단위 처리**: 영상 처리 시 각 프레임 독립 처리로 연속성·일관성 부족.  
- **복잡한 조명 변화**: 학습 데이터와 유사한 환경에서는 우수하나 극단적 조명·색 온도 변화에는 성능 저하 가능.  
- **고해상도 입력**: 입력 사이즈 256×256에 최적화되어, 고해상도 일반화에는 추가 구성이 필요.

***

## 4. 일반화 성능 향상 관점  

- **잔차/조명 분리 학습**: 도메인 변화에도 잔차와 조명 패턴을 독립적으로 추출하므로, 미리 학습한 잔차·조명 네트워크를 타 도메인(비디오, 야간 촬영)에도 전이 학습 가능.  
- **코스 투 파인 구조**: 중간 제거와 정교화 단계 분리로, 첫 단계에서 전역 구조를, 후반부에서 세부 텍스처를 보강하여 다양한 장면에도 유연하게 대응.  
- **joint discriminator**: 생성물 전반의 특징을 통합 평가하므로, 데이터 분포 변화에 따른 품질 일관성 유지에 기여.

***

## 5. 향후 연구에 미치는 영향 및 고려 사항  

- **연속적 영상 그림자 제거**: 프레임 간 시계열 일관성을 보장하는 Temporal GAN 또는 Optical Flow 기반 모듈 통합 연구 필요.  
- **타 저해상·다채널 도메인 확장**: 저조도, 열화상, 다채널 스펙트럴 영상에도 잔차-조명 분리 접근 적용 가능성 탐색.  
- **리얼월드 데이터셋 구축**: 극단적 조명·반사 환경을 포괄하는 대규모 데이터셋 확보가 모델 일반화 성능 향상 관건.  
- **경량화·실시간 처리**: 모바일·임베디드 적용을 위한 네트워크 압축 및 지연 저감 전략 연구 필요.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/1694aea4-794c-4f7c-88c4-2755d07c061f/1911.09178v2.pdf)
