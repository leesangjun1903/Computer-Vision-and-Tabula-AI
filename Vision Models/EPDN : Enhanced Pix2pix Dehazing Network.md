# EPDN : Enhanced Pix2pix Dehazing Network | Image generation

**핵심 주장**  
Enhanced Pix2pix Dehazing Network(EPDN)는 전통적 물리 기반 산란 모델에 의존하지 않고, 조건부 생성 적대 신경망(GAN)을 이용해 “이미지→이미지 번역” 방식으로 단일 이미지 디헤이징을 수행함으로써 색 왜곡과 디테일 손실 문제를 동시에 극복한다.

**주요 기여**  
- **모델 무관성**: 물리적 산란 모델의 전이 맵과 대기광 추정이 불필요한, 순수 데이터 기반 디헤이징 프레임워크 제안.  
- **글로벌-퍼스트 구조**: 글로벌 해상도 생성기(global sub-generator)와 지역 해상도 생성기(local sub-generator)를 결합하여 거시적 구조→미시적 디테일 순으로 복원.  
- **Enhancer 블록**: 수용 영역 이론에 기반한 다중 스케일 피라미드 풀링 블록을 두 차례 적용, 색상·텍스처·윤곽선 디테일을 강화.  
- **통합 학습 스킴**: GAN의 적대적 손실과 피처 매칭 손실, VGG 기반 지각 손실(perceptual loss), 픽셀 단위 충실도 손실(fidelity loss)을 교대로 최적화하는 훈련 알고리즘(A LGORITHM 1) 설계.  
- **지각지수(PI) 도입**: “주관적 시각 품질”을 수치로 환산하는 PI 지표를 디헤이징에 최초로 도입·평가.  

***

## 1. 해결하고자 하는 문제  
기존 단일 이미지 디헤이징 방법은 대체로 물리적 산란 모델  

$$
I(z) = J(z)\,t(z) + A(z)\,\bigl(1 - t(z)\bigr)
$$  

에 의존하며, 전이 맵 $$t(z)$$과 대기광 $$A(z)$$ 추정의 정확도가 결과 화질을 좌우한다. 모델 기반·사전 기반(prior-based) 접근법은 실제 환경에서 쉽게 위배되는 한계가 있고, 많은 딥러닝 기법조차 물리 모델을 전제로 한다.  

EPDN는 “디헤이징 = 이미지를 깨끗한 스타일로 번역”이라는 관점으로 문제를 재정의해, 물리 기반 제약에서 완전히 독립시킨다.  

***

## 2. 제안하는 방법

### 2.1 모델 구조  
EPDN은 세 파트로 구성된다 (그림 2 참조).

1. **Multi-resolution Generator**  
   - 글로벌 서브-제너레이터 $$G_1$$: 입력 이미지를 2× 축소 후 처리해 거시 구조 생성.  
   - 로컬 서브-제너레이터 $$G_2$$: 원본 스케일에서 $$G_1$$ 출력과 결합해 디테일 보완.  

2. **Enhancer 모듈**  
   - 두 개의 **Enhancing Block**:  
     - 각 블록은 3×3 컨볼루션→4×,8×,16×,32× 스케일 다운샘플링된 피라미드 구축→1×1 컨볼루션(채널 어텐션)→업샘플링→피처 합친 뒤 3×3 컨볼루션 수행.  
     - 첫 블록 입력은 원본+제너레이터 피처, 두 번째는 첫 블록 출력에만 의존.  

3. **Multi-scale Discriminator**  
   - $$D_1$$, $$D_2$$: 입력 해상도의 1×, 2× 다운샘플 이미지를 각각 평가해, 전역·국부 특성을 동시에 감독.  

### 2.2 손실 함수  

```math
L_{\text{EPDN}}
= L_{A}
+ \lambda\,L_{\text{FM}}
+ \lambda\,L_{\text{VGG}}
+ L_{F}
```

- **Adversarial loss** $$L_A$$: $$\sum_{k=1}^2 \mathbb{E}\_{X}\bigl[\log D_k(X)\bigr] + \mathbb{E}_{\hat X}\bigl[\log(1 - D_k(G(\hat X)))\bigr]$$.  
- **Feature Matching loss** $$L_{\text{FM}}$$: 판별기 내부 피처 맵 간 L1 차이.  
- **Perceptual loss** $$L_{\text{VGG}}$$: VGGNet i층 활성화 차이 L1.  
- **Fidelity loss** $$L_F = \lVert X - \hat Y\rVert_2^2$$.  

### 2.3 훈련 알고리즘 (Algorithm 1)  
1. GAN 모듈($$G$$, $$D_1$$, $$D_2$$) 업데이트: 적대적 + 피처 매칭 손실  
2. Generator+Enhancer 업데이트: 지각 손실 + 충실도 손실  
이 과정을 번갈아 반복해 **global-first**∙**fine-detail**를 동시에 학습.  

***

## 3. 성능 향상 및 한계

### 3.1 성능 향상  
- **합성 데이터(SOTS)**  
  - Indoor: PSNR 25.06 dB, SSIM 0.9232 (기존 최고 대비 +2.76 dB, +0.0432)  
  - Outdoor: PSNR 22.57 dB (최고), SSIM 0.8630 (2위), PI 2.3858(2위)  

- **실세계 데이터**  
  - 합성 학습만으로도 실제 안개·스모그 제거에 견고한 성능.  
  - 시각적 품질(PI) 및 디테일 복원 우수.  

### 3.2 한계  
- **과도한 후방 헤이즈**: 매우 짙은 안개 장면에서는 물체 경계 복원이 불안정(그림 7).  
- **Enhancer 확장 필요**: 더 복잡한 다중 스케일 블록 또는 어텐션 메커니즘으로 보완 가능.  

***

## 4. 일반화 성능 향상 관점

- **물리 모델 독립성**으로 학습 데이터와 실제 촬영 환경 간 도메인 갭 감소.  
- **강력한 지각 손실**과 **피처 매칭** 조합이 디테일 일반화에 기여.  
- **피라미드 풀링 Enhancer**가 다양한 스케일 특징을 포착, 미지 환경에도 적응성 향상.  
- 향후 도메인 적응(unsupervised domain adaptation) 기법 및 **자기 지도 학습** 결합으로, 실제 대규모 현장 이미지로 추가 파인튜닝 시 더욱 견고한 일반화 가능.  

***

## 5. 향후 연구에 미치는 영향 및 고려 사항

- **GAN 기반 디헤이징 연구 활성화**: 전통 모델 기반 접근에서 벗어나, 순수 데이터 주도로 미세 디테일을 복원하는 새로운 패러다임 제시.  
- **지각 지수(PI) 확장**: 영상 복원·초해상도 등 타 태스크에서도 주관적 품질 지표로서 표준화 기대.  
- **적응형 Enhancer 발전**: 동적 스케일 및 위치별 어텐션, 비디오 디헤이징으로 확장 연구.  
- **도메인 적응과 무감독 학습** 통합: 실세계 안개 영상 레이블 부족 문제 해결을 위한 반감독·무감독 학습 프레임워크 필요.  

향후 디헤이징 분야는 EPDN이 제시한 **모델 무관성**, **글로벌-퍼스트+미시적 디테일 강화 전략**을 기반으로, 더욱 강건하고 일반화된 딥러닝 솔루션 개발에 집중할 것으로 기대된다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/4bb3ea05-3d4a-47e9-bfde-8a25213511dd/Qu_Enhanced_Pix2pix_Dehazing_Network_CVPR_2019_paper.pdf)
