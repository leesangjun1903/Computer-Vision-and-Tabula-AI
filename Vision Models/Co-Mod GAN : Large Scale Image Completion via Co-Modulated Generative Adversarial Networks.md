# Co-Mod GAN : Large Scale Image Completion via Co-Modulated Generative Adversarial Networks | Image generation, Image inpainting

## 핵심 주장과 주요 기여

이 논문은 기존 이미지 완성(image completion) 방법들이 대규모 결손 영역 처리에 실패하는 근본적 한계를 해결하기 위해 **Co-Modulated GANs**를 제안합니다[1]. 주요 기여는 다음과 같습니다:

**핵심 기여:**
- **Co-modulation 접근법**: 조건부(conditional)와 무조건부(unconditional) 생성 모델 간의 격차를 해소하는 범용적 방법론 제시
- **P-IDS/U-IDS 평가 지표**: 기존 FID 대비 더 견고하고 인간 선호도와 높은 상관관계를 보이는 새로운 정량적 평가 방법
- **우수한 성능**: 품질과 다양성 측면에서 기존 최첨단 방법들을 능가하는 결과

## 해결하고자 하는 문제

**핵심 문제:**
기존의 모든 이미지 완성 알고리즘들이 **대규모 결손 영역**을 처리할 때 실패하는 현상입니다. 이는 근본적으로 충분한 생성 능력(generative capability)의 부족에서 기인합니다[1].

**기존 방법들의 한계:**
1. 조건부 변조(conditional modulation) 방법들은 확률적 생성 능력이 부족
2. 제한된 조건 정보만 사용 가능한 상황에서 일반화 성능이 떨어짐
3. 다양한 출력을 생성하지 못함

## 제안하는 방법: Co-Modulation

### 수학적 정식화

**기존 접근법들:**

1. **무조건부 변조**: $$s = A(M(z)) $$ [1]
2. **조건부 변조**: $$s = A(E(y)) $$ 

**제안하는 Co-modulation**:

$$ s = A(E(y), M(z)) $$ 

여기서:
- $$s $$: 스타일 벡터
- $$A $$: 학습된 아핀 변환
- $$E(y) $$: 조건부 입력에서 추출된 스타일 표현
- $$M(z) $$: 잠재 벡터에서 매핑된 확률적 스타일 표현

### 모델 구조

**핵심 아키텍처:**
- **조건부 인코더(E)**: 입력 이미지로부터 조건부 스타일 표현 추출
- **매핑 네트워크(M)**: 잠재 벡터를 확률적 스타일 표현으로 변환
- **생성 디코더(D)**: Co-modulated 스타일로 출력 이미지 생성

**스타일 변조 과정:**
입력 특성 맵이 스타일 벡터 $$s $$로 채널별 곱셈을 거친 후 컨볼루션을 통과하고, 가중치 정규화 단계 $$s'\_j = 1/\sqrt{\sum_{i,k}(s_i w_{ijk})^2} $$를 통해 단위 분산으로 정규화됩니다[1].

## 성능 향상

### 정량적 결과

**FFHQ 데이터셋:**
- P-IDS: 16.6% (기존 최고 0.9% 대비 큰 향상)
- U-IDS: 29.4% (기존 최고 8.6% 대비 향상)
- FID: 3.7 (기존 최고 17.4 대비 향상)

**Places2 데이터셋:**
- P-IDS: 13.3%
- U-IDS: 27.4%
- FID: 7.9

### P-IDS/U-IDS 평가 지표의 우수성

**기존 FID 대비 장점:**
1. **샘플링 크기에 대한 견고성**: 1k-10k 샘플에서 빠른 수렴
2. **미세한 차이 감지**: 29개 픽셀 수준의 미세한 변화도 감지
3. **인간 선호도와의 상관관계**: 0.870 (FID는 -0.765)

## 일반화 성능 향상

### Image-to-Image Translation 성능

**Edges to Photos:**
- Edges2Shoes: FID 38.5 (기존 최고 47.3 대비 향상)
- Edges2Handbags: FID 56.9 (기존 최고 76.0 대비 향상)

**COCO-Stuff (Labels to Photos):**
- SPADE와 유사한 FID (22.5) 달성
- P-IDS와 U-IDS에서 SPADE 대비 우수한 성능
- 사용자 연구에서 59.0% 선호도 획득

### 일반화 가능성의 핵심 요소

**고유한 확률성(Inherent Stochasticity):**
- 외부 손실 함수 없이도 자연스럽게 확률적 스타일 표현 활용
- Truncation parameter ψ를 통한 품질-다양성 trade-off 제어 가능
- 동일한 입력과 마스크에서도 다양한 결과 생성

## 한계점

**인식된 한계:**
1. **의미 정보 인식 실패**: 주변 영역의 의미적 정보를 인식하지 못해 이상한 artifacts 생성
2. **복잡한 장면 처리**: Places2와 같은 다양한 스타일과 품질을 가진 수백만 장면 데이터셋에서 특히 어려움
3. **조건부 대응 학습**: Edges2Shoes에서는 제한된 훈련 세트로 인해 다양성 학습 실패

## 향후 연구에 미치는 영향

### 긍정적 영향

**1. 방법론적 기여:**
- 조건부와 무조건부 GAN 간 격차 해소의 범용적 접근법 제시
- 다른 조건부 생성 작업에 쉽게 적용 가능한 프레임워크

**2. 평가 방법론 개선:**
- P-IDS/U-IDS를 통한 더 신뢰할 수 있는 정량적 평가 기준 제공
- 사용자 연구의 비용과 분산 문제 해결

**3. 실용적 응용:**
- 대규모 결손 영역 처리 능력으로 실제 응용 프로그램에서 활용도 증가
- Image-to-image translation 작업에서의 범용성 입증

### 향후 연구 고려사항

**1. 의미적 이해 강화:**
- 주변 맥락의 의미적 정보를 더 잘 이해할 수 있는 방법 연구 필요
- Attention mechanism이나 semantic segmentation과의 결합 고려

**2. 아키텍처 최적화:**
- Co-modulation에서 비선형 매핑 함수 탐구
- 더 효율적인 계산 방법 개발

**3. 평가 지표 발전:**
- P-IDS/U-IDS의 다른 도메인으로의 확장성 검증
- 더 다양한 생성 품질 측면을 포괄하는 종합적 평가 방법 개발

**4. 일반화 연구:**
- 다른 조건부 생성 작업(video generation, 3D synthesis 등)으로의 확장
- Few-shot learning 환경에서의 성능 검증

이 연구는 이미지 완성 분야의 근본적 한계를 해결하는 동시에, 조건부 생성 모델의 일반적인 프레임워크를 제시함으로써 향후 관련 연구들의 중요한 기반이 될 것으로 예상됩니다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/c649d7f3-4a5d-4819-b9bc-525f5df08059/2103.10428v1.pdf
