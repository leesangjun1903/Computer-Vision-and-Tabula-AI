## Denoising Diffusion Bridge Models

### 1. 핵심 주장과 주요 기여

**Denoising Diffusion Bridge Models (DDBMs)**는 기존 확산 모델의 한계를 극복하는 새로운 생성 모델링 프레임워크입니다.[1]

**핵심 주장:**
- 기존 확산 모델은 가우시안 노이즈를 전제로 하여 이미지-to-이미지 번역과 같은 작업에서 한계가 있음[1]
- DDBM은 두 개의 임의 분포 간 직접적인 매핑을 학습하여 더 일반적이고 효율적인 분포 변환을 제공함[1]
- 역시간 확산 브릿지 관점을 채택하여 기존 확산 모델의 설계를 재사용하고 일반화함[1]

**주요 기여:**
1. **통합된 이론적 프레임워크**: Score-based 확산 모델과 OT-Flow-Matching을 하나의 프레임워크로 통합[1]
2. **실용적 알고리즘**: Denoising Bridge Score Matching을 통한 확장 가능한 학습 방법[1]
3. **강력한 실증적 성능**: 이미지 번역 작업에서 baseline 대비 상당한 성능 향상[1]

### 2. 해결하고자 하는 문제와 제안 방법

**문제 정의:**
기존 확산 모델은 데이터를 가우시안 노이즈로 변환하는 것에만 특화되어 있어, 두 이미지 분포 간의 직접적인 번역에는 부적절함. 기존 해결책들은 이론적 근거가 부족하거나 계산 비용이 높음.[1]

**제안 방법:**

**3.1 시간 역전 SDE와 확률 흐름 ODE**

핵심 이론인 **Theorem 1**에서 조건부 확률 $$q(x_t | x_T)$$의 진화는 다음과 같은 역시간 SDE로 표현됩니다:

$$dx_t = [f(x_t, t) - g^2(t)(s(x_t, t, y, T) - h(x_t, t, y, T))]dt + g(t)d\hat{w}_t$$[1]

연관된 확률 흐름 ODE는:

$$dx_t = [f(x_t, t) - g^2(t)(\frac{1}{2}s(x_t, t, y, T) - h(x_t, t, y, T))]dt$$[1]

여기서 $$s(x, t, y, T) = \nabla_{x_t} \log q(x_t | x_T)$$는 학습해야 할 score function이고, $$h(x, t, y, T) = \nabla_{x_t} \log p(x_T | x_t)$$는 Doob's h-transform입니다[1].

**3.2 Denoising Bridge Score Matching**

**Theorem 2**는 핵심 학습 목적함수를 제공합니다:

$$L(\theta) = \mathbb{E}\_{x_t,x_0,x_T,t}[w(t)\|s_{\theta}(x_t, x_T, t) - \nabla_{x_t} \log q(x_t | x_0, x_T)\|^2]$$ [1]

이 목적함수의 최솟값은 $$s_{\theta}(x_t, x_T, t) = \nabla_{x_t} \log q(x_t | x_T)$$를 만족합니다[1].

### 3. 모델 구조와 일반화된 매개변수화

**샘플링 분포 설계:**
가우시안 전이 커널을 가진 확산 과정에서, 샘플링 분포는 다음과 같습니다:

$$q(x_t | x_0, x_T) = \mathcal{N}(\hat{\mu}_t, \hat{\sigma}_t^2 I)$$ [1]

여기서:
$$\hat{\mu}_t = \frac{SNR_T}{SNR_t}\frac{\alpha_t}{\alpha_T}x_T + \alpha_t x_0(1 - \frac{SNR_T}{SNR_t})$$[1]
$$\hat{\sigma}_t^2 = \sigma_t^2(1 - \frac{SNR_T}{SNR_t})$$[1]

**EDM 확장:**
EDM의 pred-x 매개변수화를 확장하여 분포 번역에 적용:
- $$c_{in}(t) = \frac{1}{\sqrt{a_t^2\sigma_T^2 + b_t^2\sigma_0^2 + 2a_tb_t\sigma_{0T} + c_t}}$$[1]
- $$c_{out}(t) = \sqrt{a_t^2(\sigma_0^2\sigma_T^2 - \sigma_{0T}^2) + \sigma_0^2c_t} \cdot c_{in}(t)$$[1]

### 4. 성능 향상 및 한계

**성능 향상:**

**이미지-to-이미지 번역 결과:**
- Edges→Handbags (64×64): FID 1.83 (VP), 2.93 (VE) vs. 최고 기존 방법 7.43[1]
- DIODE (256×256): FID 4.43 (VP), 8.51 (VE) vs. 최고 기존 방법 9.34[1]
- LPIPS와 MSE 메트릭에서도 상당한 개선 달성[1]

**무조건 생성 결과:**
- CIFAR-10: FID 2.06 vs. EDM 2.04 (거의 동등)[1]
- FFHQ-64×64: FID 2.44 vs. EDM 2.53 (소폭 개선)[1]

**핵심 개선사항:**
1. **Hybrid Sampler**: ODE와 SDE를 결합하여 블러리한 출력 문제 해결[1]
2. **일반화된 시간 역전**: 가이던스 강도 매개변수 $$w$$ 도입[1]
3. **VP vs VE 브릿지**: VP 브릿지가 일부 작업에서 VE보다 우수한 성능[1]

**한계:**

1. **잠재 공간 성능**: 잠재 공간 번역에서 Rectified Flow와 I2SB 대비 성능 저하[1]
   - Day→Night: FID 27.63 vs. Rectified Flow 12.38[1]
   - pred-x 매개변수화가 잠재 공간에 최적화되지 않음으로 분석[1]

2. **계산 복잡성**: 여전히 반복적 샘플링 과정 필요
3. **하이퍼파라미터 민감성**: VP 브릿지는 가이던스 매개변수에 크게 의존[1]

### 5. 일반화 성능 향상 가능성

**이론적 통합성:**
- 기존 Score-based 확산 모델과 OT-Flow-Matching을 특수 사례로 포함[1]
- 무조건 확산 과정, OT-Flow-Matching, Rectified Flow 모두 DDBM의 특수 사례임을 증명[1]

**설계 재사용성:**
- EDM의 아키텍처, 노이즈 스케줄, 샘플링 기법을 DDBM에 직접 적용 가능[1]
- 기존 확산 모델의 발전을 즉시 활용할 수 있는 프레임워크[1]

**확장 가능성:**
- VP와 VE 브릿지 모두 지원하여 다양한 응용에 적응[1]
- 픽셀 공간과 잠재 공간 모두에서 작동[1]

### 6. 미래 연구에 미치는 영향 및 고려사항

**긍정적 영향:**

1. **분포 번역의 표준 프레임워크**: DDBM이 이미지-to-이미지 번역 작업의 새로운 표준이 될 가능성[1]
2. **이론적 통합**: 다양한 생성 모델링 패러다임의 통합된 이해 제공[1]
3. **실용적 적용**: 의료 영상, 스타일 전송, 도메인 적응 등 다양한 분야 응용 가능[1]

**향후 연구 고려사항:**

1. **잠재 공간 최적화**: 잠재 공간에서의 성능 개선을 위한 전용 매개변수화 개발 필요[1]
2. **계산 효율성**: 더 빠른 샘플링 알고리즘 개발
3. **조건부 생성**: 텍스트나 다른 모달리티 조건부 생성으로의 확장
4. **이론적 분석**: 수렴성과 안정성에 대한 더 깊은 이론적 분석
5. **스케일링**: 대규모 데이터셋과 고해상도 이미지에 대한 확장성 연구

**결론적으로**, DDBM은 확산 모델의 일반화된 프레임워크를 제시하며, 특히 분포 간 변환 작업에서 혁신적인 성능을 보여줍니다. 이 연구는 생성 AI 시대에서 중요한 역할을 할 것으로 기대되며, 향후 연구자들은 제시된 한계점들을 개선하고 더 넓은 응용 분야로 확장하는 것을 고려해야 합니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/3f362a20-9a69-4da1-92dd-daf1d5663849/2309.16948v3.pdf)
