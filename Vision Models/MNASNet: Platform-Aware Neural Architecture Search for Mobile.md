# MnasNet: Platform-Aware Neural Architecture Search for Mobile | NAS. Image classification, Object detection

# 핵심 요약

**주장:** MnasNet은 모바일 기기에서 실제 추론 지연(latency)을 직접 측정해 이를 최적화 목표에 포함하는 플랫폼 인지형 신경망 구조 탐색(Neural Architecture Search)을 제안한다.  
**주요 기여:**  
1) 정확도와 실제 지연을 동시에 고려하는 다중 목적 최적화 보상 함수 도입  
2) 계층별 다양성을 확보하면서 탐색 공간 크기를 줄이는 ‘요소화 계층적 검색 공간(Factorized Hierarchical Search Space)’ 설계  
3) ImageNet 분류와 COCO 객체 검출에서 모바일 제약 하에 최첨단 성능 달성  

***

# 1. 해결하고자 하는 문제

기존 모바일 CNN 설계는  
- 수작업으로 연산량(FLOPS), 파라미터 수 등을 기준으로 설계하거나  
- NAS에서 FLOPS를 지연의 대리 지표로 삼았으나, 실제 모바일 하드웨어 지연과 큰 괴리가 발생  

MnasNet은 FLOPS 대신 **실기기에서 측정한 추론 지연**을 최적화 대상에 직접 포함해 **정확도–지연** 간의 실제 트레이드오프를 탐색하려 한다.

***

# 2. 제안 방법

## 2.1 다중 목적 보상 함수

모델 $$m$$의 정확도 $$ACC(m)$$, 지연 $$LAT(m)$$, 목표 지연 $$T$$일 때, 보상 $$R(m)$$은 다음과 같다:  

$$
R(m) = ACC(m)\times\biggl(\frac{LAT(m)}{T}\biggr)^{\,w}
$$  

$$
w = 
\begin{cases}
\alpha, & LAT(m)\le T\\
\beta,  & LAT(m)>T
\end{cases}
$$  

실험에서는 $$\alpha=\beta=-0.07$$를 사용해 지연 제약을 부드럽게 반영한다.  

## 2.2 요소화 계층적 검색 공간

- 네트워크를 블록 단위로 미리 정의된 해골(skeleton) 구조로 분할  
- 각 블록 당  
  - ConvOp: 일반/Depthwise/모바일 병목(conv)  
  - KernelSize: 3×3, 5×5  
  - SE 비율: 0, 0.25  
  - SkipOp: 풀링·아이덴티티·없음  
  - 채널 크기 스케일링(0.75, 1.0, 1.25)  
  - 반복 레이어 수 $$N_i$$  
- 블록별로 하나의 레이어 표현을 탐색하고, 이를 $$N_i$$회 반복  
- 탐색 공간 크기: $$S^B$$ (일반적인 per-layer 탐색 시 $$S^{B\times N}$$ 대비 대폭 감소)

## 2.3 탐색 알고리즘

- RNN 기반 컨트롤러가 토큰 시퀀스(아키텍처)를 샘플링  
- 각 모델을 ImageNet 데이터(5 에폭)로 학습해 정확도 측정, Pixel 1 CPU에서 지연 측정  
- PPO(Proximal Policy Optimization)로 컨트롤러 파라미터 갱신  
- 약 8천 모델 샘플, 상위 15개만 전체 학습 및 COCO 전이

***

# 3. 모델 구조

아래는 대표 모델 MnasNet-A1 개요이다:

| 블록 | 입/출력 해상도 | 주요 연산 (ConvOp, Kernel, SE) | 반복 수 |
|-----|---------------|--------------------------------|--------|
| 1   | 224×224→112×112 | SepConv (3×3)                  | 1      |
| 2   | 112×112→56×56  | MBConv6 (3×3)                  | 2      |
| 3   | 56×56→28×28    | MBConv3 (5×5) + SE             | 3      |
| …   | …              | …                              | …      |
| 최종| 7×7→1×1        | 풀링 → FC → Softmax            | –      |

- 모든 블록에서 블록마다 서로 다른 연산·커널·SE 유무가 독립적으로 탐색되어 **계층별 구조 다양성** 확보

***

# 4. 성능 향상

## 4.1 ImageNet 분류

| 모델                     | Top-1 정확도 | 지연 (ms) | 파라미터 | Mult-Adds |
|------------------------|------------|---------|--------|----------|
| MobileNetV2 [참고]       | 72.0%      | 75      | 3.4M   | 300M     |
| NASNet-A [참고]          | 74.0%      | 183     | 5.3M   | 564M     |
| **MnasNet-A1 (제안)**    | **75.2%**  | **78**  | 3.9M   | 312M     |

- 동일 대기시간 제약 하에서 MobileNetV2 대비 3.2%p↑, 1.04× 지연  
- NASNet-A 대비 1.2%p↑, 2.3× 빠름  

## 4.2 COCO 객체 검출

| 모델                                 | mAP  | 지연 (ms) | 파라미터 | Mult-Adds |
|-----------------------------------|-----|---------|--------|----------|
| SSD300 [참고]                        | 23.2| –       | 36.1M  | 35.2B    |
| MobileNetV2+SSDLite [참고]          | 22.1| 200     | 4.3M   | 0.8B     |
| **MnasNet-A1+SSDLite (제안)**       | **23.0** | **203** | 4.9M   | 0.8B     |

- SSD300 대비 7.4× 적은 파라미터, 42× 적은 Mult-Adds로 동등한 mAP  

***

# 5. 일반화 성능과 한계

- **찾아낸 아키텍처는 다양한 지연 제약에 맞춰 재탐색 가능**: 22ms 등 낮은 지연 목표에도 별도 NAS 수행으로 더 나은 정확도 달성  
- **계층 다양성** 덕분에 다양한 규모·입력 해상도에 걸쳐 MobileNetV2 대비 일관된 성능 우위 확인  
- **한계:**  
  - 대규모 NAS(64 TPUv2×4.5일)로 높은 연산 비용  
  - 검색 공간이 여전히 수천억 규모로, 컨트롤러 효율화 필요  

***

# 6. 향후 연구에 미치는 영향 및 고려사항

- **플랫폼 인지형 NAS:** 실제 하드웨어 특성을 직접 반영하는 NAS 프레임워크가 표준으로 자리잡을 전망  
- **효율적 검색 공간 설계:** 요소화 계층적 구조는 대형 모델뿐만 아니라 경량 모델 디자인에도 응용 가능  
- **자동화와 휴먼 인사이트 결합:** NAS가 제안한 아키텍처 특성을 분석해 **핸드크래프트 모델에도 적용**하거나, NAS 초기화에 활용하여 비용 절감  
- **추가 고려점:**  
  - 다양한 모바일 칩셋·컴파일러 환경에 대응한 지연 측정 자동화  
  - NAS 비용 절감을 위한 **지연 예측 모델** 통합  
  - **다중 태스크(분류·검출·세그멘테이션)** NAS로 범용성 확장  

MnasNet은 모바일 환경에 특화된 NAS 연구의 전형을 제시하며, 향후 경량·효율 모델 설계에 있어 핵심적 기준이 될 것이다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/c05fd73f-c10a-4e20-9a22-00b632a7b3ba/1807.11626v3.pdf
