# Learning Transferable Architectures for Scalable Image Recognition | NAS, Image classification

# 핵심 요약 및 기여

**Learning Transferable Architectures for Scalable Image Recognition** 논문의 핵심 주장은, 소규모 데이터셋(CIFAR-10)에서 효율적으로 검색된 **컨벌루셔널 셀(convolutional cell)** 구조를 설계 공간(NASNet search space)으로부터 자동으로 학습한 뒤, 이를 대규모 데이터셋(ImageNet)으로 **무조정 전이(transfer)** 하여도 최첨단 성능을 달성할 수 있다는 것이다. 주요 기여는 다음과 같다:[1]

1. **NASNet 검색 공간 설계**: 네트워크의 깊이 및 입력 크기와 독립적인 모듈식 셀 구조를 정의하여, 셀 구조만 검색하면 전체 아키텍처를 확장 가능하도록 설계했다.[1]
2. **효율적 아키텍처 검색**: CIFAR-10에서 500 GPU를 이용해 4일 만에 최적 셀을 찾아내며, 이전 방식 대비 약 7× 빠른 탐색 속도를 기록했다.[1]
3. **스케일 조정 가능 모델**: 발견된 셀을 반복 및 필터 수 조절만으로 다양한 연산량·파라미터 규모의 모델 패밀리를 생성하여, 모바일용 경량 모델부터 최고 성능 모델까지 모두 최적화할 수 있음을 보였다.[1]
4. **일반화 및 전이 학습 성능**: CIFAR-10에서 학습된 셀로 구성된 NASNet-A 모델이 ImageNet에서 82.7% top-1, 96.2% top-5 정확도를 달성하며, 기존 인간 설계 모델보다 1.2% 우수한 정확도 및 28% 연산량 절감을 동시에 이루었다.[1]

# 문제 정의 및 제안 방법

## 해결하고자 하는 문제  
- **대규모 이미지 분류**를 위한 최적 아키텍처 탐색은 연산 비용이 매우 크다.  
- 인간 전문가에 의존한 반복적 아키텍처 설계가 비효율적이며 **자동화된 아키텍처 검색**이 필요하다.

## 제안 방법  
1. **탐색 공간(NASNet search space) 구성**  
   - 네트워크를 동일 구조의 두 종류 셀(정상 셀 Normal Cell, 축소 셀 Reduction Cell) 반복으로 구성  
   - 각 셀은 B개의 블록(block)으로 구성되며, 각 블록은  
     1) 입력 히든 상태 선택, 2) 두 번째 히든 상태 선택,  
     3) 첫 번째 상태에 적용할 연산 선택, 4) 두 번째 상태에 적용할 연산 선택,  
     5) 두 결과를 합치는 방식(합연산 또는 채널 합치기) 선택  
   - 연산 후보: convolution, separable convolution, pooling 등 13종  
2. **Neural Architecture Search with RL**  
   - RNN 컨트롤러가 위 5단계 선택을 2×5B번 수행하여 셀 구조를 샘플링  
   - CIFAR-10으로 학습된 자식 네트워크의 검증 정확도를 보상으로 PPO(policy gradient)로 컨트롤러 업데이트  
3. **ScheduledDropPath 정규화 기법**  
   - 각 경로 드롭 확률을 학습 초기엔 낮게, 학습 말기로 갈수록 선형 증가시키는 방식으로 일반화 성능 개선  

수식:  

$$ \theta \leftarrow \theta + \alpha \nabla_\theta \log p_\theta(A) \cdot R(A) $$  

여기서 $$p_\theta(A)$$는 컨트롤러가 아키텍처 A를 생성할 확률, $$R(A)$$는 검증 정확도, $$\alpha$$는 학습률이다.[1]

# 모델 구조 및 성능 향상

| 데이터셋 | 모델                 | 파라미터 수 | 연산량(FLOPS) | Top-1 정확도 |
|----------|----------------------|-------------|---------------|--------------|
| CIFAR-10 | NASNet-A (7 @ 2304)  | 27.6M       | –             | 97.60% (오차율 2.40%) |
| ImageNet | NASNet-A (6 @ 4032)  | 88.9M       | 23.8B         | **82.7%**     |
| ImageNet | MobileNet-224        | 4.2M        | 569M          | 70.6%        |
| ImageNet | ShuffleNet (2x)      | ~5M         | 524M          | 70.9%        |
| ImageNet | NASNet-A (4 @ 1056)  | 5.3M        | 564M          | **74.0%**    |

- **CIFAR-10**: NASNet-A는 기존 최고 기록 2.56% 오차율 대비 2.40% 달성.[1]
- **ImageNet**: NASNet-A(6@4032) 모델이 단일 추론으로 82.7% top-1을 달성하며, Inception-ResNet-v2의 80.1% 대비 약 2.6%p 개선.[1]
- **경량 모델**: NASNet-A(4@1056)는 기존 MobileNet, ShuffleNet 대비 약 3.4%p 높은 74.0% top-1을 달성.[1]

# 한계 및 일반화 성능 향상 가능성

- **탐색 비용**: CIFAR-10에서조차 500 GPU×4일 소요로, 비용이 여전히 크다.  
- **랜덤 탐색 대비**: RL 기반 검색은 랜덤 검색보다 최고 모델 품질이 약 1%p 높지만, 랜덤 검색도 준수한 성능을 보였다.[1]
- **일반화 확대**: ScheduledDropPath가 주요 정규화 기법으로, 다양한 데이터셋·태스크(예: COCO 객체 검출)에서 전송 성능을 크게 끌어올렸다.[1]
- **셀 설계 제한**: 현재 탐색 공간의 연산 풀 및 블록 수 B는 고정되어 있어, 더 다양한 셀 구조를 아우르기 위해 탐색 공간 확장이 필요하다.  

# 향후 연구 방향 및 고려 사항

- **탐색 효율화**: 하드웨어 비용 감소를 위해 저비용 대체 기법(e.g., 한 번 학습된 셀 재활용, 지식 증류) 도입  
- **다양한 태스크 전이**: 분류 외에 세분화(segmentation), 비디오 처리 등으로 전이 범위 확대  
- **자가 정규화 기법 연구**: ScheduledDropPath 외 새로운 동적 경로 드롭 방식과 자동 튜닝 기법 개발  
- **탐색 공간 다각화**: 블록 수 B 및 연산 종류를 확장하여 보다 풍부한 아키텍처 표현력 확보  
- **환경 적응 학습**: 소규모 데이터셋에 맞춘 메타학습(meta-learning)을 결합해, 셀이 더욱 빠르게 최적화되도록 개선  

위 연구는 **모듈식 셀 설계**와 **대규모 전이 가능성**이라는 개념을 제시함으로써, 앞으로의 이미지 인식 아키텍처 자동화 연구에 토대를 마련했다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/1ce04e49-45bf-4848-bf12-8fd61b283d11/1707.07012v4.pdf)
