# Res2Net: A New Multi-scale Backbone Architecture | Image classification

## 1. 핵심 주장 및 주요 기여
Res2Net는 단일 잔차 블록 내에 계층적 잔차 연결을 도입하여 미세(그레뉼) 수준에서 **다중 스케일** 특징 표현을 강화하는 새로운 백본 모듈을 제안한다.  
- 기존 방식이 레이어 단위로만 스케일을 처리하는 데 반해, Res2Net은 한 블록 내부에서 여러 경로로 서로 다른 수의 3×3 필터 연산을 통과하도록 설계하여 수십~수백 가지의 유효 수용 영역(receptive field)을 생성한다.[1]
- 플러그인 가능한 모듈로서 ResNet, ResNeXt, DLA 등에 삽입해 일관된 성능 향상을 달성했으며, **스케일** 차원을 깊이(depth), 너비(width), 집합성(cardinality)에 더해 네 번째 핵심 설계 요소로 제시했다.

## 2. 문제 정의 및 제안 방법
### 2.1 해결하고자 하는 문제
- 자연 이미지의 객체와 그 문맥은 매우 다양한 크기로 존재하므로, CNN이 다양한 수용 영역을 유연히 학습해야 한다.  
- 기존 Inception, FPN, DLA 등 방법들은 레이어 간, 병렬 경로, 상·하향 해상도만 조합해 스케일을 확장하며, **단일 블록 내부**의 세분화된 스케일 처리는 부족했다.

### 2.2 Res2Net 모듈 구성  
1. 1×1 컨볼루션 후 채널을 s개의 균등 그룹 $$x_i $$로 분할.  
2. $$i=1 $$인 그룹은 그대로 $$y_1 = x_1 $$.  
3. $$i\ge2 $$인 그룹은 이전 출력과 더한 후 3×3 컨볼루션:  

$$
     y_i = 
     \begin{cases}
       x_1, & i=1;\\
       K_i(x_i + y_{i-1}), & 2 \le i \le s,
     \end{cases}
   $$  

여기서 $$K_i$$는 3×3 필터 연산.  
4. 모든 $$y_i$$를 채널 방향으로 연결(concatenate)한 뒤 1×1 컨볼루션으로 융합.  
   
이로써 단일 블록 내에서 통과하는 3×3 필터 개수에 따라 다양한 조합의 유효 수용 영역(스케일)이 생성된다(그레뉼-레벨 스케일).[1]

### 2.3 아키텍처 통합
- **카디널리티(group conv)**·**SE 블록** 등 기존 모듈과 결합 가능.  
- ResNet-50, ResNeXt-50, DLA-60 등과 동일한 FLOPs/파라미터 규모(≈4.2G FLOPs, ≈25M 파라미터)로 성능 비교.

### 2.4 성능 향상
| 모델                      | Top-1 에러 (%) | Top-5 에러 (%) |
|---------------------------|---------------|---------------|
| ResNet-50 (baseline)      | 23.85         | 7.13          |
| **Res2Net-50 (s=4)**      | **22.01**↑1.84| **6.15**↑0.98 |
| ResNeXt-50                | 22.61         | 6.50          |
| **Res2NeXt-50 (s=4)**     | **21.76**↑0.85| **6.09**↑0.41 |
| DLA-60                    | 23.32         | 6.60          |
| **Res2Net-DLA-60 (s=4)**  | **21.53**↑1.79| **5.80**↑0.80 |
| SENet-50                  | 23.24         | 6.69          |
| **SE-Res2Net-50 (s=4)**   | **21.56**↑1.68| **5.94**↑0.75 |

- CIFAR-100에서도 파라미터 절감 및 오차율 감소 확인(ResNeXt-29 대비 1.11% 개선).  
- 스케일 $$s$$ 증가에 따라 성능 향상 폭이 커지나, 너무 큰 $$s>6$$에서는 수용 영역 과잉으로 한계 도달.[1]

### 2.5 한계
- 블록 내부 연산이 순차적이므로 $$s$$가 커질수록 런타임이 소폭 증가(예: $$s=8$$에서 172ms vs. 149ms).[1]
- 지나치게 많은 스케일은 작은 해상도(CIFAR 수준)에서 유의미한 이득을 내기 어려움.  
- 단일 블록에서의 복잡성 증가가 전체 모델 압축, 경량화 전략과 직접 연계되지 않음.

## 3. 일반화 성능 향상 가능성
- **다양한 스케일 조합**이 특징 학습을 더욱 세밀화하여, 객체 크기 변동, 새로운 데이터 분포에서도 **강인한 표현**을 제공.  
- CAM 시각화에서 작은 객체와 큰 객체 모두 완전한 영역 커버리지 증가 확인 → **약지도(Semantic Segmentation), 검출, 분할** 등 다운스트림 과제에 일반화.  
- 실제 VOC·COCO 객체 검출, DeepLab 세그멘테이션, Mask R-CNN 인스턴스 분할, 키포인트 추정, Salient Object Detection 모두에서 1–4% 수준의 일관된 성능 향상 입증.[1]

## 4. 향후 연구 영향 및 고려사항
- Res2Net의 **스케일 차원** 개념은 더 경량화한 모바일 네트워크(ShuffleNet 등)나 Transformer 기반 백본에도 적용 가능.  
- **스케일 최적화**: 데이터셋 해상도·도메인에 맞춰 $$s$$를 동적으로 조정하거나, 스케일별 어텐션을 도입해 효율을 극대화하는 후속 연구 필요.  
- **압축·가속화**: 순차적 구조로 인한 병목 해소를 위해 병렬화 기법, 하드웨어 친화적 설계 고려.  
- **이론적 이해**: 그레뉼 스케일이 표현 학습에 미치는 정량적 영향 분석 및 일반화 이론 정립이 요구됨.

***

 Res2Net: A New Multi-scale Backbone Architecture, IEEE Trans. PAMI, 2021.[1]

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/2137d525-76af-43ad-81bf-f5c66df6528a/1904.01169v3.pdf
