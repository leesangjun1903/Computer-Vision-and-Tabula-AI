# Twins: Revisiting the Design of Spatial Attention in Vision Transformers | Image classification, Semantic segmentation, Object detection
## 1. 핵심 주장과 주요 기여
### 핵심 주장
이 논문은 **Vision Transformer에서 공간적 주의(spatial attention) 메커니즘의 설계가 핵심적 성공 요인**이라는 관점에서 시작합니다. 저자들은 기존의 복잡한 설계 없이도 **단순하면서 효과적인 공간적 주의 메커니즘**을 통해 우수한 성능을 달성할 수 있음을 입증합니다.

### 주요 기여
1. **공간적 주의 메커니즘의 체계적 재검토**: 기존 PVT와 Swin Transformer의 성능 차이가 주로 위치 인코딩 방식에 기인함을 발견
2. **두 가지 효율적인 아키텍처 제안**: Twins-PCPVT와 Twins-SVT
3. **조건부 위치 인코딩(CPE)의 효과성 입증**: 절대 위치 인코딩 대신 CPE 사용으로 성능 향상
4. **공간적 분리 가능 자기 주의(SSSA) 설계**: 지역 주의와 전역 주의를 효율적으로 결합

## 2. 해결 문제와 제안 방법
### 해결하고자 하는 문제
**주요 문제점들:**
1. **계산 복잡도**: Vision Transformer의 자기 주의 연산이 이미지 픽셀 수에 대해 이차적 복잡도 $$O(H^2W^2d)$$를 가짐
2. **제한된 수용 영역**: 지역적 윈도우 기반 주의는 다른 윈도우 간 연결 부족으로 수용 영역이 제한됨
3. **배포의 어려움**: Swin Transformer의 shifted window 연산이 실제 배포 환경(ONNX, TensorRT)에서 최적화되지 않음
4. **위치 인코딩 문제**: 절대 위치 인코딩이 다양한 입력 크기 처리 시 한계

### 제안 방법
#### 2.1 Twins-PCPVT
PVT의 절대 위치 인코딩을 CPVT의 조건부 위치 인코딩(CPE)으로 교체:
- **위치 인코딩 생성기(PEG)**: 각 스테이지의 첫 번째 인코더 블록 후에 배치
- **2D 깊이별 합성곱**: 배치 정규화 없이 사용하여 CPE 생성

#### 2.2 Twins-SVT: 공간적 분리 가능 자기 주의(SSSA)

**지역 그룹 자기 주의(LSA):**
특징 맵을 $$m \times n$$ 서브 윈도우로 분할하여 각 윈도우 내에서만 주의 계산:

$$
\text{복잡도} = O\left(\frac{H^2W^2d}{mn}\right) = O(k_1k_2HWd)
$$

여기서 $$k_1 = \frac{H}{m}, k_2 = \frac{W}{n}$$

**전역 서브샘플 주의(GSA):**
각 서브 윈도우에서 대표값을 추출하여 전역 정보 교환:

$$
\text{복잡도} = O\left(\frac{H^2W^2d}{k_1k_2}\right)
$$

**전체 SSSA 복잡도:**

$$
\text{총 복잡도} = O\left(\frac{H^2W^2d}{k_1k_2} + k_1k_2HWd\right)
$$

최적값은 $$k_1 \cdot k_2 = \sqrt{HW}$$일 때 달성되며, 실제 구현에서는 $$k_1 = k_2 = 7$$ 사용.

**SSSA 연산 수식:**

```math
\begin{aligned}
\hat{z}^l_{ij} &= \text{LSA}(\text{LayerNorm}(z^{l-1}_{ij})) + z^{l-1}_{ij} \\
z^l_{ij} &= \text{FFN}(\text{LayerNorm}(\hat{z}^l_{ij})) + \hat{z}^l_{ij} \\
\hat{z}^{l+1} &= \text{GSA}(\text{LayerNorm}(z^l)) + z^l \\
z^{l+1} &= \text{FFN}(\text{LayerNorm}(\hat{z}^{l+1})) + \hat{z}^{l+1}
\end{aligned}
```

### 모델 구조
**Twins-PCPVT 구조:**
- 4단계 피라미드 구조 (PVT와 동일)
- 각 단계마다 PEG 삽입
- 전역 주의만 사용하되 CPE로 위치 정보 처리

**Twins-SVT 구조:**
- 4단계 피라미드 구조
- 1-3단계: LSA와 GSA 교대 배치
- 4단계: GSA만 사용 (해상도가 낮아서)
- 각 단계별 서브샘플링 크기 조정 (7→4→2→1)

## 3. 성능 향상 및 일반화 능력
### 성능 향상 결과
**ImageNet-1K 분류:**
- Twins-PCPVT-S: PVT-Small 대비 **+1.4%** 향상 (79.8% → 81.2%)
- Twins-SVT-S: Swin-T 대비 **35% FLOPs 감소**하면서 **+0.4%** 향상

**ADE20K 세그멘테이션:**
- Twins-PCPVT-S: PVT-Small 대비 **+4.5% mIoU** 향상 (39.8% → 44.3%)
- Twins-SVT-S: Swin-T 대비 **+1.7% mIoU** 향상하면서 **19% FLOPs 감소**

**COCO 객체 탐지:**
- RetinaNet 기준: Twins-PCPVT-S가 PVT-Small 대비 **+2.6% mAP** 향상
- Mask R-CNN 기준: **+2.5% mAP** 향상

### 일반화 성능 향상 가능성
**1. 다양한 해상도 적응성**
- CPE 사용으로 **가변 입력 크기**에 대한 강건성 확보
- 절대 위치 인코딩의 한계 극복으로 **해상도 독립적** 성능

**2. 태스크 간 일관된 개선**
- 분류, 탐지, 세그멘테이션에서 **일관된 성능 향상** 확인
- Dense prediction 태스크에서 특히 우수한 성능 (세그멘테이션 +4.5% mIoU)

**3. 효율성-성능 트레이드오프 개선**
- **더 적은 계산량으로 더 좋은 성능** 달성
- 실제 배포 환경에서의 **최적화 용이성** (TensorRT에서 1.7배 처리량 향상)

**4. 구조적 일반화**
- 분리된 지역-전역 주의 설계는 **다양한 스케일의 객체**에 효과적
- Depthwise convolution과 유사한 설계 철학으로 **확장성** 확보

## 4. 한계점
### 주요 한계
1. **하드웨어 종속성**: 최적 서브 윈도우 크기가 입력 해상도에 따라 달라짐
2. **메모리 사용량**: 논문에서 메모리 효율성에 대한 상세한 분석 부족
3. **스케일링 법칙**: 매우 큰 모델에서의 확장성 검증 부족
4. **위치 인코딩 의존성**: CPE의 설계가 성능에 미치는 영향이 큼

## 5. 연구 영향과 향후 고려사항
### 향후 연구에 미치는 영향
**1. 아키텍처 설계 패러다임**
- **지역-전역 주의 결합**이 효과적인 설계 패턴으로 확립
- **단순성과 효율성**을 중시하는 설계 철학 확산

**2. 위치 인코딩 연구**
- **조건부 위치 인코딩**의 중요성 부각
- 절대/상대 위치 인코딩 대안으로 CPE 활용 확산

**3. 실용성 중심 연구**
- **배포 최적화**를 고려한 모델 설계의 중요성 강조
- 학술적 성능과 실제 적용 간 격차 해소 방향 제시

### 향후 연구 시 고려사항
**1. 적응적 윈도우 크기**
- 입력 특성에 따른 **동적 서브 윈도우 크기 조정** 연구 필요
- 다양한 해상도와 종횡비에 대한 **자동 최적화** 방법

**2. 메모리 효율성**
- **메모리 사용량 최적화** 연구
- **그래디언트 체크포인팅** 등 메모리 절약 기법과의 결합

**3. 스케일링 연구**
- **대규모 모델**에서의 SSSA 효과성 검증
- **모델 크기에 따른 최적 하이퍼파라미터** 연구

**4. 도메인 적응**
- **의료 영상, 위성 이미지** 등 특수 도메인에서의 적용성
- **3D 데이터**로의 확장 가능성

**5. 하드웨어 최적화**
- **모바일/엣지 디바이스** 최적화
- **새로운 AI 가속기**에 대한 최적화 연구

이 논문은 Vision Transformer 분야에서 **실용성과 효율성을 겸비한 설계**의 중요성을 제시하며, 향후 연구가 단순히 성능 향상뿐만 아니라 **실제 배포 가능성**까지 고려해야 함을 시사합니다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/21235540-2c53-4e7d-b417-5dbe42dfdcb2/2104.13840v4.pdf
