# CLIP : Learning Transferable Visual Models From Natural Language Supervision | Image recognization, Image generation
"Learning Transferable Visual Models From Natural Language Supervision" ë…¼ë¬¸ì€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•´ ë²”ìš©ì ì¸ ì‹œê° ì¸ì‹ ëª¨ë¸ì„ êµ¬ì¶•í•œ íšê¸°ì ì¸ ì—°êµ¬ì…ë‹ˆë‹¤.

### ğŸ“Œ í•µì‹¬ ê¸°ì—¬  
1. **ìì—°ì–´ ê°ë… í•™ìŠµ**  
   - ê¸°ì¡´ ì‹œê° ëª¨ë¸ì€ ê³ ì •ëœ ê°ì²´ ë²”ì£¼ì— ì˜ì¡´í•´ ì¶”ê°€ ë¼ë²¨ë§ì´ í•„ìš”í–ˆìŒ[1][3].  
   - ë³¸ ì—°êµ¬ëŠ” **400ë§Œ ê°œì˜ ì¸í„°ë„· ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒ**ì„ í™œìš©í•´ ìì—°ì–´ ì„¤ëª…ë§Œìœ¼ë¡œ í•™ìŠµí•¨[1][2].  

2. **Contrastive í•™ìŠµ í”„ë ˆì„ì›Œí¬**  
   - ì´ë¯¸ì§€ ì¸ì½”ë”(ResNet/ViT)ì™€ í…ìŠ¤íŠ¸ ì¸ì½”ë”(Transformer)ë¥¼ ë³‘ë ¬ë¡œ êµ¬ì„±[2][5].  
   - **ëŒ€ì¡° í•™ìŠµ(Contrastive Learning)** í†µí•´ ìœ ì‚¬í•œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒì€ ê°€ê¹ê²Œ, ë¹„ìœ ì‚¬í•œ ìŒì€ ë©€ì–´ì§€ë„ë¡ ì„ë² ë”© ê³µê°„ ìµœì í™”[2][5].  

3. **ì œë¡œìƒ· ì „ì´ ì„±ëŠ¥**  
   - 30ê°œ ì´ìƒì˜ ë‹¤ì–‘í•œ íƒœìŠ¤í¬(OCR, ë™ì‘ ì¸ì‹, ì§€ë¦¬ ìœ„ì¹˜ ë“±)ì—ì„œ í‰ê°€[1][3].  
   - **ë³„ë„ ë¯¸ì„¸ ì¡°ì • ì—†ì´** ImageNetì—ì„œ ResNet-50ê³¼ ë™ë“±í•œ ì •í™•ë„ ë‹¬ì„±[1][5].  
   - ì˜ˆì‹œ: "ê°•ì•„ì§€ ì‚¬ì§„" í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œë„ ê°œ í’ˆì¢… ë¶„ë¥˜ ê°€ëŠ¥[4][5].  

### âš™ï¸ ê¸°ìˆ ì  í˜ì‹   
- **íš¨ìœ¨ì„±**: Bag-of-Words ì˜ˆì¸¡ ëŒ€ë¹„ 4ë°° ë¹ ë¥¸ í•™ìŠµ ì†ë„[2].  
- **í™•ì¥ì„±**: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì¡°ì •ìœ¼ë¡œ ìƒˆë¡œìš´ ê°ì²´ ë²”ì£¼ ì¦‰ì‹œ ì¸ì‹ ê°€ëŠ¥[4][5].  
- **ë‹¤ì¤‘ ëª¨ë‹¬ í†µí•©**: ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ë™ì¼í•œ ì„ë² ë”© ê³µê°„ì— ë§¤í•‘í•´ ì‹œê°-ì–¸ì–´ ìƒí˜¸ì‘ìš© ê°€ëŠ¥[2][5].  

### ğŸŒ ì˜ì˜ ë° í•œê³„  
- **ì˜ì˜**: ë¼ë²¨ ì˜ì¡´ì„± íƒˆí”¼, ëŒ€ê·œëª¨ ì›¹ ë°ì´í„° í™œìš© ê°€ëŠ¥ì„± ì¦ëª…[1][3].  
- **í•œê³„**:  
  - í…ìŠ¤íŠ¸ì˜ ëª¨í˜¸ì„±(ì˜ˆ: "ë¹¨ê°„ ê³µ"ì´ ì¶•êµ¬ê³µ/í…Œë‹ˆìŠ¤ê³µì¸ì§€ êµ¬ë¶„ ë¶ˆí™•ì‹¤)[4].  
  - ë°ì´í„° ë‚´ ì‚¬íšŒì  í¸í–¥ ì¬ìƒì‚° ê°€ëŠ¥ì„±[5].  

ì´ ì—°êµ¬ëŠ” **ìì—°ì–´ê°€ ì‹œê° ì¸ì‹ì˜ ê°•ë ¥í•œ ê°ë… ì‹ í˜¸**ê°€ ë  ìˆ˜ ìˆìŒì„ ì…ì¦í•˜ë©°, ì´í›„ CLIP ë“± ë‹¤ì¤‘ ëª¨ë‹¬ ëª¨ë¸ ë°œì „ì˜ ì´ˆì„ì´ ë˜ì—ˆìŠµë‹ˆë‹¤[1][5].

[1] https://arxiv.org/abs/2103.00020
[2] https://proceedings.mlr.press/v139/radford21a/radford21a.pdf
[3] http://arxiv.org/pdf/2103.00020.pdf
[4] https://molly.polycount.com/library-files/learning-transferable-visual-models-from-natural-language-supervision.pdf
[5] https://github.com/cognitivetech/llm-research-summaries/blob/main/document-processing/Learning-Transferable-Visual-Models-From-Natural-Language-Supervision_2103.00020.md
[6] http://graphics.csie.ncku.edu.tw/2025%20CGAP/Learning-Transferable-Visual-Models-From-Natural-Language-Supervision.pdf
[7] https://strikingloo.github.io/wiki/clip
[8] https://www.scribd.com/document/548666345/Learning-Transferable-Visual-Models-From-Natural-Language-Supervision
[9] https://www.semanticscholar.org/paper/Learning-Transferable-Visual-Models-From-Natural-Radford-Kim/6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4
[10] https://paperswithcode.com/paper/learning-transferable-visual-models-from

https://ffighting.net/deep-learning-paper-review/multimodal-model/clip/

https://github.com/openai/CLIP/tree/main

- How is the dataset collected? #23 : https://github.com/openai/CLIP/issues/23
