# SwinIA: Self-Supervised Blind-Spot Image Denoising without Convolutions | Image denoising

**핵심 주장:** 완전한 Transformer 기반 구조로 입력 마스킹 없이 단일 순방향 패스로 자기감독(Self-Supervised) 블라인드-스팟(image blind-spot) 이미지 디노이징을 구현하여, 기존 CNN 기반 방식들이 필요로 했던 잡음 모델 사전 지식, 복수 추론 패스, 복잡한 정규화 없이도 뛰어난 성능을 달성한다[1].

**주요 기여:**  
- 완전 Transformer(Ultra Transformer) 구조로서 최초의 블라인드-스팟 자기감독 디노이저 제안  
- 패치 셔플(patch shuffle) 및 대각선 주의(attention) 마스킹을 통한 픽셀 수준의 ‘자기-비가시(Self-Unawareness)’ 보장  
- 별도의 마스킹, 추가 손실 함수, 하이퍼파라미터 튜닝 불필요  
- 단일 MSE 손실로 end-to-end 학습, 단일 추론 패스로 빠른 처리 속도 및 효율적 학습  

# 문제 정의 및 제안 방법

## 해결 과제  
기존 자기감독 디노이징(Noise2Self, Noise2Void 등)은  
1. 입력 마스킹이나 다중 패스로 인해 학습 속도가 느리고 하이퍼파라미터 의존  
2. 블라인드-스팟 보장 시 정밀한 수용영역 제어 어려움  
3. 잡음 모델 사전 지식(노이즈 분포) 필요 혹은 후처리 요구[1].  

## 제안 모델 구조  
- SwinIA는 Swin Transformer 기반 인코더–디코더 구조  
- 입력 이미지를 크기 p∈{1,2,4} 패치로 셔플 후, 키·값(key, value)을 고정  
- 쿼리(query)만 학습 가능한 절대 위치 임베딩(APE) 사용  
- 각 윈도우 내 대각 원소를 −∞로 마스킹하여 픽셀이 자기 자신을 참조하지 못하도록 설계  
- 인코더(3단계 패치 크기별 병렬)와 디코더(2단계 병합)로 특징 융합  
- 학습 시 손실:  

$$
\mathcal{L}(\theta) = \mathbb{E}_x \|f(x;\theta) - x\|^2
$$

[1]  
- 추론 시 마스킹 제거하여 픽셀 자체 정보 복원  

## 모델 수식 주요 사항  
- 키·값은 한 번만 계산·고정:  

$$
K_p = h_p^{-1}\big(\mathrm{LayerNorm}(h_p(X)W_{kp} + \mathrm{APE}\_p)\big),
\quad
V_p = h_p^{-1}\big(\mathrm{LayerNorm}(h_p(X)W_{vp} + \mathrm{APE}_p)\big)
$$

[1]  
- 대각 마스킹된 윈도우 MSA:  

$$
\mathrm{MSA}(Q,K,V) = \mathrm{Softmax}\bigl(\tfrac{QK^T - I_n \cdot 10^9}{\sqrt{d_h}\,p}\bigr)V
$$

[1]  

# 성능 향상 및 한계

| 비교 항목                          | 장점                                                                                                       | 한계                                                         |
|----------------------------------|-----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------|
| **정밀성(PSNR/SSIM)**            | BSD68 등 그레이스케일 노이즈: 최고 성능 달성[1]                                                              | 다중 패스 방식 대비 초고성능 슈퍼비전 디노이저에는 미치지 못함 |
| **학습·추론 효율성**             | 단일 패스, MSE만으로 훈련→ CNN 방식 대비 2배 빠른 학습[1]                                                       | Transformer 특성상 대규모 연산 요구                           |
| **하이퍼파라미터 단순화**        | 마스킹/정규화 손실 계수 불필요 → 범용성↑                                                                   | 윈도우 크기·패치 크기 조정 필요                              |
| **자기-비가시 보장**             | 대각 attention 마스킹으로 완전 보장, 추론 시 해제                                                          | 공간적 잡음 상관성(카메라 보간) 처리 미흡                    |
| **모델 일반화 잠재력**            | 픽셀 임베딩이 강건한 표현 학습 → 분할·기타 다운스트림 작업 전이 가능시사[1]                                   | 소규모 데이터셋에서 과적합 위험                                |

# 일반화 성능 향상 가능성

- **자연 잡음 및 다양한 모달리티**: 형광현미경, 자연 사진, 한자 등 다종 잡음 환경에서 일관된 성능 확인[1].  
- **특징 표현의 전이**: 마지막 블록의 픽셀 임베딩을 클러스터링했을 때 의미 있는 세그멘테이션 마스크 형성(Fig. 8–9)[1]. 이는 세분화, 복원, 분류 등 다운스트림 작업에 직접 활용 가능한 잠재력을 시사.  
- **대규모 자기감독 사전학습**: NLP의 BERT 식 사전학습처럼 무마스킹 Transformer авто인코더로 대용량 이미지 코퍼스 사전학습 후 전이학습 가능성이 열려 있음.  

# 향후 연구 영향 및 고려 사항

**영향:**  
- CNN 기반 BSN 연구 패러다임 전환: 마스킹 복잡성 제거, 단일 MSE 손실로 학습 단순화  
- Transformer 응용 영역 확대: 포괄적 자기감독 복원 모델 제시  
- 이미지 임베딩 활용 가능성 부각: 대규모 사전학습, 다운스트림 작업 통합  

**고려 사항:**  
1. **컴퓨팅 자원**: 대규모 윈도우 기반 Transformer는 연산량·메모리 요구 높음 → 효율화 연구 필요  
2. **공간적 잡음 모델링**: 센서 보간·JPEG 아티팩트 등 상관 잡음 처리 기법 확장  
3. **데이터 규모**: 자료가 제한적일 때 과적합 방지 위한 정규화·데이터 증강 전략 요구  
4. **하이퍼파라미터 최적화**: 윈도우 크기, 패치 크기, 헤드 수 조정이 성능과 효율 균형 핵심[1]

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/1a24790a-3812-4b3b-9889-c4359ed4afc2/2305.05651v2.pdf
