# YOLOV2 : YOLO9000: Better, Faster, Stronger | Object detection

**핵심 주장 및 주요 기여 요약**  
YOLO9000은 객체 검출과 분류 데이터의 결합 학습을 통해 9,000개 이상의 객체 범주를 실시간으로 검출할 수 있는 통합 프레임워크를 제안한다.  
1. **YOLOv2**: 경량 네트워크 설계, 앵커 박스(anchor boxes), 차원 클러스터(dimension clustering), 위치 예측 방식 개선, 멀티스케일 학습 등 기존 YOLO를 개선하여 40–90 FPS 속도에서 PASCAL VOC 및 COCO 기준 최상위 성능 달성.  
2. **WordTree 계층 구조**: WordNet 기반 시각 개념 트리를 구성하여 분류와 검출 레이블을 계층적으로 통합, 상위 개념에 대한 조건부 확률 예측으로 레이블 간 관계를 명확히 모델링.  
3. **공동 학습(Joint Training)**: COCO 검출 데이터와 ImageNet 분류 데이터를 혼합하여 학습함으로써 검출용 바운딩박스 레이블이 없는 클래스에 대해서도 검출 능력을 확장(Weakly Supervised Detection).  

***

## 1. 문제 정의  
기존 객체 검출기는 수백 개 범주만을 다루거나(예: COCO), 분류 모델은 수만 개 범주를 학습하지만 위치 정보가 없어 검출에는 사용할 수 없다는 한계가 있다.  
- **검출 데이터 한정**: 바운딩박스 레이블 획득 비용이 높아 검출 데이터셋 규모 확장 어려움  
- **분류 데이터 미활용**: 풍부한 분류 데이터(ImageNet)가 검출 모델의 어휘(vocabulary) 확장에 활용되지 못함  

***

## 2. 제안 방법  
### 2.1 YOLOv2 개선 기법  
- **앵커 박스 기반 바운딩박스 예측**  
  - 전통적 좌표 예측 대신 앵커 박스에 대한 오프셋(offset) $$t_x, t_y, t_w, t_h$$ 및 객체성(objectness) $$t_o$$ 값을 예측  
  - 그리드 셀 위치 $$(c_x, c_y)$$ 및 앵커 크기 $$(p_w, p_h)$$를 이용해  

$$
      b_x = \sigma(t_x) + c_x,\quad
      b_y = \sigma(t_y) + c_y,\quad
      b_w = p_w e^{t_w},\quad
      b_h = p_h e^{t_h},\quad
      P(\text{obj}) = \sigma(t_o).
    $$  

- **차원 클러스터링(Dimension Clustering)**  
  - 훈련 데이터의 바운딩박스 크기를 k-means ($$d=1-\text{IoU}$$)로 군집화하여 앵커 초기화를 자동화  
- **패스스루 레이어(Passthrough)**  
  - 중간 26×26 해상도 특징을 13×13 해상도 특징과 채널 방향으로 연결하여 소형 객체 검출 강화  
- **멀티스케일 학습(Multi-scale Training)**  
  - 각 10배치마다 네트워크 입력 크기를 320–608픽셀(32의 배수) 사이 임의로 변경하여 다양한 해상도에서 학습  

### 2.2 Darknet-19 백본 네트워크  
- 19개 합성곱 레이어와 5개 풀링 레이어 구성, 3×3·1×1 필터 조합, 배치 정규화·글로벌 평균 풀링 적용  
- 224×224 입력 시 5.58 GFLOPs, ImageNet 분류에서 72.9% top-1, 91.2% top-5 정확도  

### 2.3 WordTree 계층 분류  
- WordNet 시각 명사 시냅셋을 트리로 단순화하여 계층적 관계 모델링  
- 각 노드에서 동위항(co-hyponym)에 대한 소프트맥스 예측  
- 절대 확률은 루트까지 조건부 확률 곱으로 계산  
- 검출 시 상위 노드 ‘physical object’의 객체성 예측을 활용  

### 2.4 공동 학습 전략  
- COCO 검출 이미지: 전체 YOLO 손실 함수(backpropagate)  
- ImageNet 분류 이미지: 계층 분류 손실만 역전파, 해당 클래스 최고 응답 바운딩박스에 대한 객체성 손실(r = 0.3 IoU 가정) 포함  
- 종합 모델은 COCO의 44개 클래스와 ImageNet 분류만 있는 156개 클래스에 대해 평가 시, 후자는 약 16.0 mAP 달성  

***

## 3. 성능 향상 및 한계  
### 3.1 성능 향상  
- VOC 2007: 78.6 mAP at 40 FPS, 69.0 mAP at 91 FPS  
- COCO test-dev: 21.6 AP (0.5 IoU 기준)  
- ImageNet 검출 200 클래스 중 검출 데이터 없는 156개 클래스에서도 16.0 mAP  

### 3.2 한계  
- **비동물 범주**(의류·장비 등) 약함: COCO에 라벨 없는 클래스는 객체성 예측 일반화 어려움  
- **계층 분류 복잡도**: WordTree 구축 시 노드·간선 선택 기준 단순화로 인한 구조 손실 가능성  
- **약한 감독 영역**: 분류 데이터 바운딩박스 가정($$\text{IoU}\ge0.3$$)이 잘못된 경우 오브젝트 분리 학습 저해  

***

## 4. 일반화 성능 강화 관점  
YOLO9000의 **계층적 레이블링**과 **멀티스케일 학습**은 다양한 클래스·해상도에서도 견고한 특징 표현을 학습하게 한다.  
- WordTree 구조는 상위 개념(예: ‘동물’)의 강인한 예측을 보장하여 세부 분류 불확실성에도 일반화 성능 유지  
- 앵커 차원 클러스터링 및 패스스루 연결은 다양한 객체 크기·형태에 대한 적응력을 높여 적은 학습 샘플에도 견고한 검출 달성  

***

## 5. 향후 연구 영향 및 고려사항  
YOLO9000은 객체 검출과 분류 데이터의 **결합 학습**을 통해 대규모 범주 확장을 가능케 한 선구적 모델로,  
- **약-강 지도 학습**(weak–strong supervision)에 기반한 검출 성능 향상  
- **계층적 분류**가 자연 이미지 이해·세분화(task granularity)에 미치는 영향  
- **멀티도메인 데이터 통합**을 위한 레이블 정규화·구조화 방법론 확장  

향후 연구에서는  
- 더 다양한 비(非)자연 객체 클래스에 대한 **약지도 바운딩박스 학습** 전략  
- WordTree 구조 최적화를 위한 그래프 이론적 접근  
- 시멘틱 분할·인스턴스 분할으로의 확장 및 **클래스 불균형** 해소 기법 적용을 고려해야 한다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/482484eb-09d4-45db-8e1c-e790648cb7e8/1612.08242v1.pdf
