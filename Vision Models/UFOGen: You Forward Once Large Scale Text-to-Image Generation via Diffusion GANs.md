# UFOGen: You Forward Once Large Scale Text-to-Image Generation via Diffusion GANs | 2023 · 130회 인용, Image generation

## 핵심 주장과 주요 기여

UFOGen은 텍스트-이미지 생성에서 **단일 추론 단계(one-step inference)**를 달성한 혁신적인 생성 모델입니다. 이 논문의 핵심 주장은 기존 확산 모델의 느린 다단계 샘플링 문제를 해결하기 위해 확산 모델과 GAN 목적 함수를 결합한 하이브리드 방법론을 제안한다는 것입니다.[1]

주요 기여는 다음과 같습니다:

1. **단일 단계 고품질 이미지 생성**: 텍스트 설명에 기반하여 한 번의 추론 단계로 고품질 이미지를 생성할 수 있는 강력한 생성 모델 제안[1]

2. **효율적인 훈련 프로세스**: Stable Diffusion과 같은 기존 대규모 확산 모델을 단일 단계 생성 모델로 파인튜닝할 수 있는 효율적이고 단순화된 훈련 과정 제시[1]

3. **다양한 응용 가능성**: 이미지-투-이미지 변환과 제어 가능한 생성과 같은 다양한 생성 시나리오에서 단일 단계 추론 가능성 확장[1]

## 해결하고자 하는 문제와 제안 방법

### 문제 정의

기존 확산 모델은 반복적 노이즈 제거(iterative denoising) 과정에 의존하여 최종 샘플을 생성하므로 생성 속도가 느립니다. 현재 가장 진보된 솔버들도 10-20단계의 샘플링이 필요하며, 이를 더 줄이면 이미지 품질이 눈에 띄게 저하됩니다.[1]

### 제안 방법

#### 1. 새로운 생성기 파라미터화

기존 SIDDM에서는 생성기가 $$p_θ(x_{t-1}|x_t) = q(x_{t-1}|x_t, x_0 = G_θ(x_t, t))$$로 파라미터화됩니다[1]. 

UFOGen은 새로운 파라미터화를 제안합니다:

$$p_θ(x_{t-1}) = q(x_{t-1}|x_0 = G_θ(x_t, t))$$

이 설계는 $$x_0$$에서의 분포 매칭을 가능하게 하여 단일 단계 샘플링의 길을 열어줍니다.[1]

#### 2. 개선된 재구성 손실

UFOGen의 훈련 목적 함수는 다음과 같습니다:

$$\min_θ \max_{D_φ} \mathbb{E}_{q(x_0)q(x_{t-1}|x_0),p_θ(x'_0)p_θ(x'_{t-1}|x'_0)} [\log(D_φ(x_{t-1},t)) + \log(1 - D_φ(x'_{t-1},t))] + λ_{KL}γ_t||x_0 - x'_0||^2_2$$

여기서 $$γ_t$$는 시간 의존적 계수입니다. 이 목적 함수는 시간 단계 $$t-1$$에서 노이즈가 있는 샘플을 매칭하는 적대적 손실과 시간 단계 0에서의 재구성 손실로 구성됩니다.[1]

#### 3. 사전 훈련된 확산 모델 활용

UFOGen은 생성기와 판별기 모두에 일관된 UNet 구조를 사용하여 사전 훈련된 Stable Diffusion 모델로 초기화할 수 있습니다. 이 전략은 UFOGen의 훈련을 크게 간소화하고 안정적인 훈련 동역학과 빠른 수렴을 보장합니다.[1]

## 모델 구조

UFOGen은 다음과 같은 핵심 구조를 가집니다:

- **생성기(Generator)**: Stable Diffusion의 UNet 구조를 기반으로 하며, 텍스트 조건을 받아 단일 단계에서 이미지를 생성[1]
- **판별기(Discriminator)**: 생성기와 동일한 UNet 구조를 사용하여 실제와 가짜 노이즈가 있는 잠재 변수를 구별[1]
- **텍스트 인코더**: CLIP ViT-L/14의 고정된 텍스트 인코더 사용[1]
- **VAE**: 이미지 인코딩/디코딩을 위해 Stable Diffusion 1.5와 동일한 VAE 사용[1]

## 성능 향상

### 정량적 성과

MS-COCO 2017 5k 데이터셋에서의 평가 결과:
- **FID 점수**: 22.5 (단일 단계)[1]
- **CLIP 점수**: 0.311[1]
- InstaFlow-0.9B (FID: 23.4, CLIP: 0.304) 및 InstaFlow-1.7B (FID: 22.4, CLIP: 0.309)보다 우수한 성능[1]

### 정성적 성과

질적 비교에서 UFOGen은 InstaFlow보다 이미지 품질에서 상당한 우위를 보였으며, 2단계 LCM과 비교했을 때도 LCM 샘플의 명백한 흐림 현상에 비해 상당한 이점을 보였습니다. 4단계 LCM과 비교해도 더 선명한 텍스처와 세밀한 디테일을 보여줍니다.[1]

## 일반화 성능 향상

### 다운스트림 응용의 다양성

UFOGen은 다양한 생성 작업에서 단일 단계로 작동할 수 있는 독특한 특징을 가집니다:[1]

1. **이미지-투-이미지 생성**: SDEdit 방법론을 따라 입력 데이터에 적절한 양의 노이즈를 추가하고 주어진 프롬프트에 기반하여 단일 단계 생성 수행[1]

2. **제어 가능한 생성**: T2I-Adapter와 유사한 접근법으로 추가 어댑터 네트워크를 통합하여 깊이 맵과 캐니 엣지 같은 제어 신호를 처리[1]

### 기존 모델 대비 유연성

GAN 기반 텍스트-이미지 모델들과 달리 UFOGen은 노이즈 제거를 통해 샘플을 생성하므로 제로샷 이미지-투-이미지 생성 작업에서 뛰어난 성능을 보입니다. 또한 StyleGAN 아키텍처에 보조 모듈을 추가하는 복잡성으로 인해 기존 GAN 기반 모델들이 탐구하지 못한 제어 가능한 생성 영역에서도 성공을 거두었습니다.[1]

## 한계

논문에서 직접적으로 언급된 주요 한계는 다음과 같습니다:

1. **공통적인 SD 기반 모델 문제**: UFOGen은 객체 누락, 속성 누출, 개수 세기 등 SD 기반 모델의 일반적인 문제들을 여전히 겪고 있습니다[1]

2. **훈련 안정성 의존성**: 노이즈가 있는 데이터에서의 적대적 손실을 통한 훈련이 확산-GAN 훈련 안정화에 중요하며, 이는 모델의 제약사항이 될 수 있습니다[1]

## 미래 연구에 미치는 영향

### 생성 모델 패러다임의 전환

UFOGen은 초고속 텍스트-이미지 합성을 가능하게 하는 선구자로서 생성 모델 환경의 변혁적 변화를 위한 길을 열어줍니다. 이는 학술적 논의를 넘어서 빠르고 고품질 이미지 생성의 실용적 환경을 혁신할 잠재력을 가지고 있습니다.[1]

### 향후 연구 고려사항

1. **하이브리드 접근법의 확장**: 확산 모델과 GAN의 결합이 다른 생성 작업에도 적용될 수 있는 가능성 탐구

2. **추론 효율성**: 단일 단계 생성의 효율성을 더욱 개선하면서도 품질을 유지하는 방법 연구

3. **사전 훈련 모델 활용**: 다양한 사전 훈련된 모델을 활용한 효율적인 파인튜닝 전략 개발

4. **제어 가능성 향상**: 더 정교하고 다양한 제어 신호를 처리할 수 있는 모델 개발

5. **평가 지표 개선**: 단일 단계 생성 모델의 품질을 더 정확하게 평가할 수 있는 새로운 메트릭 개발

UFOGen의 성공은 확산 모델의 속도 제약을 극복하는 새로운 방향을 제시하며, 실시간 고품질 이미지 생성 응용 분야의 발전을 크게 촉진할 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/b7c8d78d-51f8-4f6f-8703-c967ed4c8d2e/2311.09257v5.pdf)
