# DRAW: A Recurrent Neural Network For Image Generation | Image generation

## 1. 핵심 주장 및 주요 기여
**Deep Recurrent Attentive Writer (DRAW)**는 이미지 생성을 위해  
-  순환적 변분 오토인코더(RNN-VAE)와  
-  사람의 시각 포커싱을 모방한 차별화된 2D 어텐션 메커니즘을 결합하여,  
단일 단계가 아닌 여러 단계의 반복적 수정으로 복잡한 이미지를 점진적으로 그려낸다.[1]
주요 기여는 다음과 같다:[1]
-  MNIST에서 당시 최첨단인 평균 음의 로그우도 80.97 nats 달성  
-  SVHN에서 사람 눈으로 식별 불가능한 자연스러운 숫자 이미지 생성  
-  어텐션 기반 분류 모델이 잡음이 심한 영상에서도 높은 일반화 성능 발휘  

## 2. 문제 정의, 제안 방법, 모델 구조, 성능 및 한계

### 2.1 해결하고자 한 문제  
기존 생성 모델은 모든 픽셀을 한 번에 처리하여:  
1) 대규모 이미지로 확장 시 복잡도 급증  
2) 자기 수정(self-correction) 불가능  
3) 특정 영역 집중 학습 제한  
이러한 한계를 극복하며 “사람처럼” 부분별로 점진 수정하며 이미지를 생성하고자 함.[1]

### 2.2 제안 방법  
DRAW는 다음 과정을 반복하여 이미지를 구성한다:[1]
1. **읽기(read):** 이전 디코더 은닉 상태 $$h^{dec}_{t-1}$$로부터 2D 가우시안 필터 격자 $$(F_X,F_Y,\gamma)$$ 생성  
2. **인코딩(encoding):**  

```math
   r_t = \gamma\bigl[F_Y\,\tilde x_t\,F_X^T,\;F_Y\,x\,F_X^T\bigr],\quad
   h^{enc}_t = \mathrm{RNN}_{enc}(h^{enc}_{t-1},[r_t,h^{dec}_{t-1}])
```

3. **잠재 변수 샘플링(z):**  

$$
   \mu_t = W(h^{enc}_t),\quad
   \sigma_t = \exp\bigl(W(h^{enc}_t)\bigr),\quad
   z_t\sim\mathcal{N}(\mu_t,\sigma_t^2)
   $$  

4. **디코딩(decoding):**  

```math
   h^{dec}_t=\mathrm{RNN}_{dec}(h^{dec}_{t-1},z_t)
```  

5. **쓰기(write):**  

```math
   w_t = W(h^{dec}_t),\quad
   c_t = c_{t-1} + \tfrac{1}{\hat\gamma}\hat F_Y^T\,w_t\,\hat F_X
```

6. **손실 함수:**  

```math
   L = \mathbb{E}_{z\sim Q}\Bigl[-\log D\bigl(x\mid c_T\bigr) + \sum_{t=1}^T\mathrm{KL}\bigl(Q(Z_t)\parallel P(Z_t)\bigr)\Bigr]
```

[1]

### 2.3 모델 구조  
-  **인코더/디코더:** LSTM 기반 RNN  
-  **어텐션 패치 크기 $$N\times N$$:** 읽기·쓰기 시 공간적 집중  
-  **타임스텝 $$T$$:** 전체 생성 반복 횟수  
-  **캔버스 $$c_t$$:** 단계별 누적 수정 결과

### 2.4 성능 향상  
다음 표는 Binomial MNIST 기준 음의 로그우도 비교이다:[1]

| 모델                          | 음의 로그우도 (nats)     |
|------------------------------|-------------------------|
| DARN 1 hidden layer          | 84.13[1]                |
| EoNADE (2 hidden, 128 order) | 84.68[1]                |
| DRAW without attention       | 87.40[1]                |
| **DRAW with attention**      | **80.97[1]**            |

SVHN 및 CIFAR-10에서도 DRAW는 사람 눈으로 식별 불가능한 이미지를 생성했으나, CIFAR-10에서는 과도한 흐림(blurriness)과 학습 미달 언더피팅을 관찰.[1]

### 2.5 한계  
- **계산 복잡도:** 다단계 RNN+어텐션 연산으로 학습·추론 비용 증가  
- **고정 시점 수 $$T$$:** 동적 해상도 조정 어려움  
- **대규모 컬러 자연 이미지:** CIFAR-10에서 흐림 발생  
- **과적합 및 과소적합:** SVHN 임의 패치 학습에서 언더피팅 관찰

## 3. 일반화 성능 향상 관점  
-  **분할 집중 학습:** 어텐션으로 복잡도 높은 장면에서도 의미 있는 부분만 반복 학습 → 노이즈·잡음에 강건.[1]
-  **잠재 변수 시퀀스:** 다중 $$z_t$$ 샘플링으로 잠재 공간 표현력 확대 → 과소적합 완화 가능  
-  **재구성+KL 균형:** 손실 함수 가중치 조정으로 재구성 품질과 분포 정규화 간 최적 균형 유도  
-  **확장 고려:** 어텐션 패치 크기·단계 수·잠재 차원 제어를 통해 모델 복잡도와 일반화 능력 조율  
위 요소들은 모델이 다양한 해상도, 잡음 환경, 도메인 전이에서도 견고한 일반화를 달성하도록 돕는다.

## 4. 향후 연구 영향 및 고려사항  
### 4.1 연구 영향  
DRAW의 반복적 어텐션 기반 생성은 **VAE**, **GAN**, **메모리-증강 신경망** 등 후속 연구에 큰 영감을 주었으며,  
특히 영상/의료·위성 이미지의 점진적 복원, 텍스트-이미지 멀티모달 생성, 시계열 예측에서도 어텐션 메커니즘이 표준 기법으로 자리잡았다.

### 4.2 앞으로 연구 시 고려사항  
-  **효율성 최적화:** 단일 패치 대신 분산 병렬 어텐션, 계층적 토폴로지 적용  
-  **동적 단계 제어:** 적응적 $$T$$ 결정으로 불필요한 연산 최소화  
-  **결합 학습:** 어텐션-컨볼루션 혼합, 템플릿 매칭, 스케일 불변성 처리 강화  
-  **강화 학습 통합:** 어텐션 위치 선택을 정책 학습으로 전환해 비차분 최적화 시도  
-  **안정적 훈련:** KL 발산 스케줄링, 스펙트럼 정규화, 스무딩 기법  

이러한 접근은 DRAW의 **일반화 성능**을 더욱 높이고, 더욱 복잡한 실세계 이미지 생성 과제를 해결하는 데 기여할 것이다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/02cd5dce-31f9-48c6-9450-00cd610b6647/1502.04623v2.pdf
