# GeNeVA-GAN : Tell, Draw, and Repeat: Generating and Modifying Images Based on Continual Linguistic Instruction | Text(Image)-Image generation

## 1. 핵심 주장 및 주요 기여  
**핵심 주장**  
- 텍스트 대화형 지시를 바탕으로 한 단계씩 이미지를 생성·수정하는 반복적(text-conditional iterative) GAN 모델(GeNeVA-GAN)이, 기존의 단일 단계(text-to-image) 생성 방식을 뛰어넘어 **지속적인 언어 입력에 따라 이미지를 점진적으로 구성 및 변형**할 수 있음을 보인다[1].  

**주요 기여**  
1. **GeNeVA 과제 정의**: 텍스트 지시 시퀀스에 따라 빈 캔버스에서 마지막 이미지까지 점진적 생성·수정을 요구하는 새로운 과제를 제안[1].  
2. **반복적 GAN 아키텍처**: 과거 지시와 최근 생성 이미지를 모두 조건으로 입력받는 **컨텍스트-어웨어 GRU**와 **컨텍스트-프리 이미지 인코더**를 결합한 모델 설계[1].  
3. **i-CLEVR 데이터셋**: CLEVR 장면을 단계별 지시와 함께 생성하도록 확장한 순차적 합성 데이터셋을 공개[1].  
4. **관계 유사도 지표(rsim)**: 생성 이미지가 지시된 객체 간 **공간적 관계**(앞, 뒤, 왼쪽, 오른쪽)를 얼마나 잘 만족하는지 평가하는 새로운 정량적 메트릭을 도입[1].  

## 2. 문제 정의, 제안 방법, 모델 구조, 성능 및 한계  

### 2.1 해결하고자 하는 문제  
- **단일 단계**로 캡션이나 대화 전체를 입력받아 이미지를 생성하는 기존 모델들은  
  - 지시 간 간섭(interference)이 발생해 복잡한 장면 조합이 어려움  
  - 피드백을 반영한 중간 편집 기능이 부재  
- **GeNeVA 과제**는 대화의 각 턴마다 이미지를 수정·확장하며 누적 언어 지시를 반영해 최종 장면을 완성하도록 요구[1].  

### 2.2 제안 방법  
- 매 타임스텝 $$t$$에서, 이전 생성 이미지 $$\tilde{x}_{t-1}$$와 현재까지의 언어 컨텍스트 $$h_t$$를 입력으로
 
$$
    \tilde{x}\_t = G\bigl(z_t,\; h_t,\; f^G_{t-1}\bigr)
$$
  
  - $$z_t \sim \mathcal{N}(0,1)$$: 노이즈 벡터  
  - $$h_t = \mathrm{GRU}\_\mathrm{lang}(d_t, h_{t-1})$$: 지시 임베딩 $$d_t$$와 이전 상태의 반복 계산[1]
  - $$f^G_{t-1} = E_G(\tilde{x}_{t-1})$$: 이전 이미지의 CNN 인코딩  
- **판별자** $$D$$는 현재·이전(진짜 또는 생성) 이미지 쌍을 함께 입력받아  
  - 정상(real) vs. 생성(fake) 구분  
  - 잘못된 지시(wrong instruction) 판별  
  - 객체 존재(auxiliary detection)까지 동시 학습[1].  

### 2.3 모델 구조  
| 구성 요소              | 역할                                                         |
|-----------------------|--------------------------------------------------------------|
| 텍스트 인코더         | 양방향 GRU + GloVe 임베딩 → 지시 임베딩 $$d_t$$[1]          |
| 컨텍스트-어웨어 GRU   | 과거 언어 지시 상태 $$h_{t-1}$$와 새 임베딩 $$d_t$$ 통합       |
| 이미지 인코더 $$E_G$$| 이전 생성 이미지 → 컨텍스트-프리 특징 $$f^G_{t-1}$$[1]        |
| 생성기 $$G$$          | $$z_t, h_t, f^G_{t-1}$$ 조건으로 이미지 생성                 |
| 판별자 $$D$$          | 전·현 이미지 퓨전 + 명령 투영(projection) + 객체 검출 $$\beta L_{aux}$$[1] |

### 2.4 성능 향상  
- **비반복(Non-iterative)** 대비, Precision·Recall·F1 및 관계 유사도(rsim)에서 모두 유의미한 개선(Table 1)[1]:  
  | 모델                 | CoDraw F1-Score | CoDraw rsim | i-CLEVR F1-Score | i-CLEVR rsim |
  |----------------------|-----------------|-------------|------------------|--------------|
  | Non-iterative        | 44.96%          | 22.33%      | 22.63%           | 11.52%       |
  | GeNeVA-GAN (D Subtract) | **58.83%**      | **35.41%**  | **88.39%**       | **74.02%**   |

- **ablation 결과**:  
  - 이전 이미지 인코딩 $$f^G_{t-1}$$ 도입 → 관계 유사도 대폭 향상  
  - 판별자의 이미지 퓨전(차분) 기법 → 학습 신호 강화  

### 2.5 한계  
1. **세밀한 디테일 부족**: 작은 객체, 표정·포즈 표현에서 한계[1].  
2. **데이터 편향**: CoDraw의 제한된 클립아트 객체군, i-CLEVR의 합성 환경에 국한.  
3. **객체 중복·과잉 생성**: 현재 단일 클래스당 하나만 탐지하므로 다중 인스턴스 대응 미흡[1].  
4. **질의 기능 부재**: 모호한 지시 시 사용자에게 추가 질문하는 능력 미탑재.  

## 3. 일반화 성능 향상 가능성  
- **새 배경 이미지 적응실험**: 훈련 시 사용하지 않은 중간 이미지로 초기화 후에도  
  - 기존 객체 보존  
  - 새로운 객체 올바른 위치·속성으로 추가 성공  
  → **무교사 배경 일반화** 가능성 확인[1].  
- **향후 확장 방향**:  
  1. **실세계(photo-realistic) 데이터셋 구축** 및 전이 학습  
  2. **객체 질의(questioning) 모듈** 통합으로 불명확 지시 대응  
  3. **다중 인스턴스·속성 평가 메트릭** 개발  

## 4. 향후 연구 영향 및 고려 사항  
- **인터랙티브 생성 발전**: 언어 기반 이미지 편집·디자인 툴, 교육·접근성 보조 어플리케이션 확대.  
- **모델 설계 시 유의점**:  
  1. **지속적 상태 관리**: 컨텍스트-어웨어·프리 정보를 어떻게 균형 있게 활용할지 설계  
  2. **실제 데이터 비주얼 격차 해소**: 합성 대비 실세계 이미지 복잡도 고려  
  3. **사용자 질의·피드백**: 양방향 대화형 시스템 구축  

-> GeNeVA 과제는 **점진적 텍스트-이미지 상호작용** 연구의 토대를 마련하며, 향후 인터랙티브 멀티모달 생성 분야에 중요한 기준을 제시할 것이다[1].

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/df1983d6-2e05-4f40-b728-069de823e743/1811.09845v3.pdf
