# SASCNet : Change Detection in Images Using Shape-Aware Siamese Convolutional Network | Change detection

## 1. 핵심 주장 및 주요 기여 요약  
이 논문은 **변화 감지(change detection)** 과제에서 기존 시암 네트워크 기반 방법들이 경계가 거칠고 형상이 부정확하다는 문제점을 해결하기 위해,  
1) 다단계의 정보(에지, 위치, 의미론)들을 추출·융합하고  
2) 잔차 기반 정제 모듈을 도입한 **Shape-Aware Siamese Convolutional Network (SASCNet)** 을 제안한다.  
이를 통해 변화 영역의 **형상 정확도(shape quality)** 를 크게 향상시키고, 후처리 없이도 빠른 추론 속도를 유지한다.

***

## 2. 해결 문제 및 제안 방법

### 2.1 해결하고자 하는 문제  
- Siamese 네트워크 기반 변화 감지 모델들은 유사도 점수만을 이용해 변화 영역을 예측하므로  
  - 경계(boundary)가 흐릿하고  
  - 내부에 구멍(hole)이나 노이즈가 많아  
  - 복잡한 배경, 조명 변화, 줌·회전 등에서 성능 저하  

### 2.2 제안하는 방법 개요  
SASCNet은 다음 세 모듈로 구성된다 :

1. **Change Map Extraction Module (CMEM)**  
   - 시암 인코더–디코더 구조  
   - ResNet-34 기반의 3단계 인코더 + 디코더  
   - 세 레벨(에지·위치·의미론)에서 변화 맵 $$C_1, C_2, C_3$$ 추출  

$$
       C_k(i,j) = \|F_{1}^{(k)}(i,j) - F_{2}^{(k)}(i,j)\|_2,\quad k=1,2,3
     $$  
   
   - Contrastive Loss로 각 레벨별 학습:

$$
       \mathcal{L}\_c = \sum_{k=1}^3 \sum_{i,j} \Bigl[y_{ij}C_k^2 + (1-y_{ij})\max(\delta - C_k,0)^2\Bigr]
     $$

2. **Change Map Fusion Module (CMFM)**  
   - 에지($$C_1$$), 위치($$C_2$$), 의미론($$C_3$$) 정보 픽셀별 덧셈 융합  
   - Sigmoid 활성화로 최종 융합 맵 $$C_4$$ 생성:

$$
       C_4 = \sigma\bigl(\mathrm{Up}(C_1)+\mathrm{Up}(C_2)+C_3\bigr)
     $$

3. **Fusion Fine-Tune Module (FFM)**  
   - U-Net 유사 구조의 잔차(refinement) 네트워크 $$\psi$$  
   - $$C_4$$와 잔차 $$\psi(C_4)$$를 더해 정제된 변화 맵 $$C_5$$ 생성:

$$
       C_5 = C_4 + \psi(C_4)
     $$  
   
   - Binary Cross-Entropy Loss로 경계·형상 정교화

***

## 3. 모델 구조 및 수식 정리  
- **인코더**: ResNet-34의 첫 3개 블록 사용 (layer1–3)  
- **디코더**: Transposed Convolution + Bilinear Upsampling  
- **융합**: 픽셀별 덧셈 + Sigmoid  
- **정제**: 3단계 U-Net 유사 잔차 블록 (Conv+Pool⇄Upsample+Conv)  

### 주요 수식 요약  
1. 변화 맵 계산  

$$
   C_k = \|F_1^{(k)} - F_2^{(k)}\|_2,\quad k=1,2,3
   $$

2. 융합  

$$
   C_4 = \sigma\bigl(\mathrm{Up}(C_1)+\mathrm{Up}(C_2)+C_3\bigr)
   $$

3. 정제  

$$
   C_5 = C_4 + \psi(C_4)
   $$

***

## 4. 성능 향상 및 한계

### 4.1 성능 향상  
- **CDnet 2014**: 평균 F-measure 0.923, PWC 0.311 (기존 최상위 0.921/0.405 대비 개선)  
- **AICD-2012**: F-measure 0.867, mIoU 0.780 (이전 최고 0.370/0.649 대비 대폭 상승)  
- **경계 선명도**: 기존 방법 대비 구멍·노이즈 감소, 형태 보전  
- **속도**: 후처리(CRF 등) 없이 이미지당 0.101s 추론

### 4.2 한계  
- **매우 작은 변화 객체**: 배경과 유사하면 $$\|F_1-F_2\|\approx0$$가 되어 검출 실패  
- **초저해상도·저프레임 환경**: 디코더의 업샘플링 단계에서 디테일 손실  
- **학습 복잡도**: 전체 네트워크 동시 학습 난이도로 단계적 사전 학습 필요  

***

## 5. 일반화 성능 향상 관점  
- **다단계 정보 융합**: 에지·위치·의미론 정보를 통합해 다양한 조건(조명·줌·회전)에서 견고성 확보  
- **잔차 기반 정제**: 데이터셋 간 도메인 차이에도 픽셀 분포 보정 가능  
- **모듈화 설계**: CMEM, CMFM, FFM 분리 학습 및 교체를 통해 다른 영상 데이터에도 유연 적용  

이를 통해 새로운 센서, 다른 해상도·스펙트럼 영상으로 빠른 확장 및 재학습이 용이하다.

***

## 6. 향후 연구에 미치는 영향 및 고려사항  
- **영향**:  
  - **통합·정제 구조**는 변화 감지뿐 아니라 물체 분할, 의료 영상 분할 등 다양한 시멘틱 분할 분야에 적용 가능  
  - **다중 슈퍼비전**과 **잔차 네트워크** 조합 아이디어가 후속 모델 설계에 영감을 제공  

- **고려사항**:  
  1. **작은 객체 검출**: 고해상도 피처 또는 어텐션 메커니즘 도입  
  2. **약지도·비지도 확장**: 정답 라벨 부족 환경에서 일반화  
  3. **경량화**: 임베디드·실시간 시스템용 모델 축소  
  4. **다중 모달**: SAR·적외선 등 타 센서 데이터 융합 방안 모색  

이 논문은 변화 감지 모델의 **형상 정교화**와 **모듈화 확장성**을 제시하며, 향후 다양한 영상 분석 과제의 발전 방향을 제시한다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/d5574f8c-0daf-414a-83d5-a1e443c28f23/1-s2.0-S0952197620301950-main.pdf
