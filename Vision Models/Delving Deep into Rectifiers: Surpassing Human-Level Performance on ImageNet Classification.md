# Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification | Image classification

**주요 결론:** 본 논문은 활성화 함수로서의 ReLU를 일반화한 PReLU(Parametric ReLU)를 제안하고, 이에 최적화된 가중치 초기화 방식을 도입하여 1000개 클래스 ImageNet 2012 분류에서 인간 수준(Top-5 error 5.1%)을 뛰어넘는 4.94% 오류율을 기록했다.[1]

## 1. 논문이 해결하는 문제
현존하는 딥 신경망은 깊어질수록 학습이 어려워지고, 활성화 함수의 고정된 형태는 모델 표현력을 제한한다.  
특히  
- ReLU 사용 시 음수 영역에서 기울기 소실로 인한 정보 손실  
- 깊은 네트워크 초기화 부적절로 인한 학습 불안정  
두 가지가 주된 병목이었다.[1]

## 2. 제안 방법
### 2.1 PReLU 활성화 함수  
수식 1)  

$$
f(y_i) = 
\begin{cases}
y_i, & y_i > 0, \\
a_i\,y_i, & y_i \le 0,
\end{cases}
$$  

여기서 $$a_i$$는 채널별로 학습되는 음수 기울기 계수다. 이로써 음수 정보도 적절히 보존하며, Leaky ReLU와 달리 계수를 데이터에 맞춰 최적화한다.[1]

### 2.2 깊은 네트워크 초기화  
ReLU/PReLU의 비선형성을 반영하여, 각 층 $$l$$의 가중치 W를 평균 0, 표준편차 $$\sqrt{2/n_l}$$로 랜덤 초기화한다(식 10).  

$$
\mathrm{Var}[w] = \frac{2}{n_l},\quad n_l = k^2\,c_{l},
$$  

이로써 순전파·역전파 시 신호 수치가 감쇠되거나 폭발하지 않도록 보장한다.[1]

## 3. 모델 구조 및 성능
- **기본 아키텍처(A):** VGG-19 변형, 첫 conv 필터 7×7, SPP(spatial pyramid pooling) 적용.  
- **확장 모델(B, C):** 깊이(B) 및 너비(C) 확장.  
- **학습 전략:** 멀티스케일 입력, 강력한 데이터 증강(크기·색상·좌우 뒤집기), 4–8 GPU 병렬 학습.[1]

| 모델 | 활성화 | Top-5 오류율 (val) |
|:----:|:------:|:-----------------:|
| A    | ReLU   | 6.51%             |
| A    | PReLU  | 6.28% ↓           |
| B    | PReLU  | 6.27%             |
| C    | PReLU  | **5.71%**         |

- 최종 **멀티모델 앙상블**로 Test set 4.94% 기록, GoogLeNet(6.66%) 대비 상대 개선 26%.[1]

## 4. 일반화 성능 향상
- PReLU는 음수 영역 기울기를 학습해 채널별 비선형 특성을 최적화함으로써 표현력을 높인다.  
- 새로운 초기화는 깊이 확장 시 발생하는 기울기 소실·폭발을 막아 안정적 학습을 유도한다.  
- 강력한 데이터 증강과 SPP 구조가 과적합 억제에 기여, 다양한 스케일에 걸친 일반화 능력을 확보했다.[1]

## 5. 향후 연구 영향 및 고려 사항
- **활성화 함수 커스터마이제이션:** PReLU 개념을 확장해 다른 비선형 함수 학습으로 이어질 수 있다.  
- **초기화 기법 확장:** BatchNorm 등 현대적 모듈과 결합해 더욱 깊은 네트워크 안정화 연구가 필요하다.  
- **과도한 깊이 한계:** 30층 이상 확장 시 정확도 포화 또는 저하 현상이 관찰되어, 깊이·너비 설계 균형에 대한 추가 연구가 요구된다.  
- **실제 적용:** PReLU·초기화 기법은 다양한 비전 및 음성 인식 과제에 적용 가능하므로, 타 도메인 일반화 성능 검증이 중요하다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/21f4e207-91d8-4457-8098-32ab9eb0c7d1/1502.01852v1.pdf
