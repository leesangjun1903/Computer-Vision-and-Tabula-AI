
# 머신러닝 초보자를 위한 핵심 용어 가이드

머신러닝을 처음 공부할 때 가장 혼란스러운 것 중 하나는 바로 용어입니다. 데이터셋, 인스턴스, 특성, 라벨... 이런 용어들이 정확히 무엇을 의미하는지 알아야 머신러닝의 개념을 제대로 이해할 수 있습니다.[^1][^2][^3]

## 머신러닝 용어의 기본 구조

머신러닝에서 사용하는 용어들은 **계층적 구조**를 가지고 있습니다. 가장 큰 범주부터 작은 단위까지 체계적으로 정리해보겠습니다.

### 1. 데이터셋 (Dataset)

**데이터셋은 모든 데이터의 집합**입니다. 머신러닝 프로젝트에서 사용할 전체 데이터를 의미합니다. 예를 들어, 붓꽃 데이터셋에는 150개의 붓꽃 정보가 모두 포함되어 있습니다.[^1][^4][^5]

### 2. 인스턴스 (Instance)

인스턴스는 **개별 데이터 하나**를 가리킵니다. 다른 말로는 사례(example), 샘플(sample), 레코드(record), 데이터 포인트(datapoint), 행(row)이라고도 합니다.[^1][^2]

붓꽃 데이터에서 하나의 인스턴스는 **특정 붓꽃 한 송이의 정보**를 담고 있습니다. 예를 들어, `[5.1, 3.5, 1.4, 0.2, setosa]`가 하나의 인스턴스입니다.

### 3. 특성 (Feature)

특성은 **머신러닝 학습에 사용되는 입력 변수**입니다. 독립변수(independent variable), 입력(input), 차원(dimension)이라고도 부릅니다.[^1][^2][^6][^7]

특성과 속성(attribute)은 미묘한 차이가 있습니다. **속성은 데이터가 가진 모든 특징**을 의미하고, **특성은 그 중에서 학습에 사용하기로 선택된 속성들**입니다.[^1]

붓꽃 데이터에서 특성은:

- 꽃받침 길이 (sepal length)
- 꽃받침 너비 (sepal width)
- 꽃잎 길이 (petal length)
- 꽃잎 너비 (petal width)


### 4. 라벨 (Label)

라벨은 **머신러닝 모델이 예측해야 하는 정답**입니다. 클래스(class), 타겟(target), 종속변수(dependent variable)라고도 합니다.[^1][^8][^6][^7]

- **분류 문제**에서는 카테고리를 나타내는 라벨 사용
- **회귀 문제**에서는 연속적인 수치를 나타내는 타겟 사용

붓꽃 데이터에서 라벨은 붓꽃의 종류입니다:

- 0: setosa
- 1: versicolor
- 2: virginica


## 용어들의 관계 이해하기

![붓꽃 데이터셋의 꽃잎 길이와 너비 관계 - 특성으로 라벨을 구분하는 예시](https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/ed066bda8f417605cee8a04e752a4ff8/25e64d9b-69de-4e5e-8a25-4f8e59d55e15/01b71fee.png)

붓꽃 데이터셋의 꽃잎 길이와 너비 관계 - 특성으로 라벨을 구분하는 예시

위 그래프는 붓꽃 데이터에서 **특성들(꽃잎 길이, 꽃잎 너비)이 어떻게 라벨(붓꽃 종류)을 구분하는데 사용되는지**를 보여줍니다. 각 점이 하나의 **인스턴스**이고, 색깔이 **라벨**을 나타냅니다.

## 실제 머신러닝 예제로 이해하기

붓꽃 데이터셋을 사용한 실제 예제를 통해 용어들을 확인해보겠습니다:

### 데이터 구조 분석

| 구성 요소 | 설명 | 붓꽃 데이터 예시 |
| :-- | :-- | :-- |
| **데이터셋** | 전체 데이터 집합 | 150개 붓꽃 데이터 |
| **인스턴스** | 개별 데이터 | 한 송이 붓꽃의 측정값 |
| **특성** | 입력 변수 | 꽃받침/꽃잎의 길이와 너비 |
| **라벨** | 정답/목표값 | 붓꽃 종류 (setosa, versicolor, virginica) |

## 머신러닝 프로세스에서의 활용

### 1. 데이터 준비 단계

- **데이터셋** 수집 및 정리
- **인스턴스**들의 품질 검사
- **특성** 선택 및 전처리


### 2. 모델 훈련 단계

- **특성**을 입력으로 사용
- **라벨**을 정답으로 학습
- 여러 **인스턴스**를 통해 패턴 학습


### 3. 예측 단계

- 새로운 **인스턴스**의 **특성** 입력
- 모델이 **라벨** 예측
- 성능 평가 및 개선


## 용어 정리와 실전 팁

### 혼동하기 쉬운 용어들

**속성 vs 특성**

- 속성: 데이터가 가진 모든 특징
- 특성: 학습에 선택된 속성들

**라벨 vs 타겟**

- 분류 문제: 라벨(카테고리)
- 회귀 문제: 타겟(연속값)


### 실제 프로젝트에서의 적용

고객 구매 예측 프로젝트를 예로 들면:

- **데이터셋**: 전체 고객 데이터
- **인스턴스**: 개별 고객 정보
- **특성**: 나이, 성별, 소득, 구매 이력
- **라벨**: 구매 여부 (구매함/안함)


## 마무리

이런 기본 용어들을 정확히 이해하면 머신러닝 논문이나 강의를 들을 때 훨씬 수월해집니다. 특히 **인스턴스 기반 학습(instance-based learning)**이나 **특성 공학(feature engineering)** 같은 고급 개념들도 이 기본 용어들의 조합으로 이루어져 있습니다.[^9][^10][^11][^12]

머신러닝을 공부할 때는 이런 용어들을 단순히 암기하기보다는, 실제 데이터와 코드를 통해 체험해보는 것이 중요합니다. 붓꽃 데이터셋 같은 간단한 예제부터 시작해서 점차 복잡한 데이터셋으로 넘어가면서 용어들을 자연스럽게 익혀보세요.
<span style="display:none">[^13][^14][^15][^16][^17][^18][^19][^20][^21][^22][^23][^24][^25][^26][^27][^28][^29][^30][^31][^32][^33][^34][^35][^36][^37][^38][^39][^40][^41][^42][^43][^44][^45][^46][^47][^48][^49][^50][^51][^52][^53][^54][^55][^56][^57][^58][^59][^60][^61][^62][^63][^64]</span>

<div style="text-align: center">⁂</div>

[^1]: https://ryuna.pokemoem.com/15

[^2]: https://www.androidhuman.com/2018-03-04-ml_for_everyone_basics_01

[^3]: https://ch-hey.github.io/posts/AI-Definition/

[^4]: https://datapilots.tistory.com/26

[^5]: https://wikidocs.net/265451

[^6]: https://www.geeksforgeeks.org/machine-learning/features-and-labels-in-supervised-learning-a-practical-approach/

[^7]: https://toloka.ai/blog/machine-learning-labels-and-features/

[^8]: https://www.ibm.com/kr-ko/topics/data-labeling

[^9]: https://ijsra.net/sites/default/files/IJSRA-2023-0410.pdf

[^10]: http://arxiv.org/pdf/1805.05052v17.pdf

[^11]: https://arxiv.org/abs/2407.11778

[^12]: https://dl.acm.org/doi/10.1145/3532190

[^13]: https://pangguinland.tistory.com/262

[^14]: https://www.semanticscholar.org/paper/05674bee56e43f6b5631e322c6eb9f1d89ce3ccf

[^15]: https://www.semanticscholar.org/paper/6cd684f22072b37803ed6f1249d77642d378fe3c

[^16]: https://pmc.ncbi.nlm.nih.gov/articles/PMC6428006/

[^17]: https://www.bio-conferences.org/10.1051/bioconf/20249700133

[^18]: https://arxiv.org/pdf/2104.05314.pdf

[^19]: http://ijarcs.info/index.php/Ijarcs/article/download/6281/5103

[^20]: https://pmc.ncbi.nlm.nih.gov/articles/PMC8670494/

[^21]: https://arxiv.org/pdf/2008.11945.pdf

[^22]: https://pmc.ncbi.nlm.nih.gov/articles/PMC1904382/

[^23]: https://pmc.ncbi.nlm.nih.gov/articles/PMC3278390/

[^24]: http://ijarcs.info/index.php/Ijarcs/article/download/5799/4788

[^25]: https://www.ijfmr.com/papers/2024/4/25909.pdf

[^26]: https://arxiv.org/html/2410.09186v1

[^27]: https://arxiv.org/pdf/1712.08523.pdf

[^28]: https://arxiv.org/pdf/2310.20360.pdf

[^29]: https://www.mdpi.com/2073-431X/14/3/93

[^30]: https://arxiv.org/pdf/2310.11470.pdf

[^31]: https://www.preprints.org/manuscript/202007.0230/v1/download

[^32]: https://liz09045.tistory.com/94

[^33]: https://docs.ultralytics.com/ko/datasets/

[^34]: https://developers.google.com/machine-learning/glossary/googlecloud?hl=ko

[^35]: https://littlefoxdiary.tistory.com/52

[^36]: https://ieeexplore.ieee.org/document/10212616/

[^37]: https://www.mdpi.com/2076-3417/12/11/5547

[^38]: https://www.semanticscholar.org/paper/ea299efa21231736a50dc16026b34c996f9d423f

[^39]: https://link.springer.com/10.1007/s13042-024-02349-3

[^40]: https://www.nature.com/articles/s41598-024-51825-x

[^41]: https://melba-journal.org/2024:017

[^42]: https://link.springer.com/10.1007/s00500-019-03968-7

[^43]: https://arxiv.org/abs/2406.06039

[^44]: https://www.mdpi.com/2078-2489/14/10/532/pdf?version=1695911158

[^45]: https://doi.org/10.5591/978-1-57735-516-8/IJCAI11-270

[^46]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11452559/

[^47]: http://arxiv.org/pdf/2407.12793.pdf

[^48]: https://www.mdpi.com/1099-4300/26/11/992

[^49]: https://arxiv.org/pdf/2207.06224.pdf

[^50]: https://pmc.ncbi.nlm.nih.gov/articles/PMC11592953/

[^51]: https://dl.acm.org/doi/pdf/10.1145/3640543.3645157

[^52]: http://thesai.org/Downloads/Volume8No10/Paper_48-Accuracy_based_Feature_Ranking_Metric.pdf

[^53]: https://arxiv.org/pdf/1803.09010.pdf

[^54]: https://dev.mysql.com/doc/heatwave/en/mys-hwaml-iris-quickstart.html

[^55]: https://www.staffordglobal.org/blog/fundamental-data-science-concepts/

[^56]: https://dev.to/kammarianand/ml-intro-iris-dataset-4e13

[^57]: https://www.kdnuggets.com/2020/12/20-core-data-science-concepts-beginners.html

[^58]: https://developers.google.com/machine-learning/glossary

[^59]: https://www.geeksforgeeks.org/data-science/iris-dataset/

[^60]: https://www.geeksforgeeks.org/data-science/data-science-fundamentals/

[^61]: https://working-helen.tistory.com/75

[^62]: https://www.quarkml.com/2022/05/iris-dataset-classification-with-python.html

[^63]: https://codesignal.com/learn/courses/intro-to-unsupervised-machine-learning/lessons/exploring-and-visualizing-the-iris-dataset

[^64]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/ed066bda8f417605cee8a04e752a4ff8/89d271ec-2474-46c0-8a31-160825533dfb/87843d62.csv



# instance

인스턴스 (instance) ≒ 사례, 샘플 (example, case, sample) ≒ 레코드 (record) ≒ 데이터 포인트 (datapoint) ≒ 행 (row) : 개별 데이터
위의 나열한 용어들은 여러 데이터들에서 개별 데이터를 지칭할 때 쓰인다.

소프트웨어 요소의 구체적인 발생 또는 구현을 뜻하며, 클래스라는 설계도에 따라 생성된 객체를 가리킵니다. 객체 지향 프로그래밍에서 클래스의 인스턴스는 그 클래스의 속성들을 가진 독립적인 객체입니다.
예를 들어, "Car"라는 클래스가 있으면, 각각의 차 한 대가 그 클래스의 인스턴스가 됩니다. 인스턴스마다 고유한 속성값을 가질 수 있습니다(색상, 모델 등).
프로세스(실행 중인 프로그램)의 경우에도 한 프로그램의 실행 단위를 인스턴스라고 부릅니다.
요약하면, 일반 사전적 의미에서는 "특정한 예" 또는 "사례"를 의미하며, 컴퓨터 과학에서는 "클래스로부터 생성된 구체적 객체"를 뜻하는 용어입니다.

# Reference
https://pangguinland.tistory.com/262
