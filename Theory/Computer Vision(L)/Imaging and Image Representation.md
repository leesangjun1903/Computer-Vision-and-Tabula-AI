# Imaging and Image Representation
이 장의 주요 목적은 센서가 **2D 또는 3D 장면의 디지털 이미지를 생성하는 방법을 설명하는 것**입니다.
물리적 세계의 물체에서 반사되거나 침투하는 다양한 종류의 방사선은 서로 다른 이미징 장치에 의해 감지될 수 있습니다.  
2D 디지털 이미지는 물체에서 반사되거나 물체를 통해 전달되는 강도 샘플의 배열로, 이 이미지는 장면에 대한 결정을 내리기 위해 기계나 컴퓨터 프로그램에 의해 처리됩니다.  
종종 **2D 이미지는 3D 장면의 투영**을 나타내며, 이는 기계 비전과 이 책에서 가장 일반적으로 사용되는 표현입니다.  
이 장의 마지막에서는 3D 세계의 구조와 2D 이미지의 구조 사이의 몇 가지 관계에 대해 논의합니다.

## 2.1 Sensing Light
인간의 눈 수용체에 있는 화학 물질은 약 400나노미터(자외선)에서 800나노미터(빨간색) 범위의 파장을 가진 방사선(빛)에 민감합니다.  
뱀과 CCD 센서(아래 참조)는 800나노미터(적외선) 이상의 파장을 감지할 수 있습니다. 매우 짧은 길이의 X-선을 감지하는 장치와 긴 전파를 감지하는 장치가 있습니다.

<img width="749" alt="스크린샷 2025-04-16 오후 12 45 14" src="https://github.com/user-attachments/assets/f4c4b291-28f4-49d3-a794-40e0e2dbff0a" />

그림 2.1은 일반적인 사진의 간단한 모델을 보여줍니다:  
단일 소스(태양 또는 플래시 전구)에 의해 조명된 표면 요소는 필름의 화학 물질을 통해 카메라를 향해 방사선을 반사합니다. 이 상황에 대한 자세한 내용은 6장에서 다룹니다.  
**빛 범위의 파장은 물체 표면 근처에서 메커니즘을 생성하거나 반사하여 발생**합니다.

## 2.2 Imaging Devices
디지털 이미지를 생성하는 장치에는 다양한 종류가 있습니다. 이들은 감지되는 현상뿐만 아니라 전기 기계적 설계에서도 차이가 있습니다.  
이 장에서는 여러 가지 다른 센서에 대해 설명합니다.

### CCD Cameras
<img width="847" alt="스크린샷 2025-04-16 오후 12 47 30" src="https://github.com/user-attachments/assets/e362a764-2921-488c-b60e-41f22881f6e5" />

그림 2.2는 기계 비전 시스템에 가장 유연하고 일반적인 입력 장치인 전하 결합 장치(CCD) 기술을 사용하여 제작된 카메라를 보여줍니다.  
CCD 카메라는 작은 고체 셀이 빛에 반응하는 화학 필름 대신 이미지 평면을 제외한 가족 사진에 일반적으로 사용되는 35mm 필름 카메라와 매우 유사합니다.  
각 셀은 수신한 빛 에너지를 전하로 변환합니다. 모든 셀은 먼저 0으로 제거된 다음 셀에 떨어지는 빛 에너지에 대한 응답을 통합하기 시작합니다.  
감지 시간을 제어하기 위해 셔터가 필요할 수도 있고 필요하지 않을 수도 있습니다.  
**이미지 평면은 컴퓨터 입력 프로세스를 통해 행 단위로 읽을 수 있는 디지털 메모리 역할**을 합니다. 그림은 간단한 단색 카메라를 보여줍니다.

디지털 이미지에 500줄과 500줄의 바이트 크기 회색 값이 있는 경우, 25만 바이트의 메모리 배열을 얻을 수 있습니다. 

<img width="606" alt="스크린샷 2025-04-16 오후 12 51 11" src="https://github.com/user-attachments/assets/69f21afc-ab7a-4c70-98b4-6ee692881cf6" />

그림 2.3은 카메라 입력과 그래픽 출력을 모두 갖춘 전체 컴퓨터 시스템을 스케치한 것입니다. 이는 산업 비전 작업이나 의료 영상 작업을 위한 전형적인 시스템입니다.  
또한, 저렴한 카메라가 원격 회의 목적으로 이미지를 촬영할 수 있는 멀티미디어 컴퓨터에서도 일반적입니다.  
고속 이미지 저장소로서 프레임 버퍼의 역할은 여기서 중심적입니다:  
**카메라는 아날로그에서 디지털로 변환**된 후 **프레임 버퍼에 디지털 형태로 저장된 입력 이미지를 제공하여 사용자에게 표시**하고 다양한 컴퓨터 알고리즘에 의해 처리할 수 있도록 합니다.  
프레임 버퍼는 실제로 여러 이미지 또는 그 파생물을 저장할 수 있습니다.

디지털 이미지를 처리하는 컴퓨터 프로그램은 I [r, c] 또는 I[r][c]로 **픽셀 값**을 나타낼 수 있으며, 여기서 I는 배열 이름이고 r과 e는 각각 행과 열 번호입니다.  
이 책은 제시된 알고리즘에서 이러한 표기법을 사용합니다. 일부 카메라는 이진 이미지를 생성하도록 설정할 수 있습니다.  
픽셀은 어두운 대 밝은 것을 나타내는 0 또는 1이거나 그 반대입니다.  
간단한 알고리즘은 임계값 t 이하의 모든 픽셀을 0으로, 그 위의 모든 픽셀을 1로 변경하여 동일한 효과를 낼 수 있습니다.  
1장에서는 높은 혈류와 낮은 혈류를 대조하기 위해 자기 공명 이미지를 임계값으로 설정한 예를 제시했습니다.

### Image Formation
이미지 형성의 기하학적 구조는 3D 장면의 각 지점을 투영 중심 또는 렌즈 중심을 통해 이미지 평면에 투영하는 것으로 개념화할 수 있습니다. 

<img width="847" alt="스크린샷 2025-04-16 오후 12 47 30" src="https://github.com/user-attachments/assets/e362a764-2921-488c-b60e-41f22881f6e5" />

그림 2.2에는 두 개의 볼록한 표면을 가진 단일 렌즈가 표시되어 있지만 대부분의 실제 렌즈는 두 개 이상의 굴절 표면을 가진 복합 렌즈입니다.  
두 가지 매우 중요한 점이 있습니다. 첫째, **렌즈는 빛이 3D 지점에서 렌즈에 도달하는 전체 원뿔을 통해 이미지 지점에 도달**한다는 것입니다.  
그림 2.2의 꽃병 상단에서 세 개의 광선이 투사되는 모습이 보여지며, 이는 꽃병 상단에만 렌즈가 수집한 원뿔의 극단값을 결정합니다.  
다른 모든 장면 지점에도 유사한 원뿔이 존재합니다. 렌즈의 기하학적 불완전성, 다양한 색상의 빛의 굴절 및 기타 현상으로 인해 원뿔은 실제로 이미지 평면에 유한하거나 흐릿한 점인 혼란의 원을 초래합니다.  
둘째, **CCD 센서 배열은 무한한 점이 아닌 물리적으로 이산적인 단위로 구성**되므로 각 센서 셀은 3D 표면의 많은 인접 지점에서 수신한 광선을 통합합니다.  
이러한 두 가지 효과로 인해 이미지가 흐려지고 선명도와 감지할 수 있는 가장 작은 장면 세부 사항의 크기가 제한됩니다.

512*512 이미지라 했을 때 선형 배열을 사용하면 1000~5000픽셀을 한 줄로 사용할 수 있습니다. 

원형 배열은 시계나 속도계와 같은 아날로그 다이얼을 검사하는 데 유용합니다. 

### Video cameras
비디오 카메라는 인간 소비를 위한 이미지를 초당 30초의 속도로 기록하여 단일 이미지나 프레임에 표현된 공간적 특징 외에도 시간이 지남에 따라 물체의 움직임을 표현할 수 있게 합니다.  
인간의 원활한 인식을 위해 초당 60개의 하프 프레임이 사용됩니다. 이 하프 프레임은 모두 홀수 이미지 행으로, 모든 짝수 이미지 행이 번갈아 가며 이어집니다. 오디오 신호도 인코딩됩니다. 

**비디오 시퀀스의 프레임은 마커로 구분되며, 일부 이미지 압축 방식은 일반적으로 데이터 양을 줄이기 위해 사용**됩니다.

기계 비전을 위한 CCD 카메라 기술은 때때로 사람이 사용할 수 있도록 설계된 디스플레이 표준에 문제가 있었습니다.  
첫째, 사람에게 부드러운 화면을 제공하기 위해 필요한 비디오 시퀀스에서 홀수/짝수 프레임을 교차 배치하는 것은 기계 비전에 불필요한 복잡성을 초래합니다.  
둘째, 많은 CCD 배열에는 가로와 세로의 비율이 4:3인 픽셀이 있었는데, 이는 대부분의 디스플레이가 4:3 크기 비율을 가지고 있기 때문입니다.  
정사각형 픽셀과 단일 스케일 매개변수가 기계 비전에 도움이 될 것입니다. 

### The Human Eye
대략적으로 말하자면, 인간의 눈은 외부에 초점 거리 20mm 렌즈가 있는 구형 카메라로, 렌즈 반대편에 있는 망막에 이미지를 초점을 맞추고 구 표면 안쪽에 고정되어 있습니다(그림 2.5 참조).  
홍채는 동공의 크기를 조절하여 렌즈를 통과하는 빛의 양을 조절합니다. 

## 2.3 * Problems in Digital Images
몇 가지 문제가 감지 프로세스에 영향을 미치며, 그 중 가장 중요한 문제는 아래에 나열되어 있습니다.

이러한 문제의 조합으로 인한 전반적인 효과는 기하학적 구조와 강도 모두에서 약간의 왜곡이 있는 이미지입니다. 

### geometric distortion
이미징 프로세스에는 여러 가지 방식으로 **기하학적 왜곡**이 존재합니다.  
렌즈가 불완전하여 장면 표면 요소에서 수집되는 빛의 콩이 의도한 대로 정확히 구부러지지 않을 수 있습니다.  
배럴 왜곡(Barrel distortion)은 일반적으로 작은 초점 거리 렌즈에서 관찰되며, 그림 2.6의 오른쪽에 표시된 것처럼 장면 주변의 직선이 이미지의 중심에서 멀어지는 것처럼 보입니다.

<img width="847" alt="스크린샷 2025-04-16 오후 1 05 50" src="https://github.com/user-attachments/assets/829d18f2-34d9-4cbd-9320-2e89a8196fe6" />

### scattering
방사선 빔은 **통과하는 매질에 의해 구부러지거나 분산**될 수 있습니다. 항공 및 위성 이미지는 대기에 렌즈와 같은 특성을 부여하는 수증기 또는 온도 구배로 인해 이러한 영향에 특히 취약합니다.

### blooming
CCD 셀과 같은 개별 검출기는 서로 완벽하게 절연되어 있지 않기 때문에 **한 셀에서 수집된 전하가 인접 셀로 누출**될 수 있습니다.  
블루밍이라는 용어는 이미지 평면의 매우 밝은 영역에서 이러한 누출이 퍼져나가 그림 2.6(가운데)에 표시된 것처럼 이미지에 실제보다 더 큰 밝은 '꽃'이 피는 현상에서 비롯됩니다.

### CCD variations
제조의 불완전성으로 인해 **동일한 빛의 강도에 대한 서로 다른 셀의 반응에 차이**가 있을 수 있습니다.  
강도를 정확하게 해석하려면 균일한 조명으로 보정하여 각 픽셀에 대해 스케일 팩터 s[r,c]와 시프트 t[r,c]의 전체 배열을 결정해야 할 수 있으며, 이를 통해 강도를 Iz[r,e] = s[r,c]I[r,c] + tr,c)로 복원할 수 있습니다.  
극단적인 경우 CCD 배열에는 전혀 응답이 없는 일부 죽은 셀이 있을 수 있습니다. 이러한 결함은 검사를 통해 감지할 수 있습니다: 하나의 소프트웨어 해결책은 죽은 셀의 응답을 이웃 셀의 평균 응답으로 할당하는 것입니다.

### clipping or wrap-around
아날로그에서 디지털 변환에서는 **매우 높은 강도가 최대값으로 클리핑되거나 고차 비트가 손실되어 값이 인코딩으로 감싸져 낮은 강도로 변환**될 수 있습니다.  
회색 스케일 이미지에서는 랩어라운드의 결과가 밝은 영역으로 나타나며, 색상 이미지에서는 색상이 눈에 띄게 변할 수 있습니다.  
그림 2.6의 왼쪽 이미지는 랩어라운드를 보여줍니다: 밝은 선의 일부 교차점에서는 두 선의 픽셀보다 더 어두운 픽셀이 나타납니다.

### chromatic distortion
렌즈에 따라 **빛의 파장이 다르게 구부러집니다(엔스의 굴절률은 파장에 따라 달라집니다)**.  
따라서 동일한 장면 지점에서 다른 파장의 빛 에너지가 실제로 검출기에서 몇 픽셀 떨어진 곳을 이미징할 수 있습니다.  
예를 들어, 장면 주변에 있는 매우 선명한 흑백 경계의 이미지는 이미지의 여러 픽셀에 걸쳐 강도 변화의 램프를 형성할 수 있습니다.

### quantization effects
디지털화 과정은 장면의 이산 영역에서 강도 샘플을 수집하여 이를 이산 회색 값 집합 중 하나에 매핑하므로 혼합 및 반올림 문제 모두에 취약합니다. 이러한 문제는 다음 섹션에서 더 자세히 설명합니다.

## 2.4 Picture Functions and Digital Images
### Types of images
그림 함수는 이미지를 두 변수의 함수로 간주하는 것이 유익한 분석에 자주 사용되는 수학적 모델입니다. 그런 다음 이미지를 분석하는 데 기능적 분석을 사용할 수 있습니다. 

디지털 이미지는 2D 직사각형 배열의 이산 값일 뿐입니다. 이미지 공간과 강도 범위는 모두 이산 값으로 양자화되어 이미지를 2D 컴퓨터 메모리 구조에 저장할 수 있습니다.  
강도는 0에서 255까지의 값을 허용하는 8비트(1바이트) 숫자로 기록하는 것이 일반적입니다. 

컬러 이미지의 각 픽셀에는 3개의 이러한 값이 필요합니다. 일부 의료 응용 분야에서는 10비트 인코딩을 사용하여 1024개의 다른 강도 값을 허용합니다. 

디지털 이미지는 이 아날로그 이미지를 이산 위치에서 샘플링하고 해당 위치의 강도를 이산 값으로 표현함으로써 형성됩니다.  
모든 실제 이미지는 위치와 강도 모두에서 정밀도를 제한하는 물리적 과정의 영향을 받습니다.

#### 2 DEFINITION
이미지는 2D 이미지 F(x,y)로, 각 나선형 점(x,y)에 대해 무한 정밀도를 가지며, 각 나선형 점(x,y)에 대해 집중적으로 무한 정밀도를 가집니다.

#### 3 DEFINITION
디지털 이미지는 2D 이미지 I [r, c]는 각각의 강도 샘플이 제한된 정밀도로 표현된 이산 2D 배열로 표현됩니다.

두 개의 실제 공간 매개변수의 함수로서 이미지의 수학적 모델은 이미지를 설명하고 이미지에 대한 연산을 정의하는 데 매우 유용합니다.  

<img width="847" alt="스크린샷 2025-04-16 오후 1 24 20" src="https://github.com/user-attachments/assets/f5300190-3185-402e-8b26-b05ac6ecfcd9" />

그림 2.7(d)는 이미지의 픽셀이 이미지 평면의 여러 지점 [x, y]에서 촬영한 연속 이미지의 샘플임을 보여줍니다.  
W의 거리에 걸쳐 X 방향으로 샘플이 M개 있는 경우 픽셀 간의 X 간격 $Δx$는 W/M입니다.  
픽셀의 중심점과 강도 샘플이 포함된 배열 셀을 연결하는 공식은 오른쪽 그림에 나와 있습니다.

#### 4 DEFINITION
그림 함수는 그림의 수학적 표현 f(x,y)를 두 공간 변수 x와 y의 함수로 나타낸 것입니다.  
x와 y는 그림의 점을 정의하는 실수 값이며, f(x,y)는 일반적으로 (x,y) 지점에서 그림의 강도를 정의하는 실수 값이기도 합니다.

#### 5 DEFINITION
그레이 스케일 이미지는 픽셀당 하나의 집중 값을 갖는 단색 디지털 이미지 I [r,c]입니다.

#### 6 DEFINITION
다중 스펙트럼 이미지는 각 공간 점 또는 픽셀에 값 벡터가 있는 2D 이미지 M(x,y)입니다. 이미지가 실제로 컬러 이미지인 경우 벡터에는 3개의 요소가 있습니다.  
그레이 스케일 이미지는 픽셀당 하나의 집중적인 값을 갖는 단색 이중 이미지 I[r] 입니다.

#### 7 DEFINITION
이진 이미지는 모든 픽셀 값이 0 또는 1인 디지털 이미지입니다.

#### 8 DEFINITION
레이블이 지정된 이미지는 디지털 이미지 L[r, c]로, 피렐 값은 유한 알파벳의 기호입니다. 픽셀의 기호 값은 해당 픽셀에 대한 어떤 결정의 결과를 나타냅니다. 관련 개념으로는 주제 이미지와 의사 색상 이미지가 있습니다.

좌표계는 이미지의 개별 픽셀을 처리하거나 컴퓨터 프로그램에서 작동하거나 수학 공식으로 참조하거나 장치 좌표에 따라 상대적으로 처리하는 데 사용되어야 합니다.  
이 책과 다른 곳에서 사용되는 다양한 시스템은 그림 2.7에 나와 있습니다. 안타깝게도 컴퓨터 도구마다 다른 시스템을 사용하는 경우가 많으며 사용자는 이에 익숙해져야 합니다.  
다행히도 개념은 좌표계와 연결되어 있지 않습니다. 이 책에서는 일반적으로 수학 텍스트와 일치하는 데카르트 좌표계를 사용하여 개념을 논의하는 반면, 이미지 처리 알고리즘은 래스터 좌표계를 사용합니다.

### Image Quantization and Spatial Measurement
픽셀이 이미지 평면에서 장면의 소스 재료로 다시 투사되는 경우 해당 장면 요소의 크기는 센서의 명목 해상도(nominal resolution)입니다.  
예를 들어 10인치 정사각형 종이를 이미지화하여 500 x 500 디지털 이미지를 형성하면 센서의 명목 해상도는 0.02인치가 됩니다.  
이 개념은 장면의 깊이와 표면 방향에 따라 명목 해상도가 달라지기 때문에 장면의 깊이 변화가 많은 경우 의미가 없을 수 있습니다.  
이미징 센서의 시야는 장면을 얼마나 많이 볼 수 있는지를 측정하는 척도입니다.  
센서의 해상도는 공간 측정이나 미세한 특징 감지의 정밀도와 관련이 있습니다. (주의 깊게 사용하고 일부 모델 정보를 사용하면 500 x 500 픽셀 이미지를 사용하여 5000분의 1의 정확도로 측정할 수 있으며, 이를 서브픽셀 해상도라고 합니다.)

#### 9 DEFINITION
CCD 센서의 명목 해상도는 이미지 평면에서 단일 픽셀로 이미징하는 장면 요소의 크기입니다.

#### 10 DEFINITION
해상도라는 용어는 측정을 할 때 센서의 정밀도를 의미하지만, 공식적으로 다른 방식으로 정의됩니다.  
실제 용어로 정의하면 "이 스캐너의 해상도는 지상에서 1미터"와 같이 명목상 해상도일 수도 있고, 감지된 이미지에서 "해상도" 또는 구분할 수 있는 밀리미터당 선 쌍의 수일 수도 있습니다.  
완전히 다른 개념은 사용 가능한 픽셀 수, 즉 "카메라의 해상도는 640 x 480픽셀"입니다.  
이 나중의 정의는 시야를 몇 부분으로 나눌 수 있는지를 명시한다는 점에서 장점이 있으며, 이는 정밀한 측정을 수행하고 장면의 특정 영역을 덮을 수 있는 능력과 관련이 있습니다.  
측정의 정밀도가 명목상 해상도의 일부라면 이를 서브픽셀 해상도라고 합니다.

컴퓨터 비전을 사용하여 문제를 해결할 때는 구현자가 적절한 해상도를 사용해야 하며, 해상도가 너무 적으면 인식이 저하되거나 부정확한 측정값이 나오고, 너무 많으면 알고리즘이 느려져 메모리가 낭비됩니다.

#### 11 DEFINITION
센서의 시야각(FOV, field of view)은 예를 들어 10인치 x 10인치와 같이 감지할 수 있는 장면의 크기입니다.  
깊이에 따라 달라질 수 있으므로 55도 x 40도와 같이 각 시야각을 사용하는 것이 더 의미 있을 수 있습니다.

이미지의 픽셀은 점이 아닌 실제 세계의 면적을 측정하기 때문에 그 값은 종종 서로 다른 재료의 혼합에 의해 결정됩니다.

각 픽셀이 지구 10m x 10m 지점에서 샘플링되는 위성 이미지를 생각해 보세요. 위의 예에서 인치당 10개의 문자로 된 종이를 이미징하는 방법을 다시 생각해 보세요.  
많은 이미지 픽셀이 문자 경계와 겹쳐서 배경에서 더 높은 강도와 문자에서 더 낮은 강도의 혼합물을 받게 되며, 최종 결과는 배경과 문자 사이의 값으로 0 또는 1로 설정할 수 있습니다. 어떤 값이든 부분적으로 잘못되었습니다!

그림 2.9는 양자화 문제에 대한 세부 사항을 보여줍니다. 

<img width="871" alt="스크린샷 2025-04-17 오후 11 56 25" src="https://github.com/user-attachments/assets/657fc7d1-176c-472e-aad7-fa8e38e91fe8" />

왼쪽 상단의 CCD 요소는 4개의 타일에서 평균 강도인 강도 2 = (0 + 0 + 8)/4를 감지합니다.  
그러나 이미지가 t = 3으로 임계값을 설정하면 하나의 타일로 구성된 밝은 패턴이 이미지에서 사라지고 다른 세 가지 특징이 모두 하나의 영역으로 융합됩니다!  
카메라가 가로 및 세로 방향 모두에서 하나의 타일에 해당하는 양만큼 이동하면 그림 2.9(d)에 표시된 이미지가 결과를 얻습니다.  

카메라가 가로 및 세로 방향 모두에서 하나의 타일에 해당하는 양만큼 이동하면 그림 2.9(d)에 표시된 이미지가 결과를 얻습니다.  
4-tile 밝은 점의 모양은 (d)와 다른 방식으로 왜곡되어 있으며 장면의 두 밝은 선은 (b)의 일정한 회색 영역이 아닌 (d)의 "ramp"를 나타냅니다.  
또한 (d)는 세 개의 객체 영역을 보여주는 반면 (b)는 두 개를 보여줍니다. 그림 2.9는 거의 한 픽셀 크기에 가까운 장면 특징의 이미지가 불안정하다는 것을 보여줍니다.

그림 2.9는 공간 양자화 효과가 측정 정확도와 탐지 가능성에 어떻게 제한을 가하는지 보여줍니다. 

작은 특징들은 놓치거나 융합될 수 있으며, 더 큰 특징들이 감지되더라도 그 공간적 범위가 제대로 표현되지 않을 수 있습니다.  
이진 이미지가 임계값을 설정하여 생성될 때 혼합 픽셀의 반올림으로 인해 경계 배치에 0.5픽셀만큼의 오차가 발생할 것으로 예상할 수 있으며, 이는 두 경계에 걸쳐 수행된 측정에서 예상되는 한 픽셀의 오차를 의미합니다.

또한 이진 이미지에서 특정 특징을 감지할 것으로 예상되는 경우, 이미지 크기가 직경이 최소 두 픽셀인지 확인해야 합니다. 여기에는 객체 간의 간격이 포함됩니다.

팩스에서 이미지가 직경이 한 픽셀이지만 4개의 CCD 셀이 만나는 지점에서 정확히 중앙에 위치한 문장을 끝내는 "주기"를 고려해 봅시다:  
각 4개의 픽셀은 문자보다 더 많은 배경과 혼합되며 이진 이미지가 형성될 때 문자가 손실될 가능성이 높습니다!

#### 12 DEFINITION
혼합 픽셀은 현실 세계에서 다양한 재료 유형의 혼합 샘플을 집중적으로 나타내는 이미지 픽셀입니다.

이미지 환경은 반드시 봐야 하는 특징이 이미지에서 적절한 크기가 되도록 설계되어야 합니다.  
세계에서 이미지로 확장한 후 이미지에 유의미한 3D 문자가 남아 있지 않다고 가정하면 다음 여러 챕터의 2D 방법을 사용하여 이미지를 분석할 수 있습니다.

## 2.5 * Digital Image Formats
디지털 이미지의 사용은 통신, 데이터베이스에서 널리 퍼져 있으며, 다양한 하드웨어와 소프트웨어가 데이터를 공유할 수 있도록 표준 형식이 개발되었습니다. 

이 섹션에서는 몇 가지 가장 중요한 형식에 대해 간략하게 설명합니다. 원시 이미지는 이미지 픽셀을 행 단위로 인코딩하는 바이트 스트림일 수 있으며, 이를 래스터 순서(raster order)라고 합니다.  

이미지 유형, 크기, 소요 시간, 생성 방법과 같은 정보는 원시 이미지의 일부가 아닙니다.  
이러한 정보는 테이프 라벨이나 누군가의 연구 노트에 손으로 작성될 수 있습니다. (한 저자가 참여한 프로젝트에서는 실험에서 이미지를 비디오로 촬영하기 전에 바코드를 비디오로 촬영했습니다. 그런 다음 컴퓨터 프로그램이 바코드를 처리하여 실험 처리에 대한 전반적인 비이미지 정보를 얻습니다.)  
가장 최근에 개발된 표준 형식에는 데이터 레이블을 지정하고 디코딩하는 데 필요한 비이미지 정보가 포함된 헤더가 포함되어 있습니다.

여러 형식은 기업이 이미지 처리 또는 그래픽 도구를 만드는 데서 시작되었으며, 경우에 따라 공개 문서화 및 변환 소프트웨어가 제공되는 경우도 있지만 그렇지 않은 경우도 있습니다.  
아래에 제공된 세부 정보는 독자에게 컴퓨터 이미지를 처리하는 데 실질적인 정보를 제공해야 합니다.  
기술이 발전함에 따라 세부 사항이 빠르게 변화하고 있지만, 이 섹션에는 지속되어야 할 몇 가지 일반적인 개념이 포함되어 있습니다.

### Image File Header
이미지 처리 도구가 사용할 수 있도록 이미지 파일을 자체 설명하려면 파일 헤더가 필요합니다.  
헤더에는 이미지 크기, 유형, 생성 날짜 및 일종의 제목이 포함되어야 합니다. 픽셀 값을 해석하는 데 사용할 색상 표 또는 코딩 표도 포함될 수 있습니다.  
자주 사용할 수 없는 좋은 기능 중 하나는 이미지가 어떻게 생성되고 처리되었는지에 대한 메모가 포함된 히스토리 섹션입니다.

### Image Data
일부 형식은 이진 및 단색과 같은 제한된 유형의 이미지만 처리할 수 있지만, 오늘날 살아남은 형식은 더 많은 이미지 유형과 기능을 포함하도록 계속 성장하고 있습니다.  
픽셀 크기와 이미지 크기 제한은 일반적으로 파일 형식마다 다릅니다. 여러 형식은 일련의 프레임을 처리할 수 있습니다.  
멀티미디어 형식은 진화하고 있으며 텍스트, 그래픽, 음악 등과 함께 이미지 데이터를 포함합니다.

### Data Compression
많은 형식은 이미지 데이터를 압축하여 모든 픽셀 값이 직접 인코딩되지 않도록 합니다.  
이미지 압축은 필요한 품질과 방법에 따라 이미지 크기를 원본 크기의 30% 또는 3%로 줄일 수 있습니다.  
압축은 무손실 또는 손실일 수 있습니다. 무손실 압축을 사용하면 원본 이미지를 정확하게 복구할 수 있습니다.  
손실 압축을 사용하면 픽셀 표현을 정확하게 복구할 수 없습니다: 때로는 품질 손실이 인식되지만 항상 그런 것은 아닙니다.  
압축을 구현하려면 이미지 파일에 압축 방법과 매개변수에 대한 오버헤드 정보가 포함되어야 합니다.  
대부분의 디지털 이미지는 상징적인 디지털 정보와 매우 다릅니다.  
디지털 이미지 데이터의 몇 비트 손실 또는 변경은 사람이든 기계든 상관없이 소비자에게 거의 또는 전혀 반사되지 않습니다.

이미지 압축은 신호 처리부터 객체 인식까지 다양한 영역에 걸쳐 있는 흥미로운 분야입니다. 

#### 13 DEFINITION
이미지 압축 방법은 원본 이미지 표현의 모든 비트를 정확하게 복구하기 위해 압축 해제 방법이 존재하는 경우 손실이 없습니다. 그렇지 않으면 압축 방법이 손실됩니다.

### Commonly used Formats
이 책에 나오는 많은 이미지들은 여러 형식을 통해 전달되었습니다.  
일부 이미지는 동료로부터 수신되었거나 GIF, JPG 또는 PS 형식의 이미지 데이터베이스에서 검색되었습니다.  
일부 이미지는 사진에서 스캔되었으며 원래 디지털 형식은 GIF 또는 TIFF였습니다.  
간단한 이미지 처리는 이미지 도구 x를 사용하여 수행되었을 수 있으며, 더 복잡한 작업은 엉덩이 도구나 특수 C 또는 C++ 프로그램을 사용하여 수행되었을 수 있습니다.

#### run-coded binary images
런 코딩(Run-coding)은 이진 또는 레이블이 지정된 이미지를 위한 효율적인 코딩 방식입니다.  
이는 메모리 공간을 줄일 뿐만 아니라 세트 작업과 같은 이미지 작업 속도를 높일 수 있습니다.  
런 코딩은 이미지 행을 따라 픽셀이 많이 중복될 때 잘 작동합니다.  
이진 이미지를 가정하고, 각 이미지 행에 대해 0의 수와 전체 행에 걸쳐 교대로 1 의 수를 기록할 수 있습니다. 그림 2.11A는 예를 제공합니다.  

<img width="871" alt="스크린샷 2025-04-18 오전 12 22 09" src="https://github.com/user-attachments/assets/b012833d-ce4a-4d67-93ce-747acba51e4d" />

그림의 런 코드 B는 원래 행을 복원할 수 있는 1개의 런만 더 간결하게 인코딩한 것을 보여줍니다.  
런 코딩은 표준 파일 형식 내에서 압축하는 데 자주 사용됩니다.

#### PGM: Portable Grey Map
이미지 데이터를 저장하고 교환하는 가장 간단한 파일 형식 중 하나는 PBM 또는 "Portable Bit Map 형식군(PBM/PGM, PPM)"입니다.  
이미지 헤더와 픽셀 정보는 ASCII로 인코딩되어 있습니다. 최대 그레이 값이 192인 16개 열의 8행 이미지를 나타내는 이미지 파일은 그림 2.12에 나와 있습니다.  

<img width="871" alt="스크린샷 2025-04-18 오전 12 23 16" src="https://github.com/user-attachments/assets/5348e0da-3643-4899-a002-738026725080" />

또한 두 개의 그래픽 렌더링이 표시되어 있으며, 각각 원본 텍스트 입력에 적용된 이미지 변환 도구의 출력입니다.  
왼쪽 하단의 이미지는 픽셀을 복제하여 각각 64개 열의 32행으로 더 큰 이미지를 만들었고, 오른쪽 하단의 이미지는 손실 압축을 통해 처음에 JPG 형식으로 변환하여 만들었습니다.  
PGM 파일의 첫 번째 항목은 예제의 Magic Value인 "P2"로, 이미지 정보가 코딩되는 방식을 나타냅니다(예시의 ASCII 그레이 레벨).  
큰 사진의 경우 ASCII 픽셀 코딩이 아닌 바이너리를 사용할 수 있습니다(바이너리의 매직 넘버는 "P4"입니다).

#### GIF image file format
그래픽 교환 형식(GIF)은 CompuServe, Inc.에서 유래했으며 WWW 또는 현재 데이터베이스에서 수많은 이미지를 인코딩하는 데 사용되어 왔습니다.  
GIF 파일은 비교적 쉽게 작업할 수 있지만, 색상 인코딩에 8비트만 사용되기 때문에 고정밀 색상에는 사용할 수 없습니다. 

#### TIFF image file format
Aldus Corp.에서 유래한 TIFF 또는 TIF는 매우 일반적이고 매우 복잡합니다.  
모든 인기 플랫폼에서 사용되며 스캐너에서 자주 사용하는 형식입니다.  
태그 이미지 파일(Tag Image File Format) 형식은 픽셀당 1비트에서 24비트의 색상을 가진 여러 이미지를 지원합니다.

#### JPEG format for still photos
JPEG 코딩 방식은 스트림 지향적이며 코딩과 디코딩을 위한 실시간 하드웨어를 가능하게 합니다.

#### PostScript
BDF/PDL/EPS 형식은 인쇄 가능한 ASCII 문자를 사용하여 이미지 데이터를 저장하며, 종종 X11 그래픽 디스플레이 및 프린터와 함께 사용됩니다.  
"PDL"은 페이지 설명 언어이고 "EPS"는 일반적으로 Adobe에서 가져온 캡슐화된 후사본으로, 더 큰 문서에 삽입할 그래픽이나 이미지를 포함하는 데 사용됩니다. 

#### MPEG Format for Video
Motion Picture Expert Group. MPEG(MPG/MPEG-1/MPEG-2)는 비디오, 오디오, 텍스트, 그래픽을 위한 스트림 지향 인코딩 방식입니다.

#### Comparison of Formats
이 최종 TIF 파일은 컬러 코드에서 비트 수가 적었지만 CRT에서 질적으로 동일한 것으로 나타났습니다.  
JPEG 파일의 3분의 1 크기도 동일하게 표시되었습니다. 손실된 JPEG는 공간 측면에서 명확한 승자이지만, 이는 디코딩 복잡성으로 인해 실시간 성능을 위한 하드웨어가 필요할 수 있습니다.

## 2.6 Richness and Problems of Real Imagery
이미지 지점의 강도나 색상은 재료, 기하학, 조명에 따라 복잡한 방식으로 달라집니다.  
재료의 종류뿐만 아니라 센서, 광원 및 기타 물체에 대한 방향도 중요합니다.  
예를 들어 반짝이는 표면, 그림자, 상호 반사, 투명한 재료 등에는 특이점이 있습니다.  
많은 표면이나 물체를 인식할 때 색상은 모양이나 질감에 비해 거의 중요하지 않을 수 있으며, 이는 하나의 픽셀이 아닌 많은 픽셀에 따라 달라지는 특성입니다. 

햇빛이나 인공 빛은 표면을 가열하여 시간이 지남에 따라 다르게 복사하여 적외선이 증가하면 CCD 이미지를 밝게 하거나 비행기가 출발한 후 활주로에 그림자를 남기게 할 수 있습니다.  
제어된 단색 레이저 빛은 일부 이미징 작업에 큰 도움이 될 수 있지만 특정 표면에 완전히 흡수되거나 다른 표면에 대한 2차 반사에 의해 지배될 수도 있습니다.

자동화의 많은 응용 분야에서 엔지니어링을 통해 문제를 해결할 수 있습니다.  
예를 들어 적외선만 통과할 수 있도록 필터를 사용하면 어두운 빨간색 체리의 흠집을 더 선명하게 볼 수 있습니다.  
지속적인 조명 하에서 흐릿한 이미지를 유발하는 움직이는 물체는 매우 짧은 시간 동안 스트로브 빛으로 조명되어 매우 민감한 검출기로 형성된 이미지에 그대로 나타날 수 있습니다.  
구조화된 빛을 사용하면 표면 측정 및 검사가 훨씬 쉬워질 수 있습니다.  
예를 들어 터빈 블레이드는 빨간색과 녹색 빛의 정확한 교대 줄무늬로 조명할 수 있으므로 2D 이미지에서 줄무늬의 부드러움에 명백한 균열처럼 많은 표면 결함이 나타납니다. 

## 2.7 3D Structure from 2D Images
이미징 프로세스는 세계의 3D 구조와 이미지의 2D 구조 사이의 복잡한 관계를 기록합니다. 

그림 2.2에서 설명한 원근 투영 모델을 가정하고 그림 2.13을 참조하세요.  

<img width="871" alt="스크린샷 2025-04-18 오전 12 37 01" src="https://github.com/user-attachments/assets/14078801-8bd2-4841-88fc-e37ddddfd745" />

간섭(Interposition)은 아마도 가장 중요한 깊이 단서일 것입니다: 멀리 있는 물체의 가려진 부분에 더 가까운 물체: 가려진 부분을 인식하면 상대적인 깊이를 얻을 수 있습니다.  
벽의 영역 내에서 보이는 사람은 벽보다 센서에 더 가깝습니다. 

문의 먼 가장자리는 가까운 가장자리보다 짧아 보이는데, 이는 원근 투영의 단축 효과로 문의 3D 방향에 대한 정보를 전달합니다. 관련 단서는 질감 기울기(texture gradient)입니다.  
관찰자와의 거리와 표면 방향에 따라 표면의 질감이 달라집니다.  
멀리서 후퇴하는 표면을 원근감으로 볼 때 이미지 텍스처가 변하는 것을 텍스처 그래디언트라고 합니다.

## 2.8 Five Frames of Reference
3D 장면의 정성적 또는 정량적 분석을 위해서는 참조 프레임이 필요합니다. 

<img width="871" alt="스크린샷 2025-04-18 오전 12 41 18" src="https://github.com/user-attachments/assets/95a52984-3ce9-4e55-8463-a63b8485ceda" />

그림 2.14에는 다섯 가지 유형의 프레임이 설명되어 있으며, 실제로 장면에는 블록과 피라미드라는 두 개의 서로 다른 객체가 각각 고유한 참조 프레임을 가지고 있기 때문에 6개의 참조 프레임이 표시되어 있습니다.  
이 모든 좌표 프레임에서 좌표는 픽셀 배열의 정수 하위 집합인 이미지 좌표를 제외하고는 연속축을 따라 실수입니다.  
아래 논의의 예에서는 카메라가 야구 경기를 덮고 장면의 객체가 선수, 베이스, 공, 배트 등인 유사한 상황을 상상해 보세요.

### Pixel Coordinate Frame I
픽셀 배열에서 각 점에는 정수 픽셀 좌표가 있습니다.  
그림 2.14에서 피라미드 A의 끝 부분 이미지는 각각 ar와 ac가 정수 행과 열인 픽셀 a = [ar, ac]에 속합니다. 장면에 대한 많은 것은 픽셀 행과 열만으로 이미지를 분석하여 결정할 수 있습니다.  
예를 들어, 픽앤플레이스 로봇이나 기타 이송 메커니즘이 항상 카메라 앞에 블록(또는 세탁 세제 상자)을 대략적으로 전달했다면, 픽셀 행과 열의 행렬로 이미지만 사용하여 전면 표면의 표시를 검사할 수 있었습니다. 야구 경기 비유에서는 이미지만 사용하여 타자가 검은 배트를 사용하고 있는지 여부를 확인할 수 있었습니다.  
그러나 다른 정보 없이 이미지 I만 사용하면 실제로 어떤 물체가 3D에서 더 큰지 또는 물체가 충돌 코스에 있는지 여부를 판단할 수 없습니다.

### Object Coordinate Frame O
객체 좌표 프레임은 컴퓨터 그래픽과 컴퓨터 비전 모두에서 이상적인 객체를 모델링하는 데 사용됩니다.  
예를 들어, 그림 2.14는 블록 Ob와 피라미드 Op의 두 가지 객체 좌표 프레임을 보여줍니다.  
객체 좌표 프레임에 대한 3D 코너 포인트 B의 좌표는 [xb, 0, zb]입니다.  
이러한 좌표는 블록이 세계 또는 작업 공간 좌표 프레임 W에 대해 어떻게 배치되든 상관없이 동일하게 유지됩니다.  
객체 좌표 프레임은 객체를 검사하기 위해 필요하며, 예를 들어 특정 구멍이 다른 구멍이나 모서리에 대해 적절한 위치에 있는지 확인하는 데 필요합니다.

### Camera Coordinate Frame C
카메라 좌표 프레임 C′는 종종 "자기 중심적"(카메라 중심적) 뷰를 위해 필요합니다.  
예를 들어 물체가 센서 바로 앞에 있는지 여부, 멀어지는 것 등을 나타내기 위해 필요합니다.  
컴퓨터 그래픽 시스템을 사용하면 사용자는 보고 있는 3D 장면의 다양한 카메라 뷰를 선택할 수 있습니다. 

### Real Image Coordinate Frame F
카메라 좌표는 일반적으로 깊이 좌표 zc를 포함하여 세계 좌표(예: 인치 또는 mm)와 동일한 단위의 실수입니다.  
3D 점은 좌표 [xf, yf, f]에서 실제 이미지 평면으로 투사되며, 여기서 f는 초점 거리입니다.  
xf와 yf는 이미지 배열의 픽셀 하위 집합이 아니라 이미지 내 광축의 픽셀 크기와 픽셀 위치와 관련이 있습니다.  
그림 2.14에서 프레임 F에 상대적인 실제 이미지 점 a의 좌표는 모두 음수입니다.  
프레임 F는 픽셀 배열 I에서 디지털 이미지를 형성하기 위해 디지털화된 그림 함수를 "포함"합니다.

### World Coordinate Frame W
좌표 프레임 W는 3D에서 물체를 연결하는 데 필요합니다.  
예를 들어 주자가 베이스에서 멀리 떨어져 있는지 또는 주자와 2루수가 충돌할지 여부를 판단하는 데 필요합니다.  
로봇 셀이나 가상 환경에서는 액추에이터와 센서가 월드 좌표를 통해 통신하는 경우가 많으며, 예를 들어 이미지 센서는 로봇에게 볼트를 어디서 집어 들고 어느 구멍에 볼트를 삽입해야 하는지 알려줍니다.  

## 2.9 * Other Types of Sensors
### Microdensitometer
슬라이드나 필름은 단일 광선을 재료에 통과시켜 스캔할 수 있습니다.  
빛의 반대편에 있는 단일 센서는 해당 위치에서 재료의 광학 밀도를 기록합니다 [r, c].  
재료는 전체 직사각형 영역이 스캔될 때까지 기계적 단계에 의해 매우 정밀하게 움직입니다.  
단일 센서를 사용하면 CCD 배열에 비해 한 가지 장점이 있는데, 제조 차이로 인한 강도 값의 변동이 적어야 한다는 점입니다.  
또 다른 장점은 더 많은 행과 열을 얻을 수 있다는 것입니다. 

### Color and Multispectral Images
일부 컬러 CCD 카메라는 얇은 굴절 필름을 CCD 배열 바로 앞에 배치하여 제작됩니다.  
굴절 필름은 흰색 빛의 단일 빔을 CCD 배열의 인접한 4개의 셀에 떨어지는 4개의 빔으로 분산시킵니다.  
이 카메라가 생성하는 디지털 이미지는 4개의 서로 다른 굴절 파장 구성 요소 각각에 대해 하나씩 4개의 인터리브 컬러 이미지 세트로 생각할 수 있습니다. 스펙트럼 정보의 증가는 공간 해상도의 손실과 교환됩니다.

<img width="871" alt="스크린샷 2025-04-18 오전 12 52 18" src="https://github.com/user-attachments/assets/f099d2ac-4fe8-4a95-823e-e37ece9d3e27" />

그림 2.15는 5개의 강도 값의 벡터인 픽셀 [b1,2, b3, 04, bs]을 생성하는 5개의 다른 대역 스펙트럼을 보여줍니다.  
2D 이미지는 보어라이트를 움직이거나 스캐닝 미러를 사용하여 주어진 행의 열을 얻음으로써 만들어집니다. 

### X-ray
센서는 마이크로 밀도계와 거의 동일한 방식으로 방출기의 먼 쪽 이미지 지점에서 전송된 에너지를 기록합니다.  
감지된 이미지 지점에서 에너지가 낮다는 것은 방출기에서 투사된 전체 광선을 따라 물질 밀도가 축적된다는 것을 나타냅니다.  
2D X-선 필름이 신체를 통과하는 X-선에 노출되는 것을 상상하기 쉽습니다.  
3D 센싱은 CT 스캐너("고양이" 스캐너)를 사용하여 수행할 수 있으며, 이 스캐너는 신체를 통해 다양한 광선을 따라 X-선을 투사하여 수집한 데이터로부터 3D 볼륨의 밀도 값을 수학적으로 구성합니다. 

### Magnetic Resonance Imaging (MRI)
자기공명영상(MRI)은 일반적으로 인체의 일부인 재료의 3D 이미지를 생성합니다.  
생성된 데이터는 3D 배열 I[s, r, c]로, s는 신체를 통과하는 단면을 나타내고 r과 e는 이전과 같습니다.  
각 작은 부피 요소 또는 복셀은 직경이 약 2mm인 샘플을 나타내며, 그곳에서 측정된 강도는 재료의 화학적 성질과 관련이 있습니다. 자기공명혈관조영술(MRA)은 복셀에서 재료의 혈류 속도(혈류)와 관련된 강도를 생성합니다.

### Range Scanners and Range Images
3D 표면 요소에서 수신되는 방사선의 강도뿐만 아니라 깊이 또는 범위를 감지하는 장치가 있습니다.  
물체의 표면 모양 샘플은 범위 이미지에서 직접 사용할 수 있는 반면, 강도 이미지에서는 어렵고 오류가 발생하기 쉬운 분석을 통해서만 표면 모양을 도출할 수 있습니다.  

<img width="871" alt="스크린샷 2025-04-18 오전 12 58 48" src="https://github.com/user-attachments/assets/c59b1b6b-1858-4e74-b631-5d2ef10faa62" />

그림 2.17에 표시된 LIDAR 장치는 진폭 변조된 레이저 빔을 3D 표면의 한 지점으로 전송하고 반사된 신호를 다시 수신합니다.  
전송된 신호와 수신된 신호 사이의 위상 변화(지연)를 비교함으로써 LIDAR는 레이저 빔의 변조 주기를 기준으로 거리를 측정할 수 있습니다.  
이는 d + $\lamda$x/2 거리의 한 지점이 모호하기 때문에 한 주기로 덮인 거리에서만 작동하며, 여기서 1은 변조 주기(period of modulation)입니다.  
또한 LIDAR는 수신된 강도에 대한 강도를 비교하여 이 레이저 빛의 파장에 대한 표면 지점의 반사율도 추정합니다.  
따라서 LIDAR는 범위 이미지와 강도 이미지라는 두 개의 등록된 이미지를 생성합니다. LIDAR는 각 지점에 대한 위상 변화를 계산하는 데 필요한 체류 시간 때문에 CCD 카메라보다 느립니다. 

