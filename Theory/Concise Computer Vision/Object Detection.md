# Object Detection
## 10.1 Localization,Classification,andEvaluation
객체 후보는 직사각형 바운딩 박스 안에 위치해 있습니다.  
바운딩 박스는 관심 영역(region of interest, RoI)의 특별한 예입니다. 그림 10.1을 참조하십시오.  

<img width="730" alt="스크린샷 2025-04-26 오후 3 26 08" src="https://github.com/user-attachments/assets/6a67bc6b-596a-4a75-b8a4-1efc6f54950b" />

위치한 객체 후보는 감지된 객체 또는 거부된 후보에서 분류에 의해 매핑됩니다.  
분류 결과는 시스템 내에서 또는 시스템의 후속 성능 분석을 통해 평가되어야 합니다.  
히트 또는 감지라고도 하는 진양성(true-positive)은 올바르게 감지된 객체입니다.  
거짓 양성(false-positive), 즉 미스 또는 오탐지는 객체가 없는 경우를 감지하는 경우 발생합니다.  
거짓 음성(false-negative)은 객체를 놓치는 경우를 나타내며, 진음성(true-negative)은 객체가 아닌 영역이 객체가 아닌 영역으로 올바르게 식별되는 경우를 설명합니다.  

### 10.1.1 Descriptors, Classifiers, and Learning
분류는 주어진 값 n > 0에 대해 $R^n$의 부분집합인 구성된 쌍별 분리 클래스(pairwise-disjoint classes)의 멤버십에 의해 정의됩니다.  
즉, 클래스는 공간 $R^n$의 분할을 정의합니다. 분류를 수행할 때 시간 효율성은 중요한 문제입니다. 이 하위 섹션에서는 분류 알고리즘의 광범위한 영역에 대한 몇 가지 간단한 기본 설명만 제공합니다.

#### Descriptors
디스크립터 x = (x1, . . , xn)는 n차원 실수 공간 Rn의 한 점으로, 디스크립터 공간이라고 불립니다. 이는 측정되거나 계산된 속성 값을 주어진 순서대로 나타냅니다 (예: SIFT 디스크립터의 길이는 n = 128입니다).1  

분류 이론에서 설명자는 일반적으로 특징이라고도 합니다. 이미지 분석에서 일반적으로 사용되는 키포인트와 설명자를 결합한 이미지의 특징입니다. 따라서 혼동을 피하기 위해 '특징' 대신 '설명자'를 계속 사용합니다.

n = 2에 대한 설명은 그림 10.3을 참조하십시오.  

<img width="730" alt="스크린샷 2025-04-26 오후 3 31 36" src="https://github.com/user-attachments/assets/9e83a054-797f-4968-9de2-e782d564feed" />

예를 들어, 이 디스크립터 공간의 세그먼트 1에 대한 디스크립터 x1 = (621.605, 10940)는 속성 "perimeter"과 "Area"으로 정의됩니다.

#### Classifiers
분류기는 일반적으로 학습 세트(학습 세트)를 위해 이미 분류된 설명자의 주어진 집합 {x1, . . . . . xm}에 클래스 번호를 할당한 다음, 적용 중인 녹음된 이미지 또는 비디오 데이터에 대해 생성된 설명자에게 클래스 번호를 할당합니다:  
1. (일반) 분류기는 클래스 번호 1, 2, . . , k를 k > 1개의 클래스에 할당하고 0을 '분류되지 않음'에 할당합니다.
2. 이진 분류기는 특정 이벤트(예: '운전자가 눈을 감았다')가 발생했는지 여부가 관심 있는 경우에만 클래스 번호 -1과 +1을 할당하며, 출력 +1로 지정됩니다. 분류기는 기대에 미치지 못하면 약합니다(예: 무작위 추측보다 약간 더 나을 수 있음);

약하거나 강한 분류기는 일반적인 경우(즉, 다중 클래스) 분류기이거나 이진 분류기일 수 있으며, 단순히 "이진"이라고 해서 "약하다, weak"고 정의되는 것은 아닙니다.

#### Example 10.1 (Binary Classifier by Linear Separation)

<img width="730" alt="스크린샷 2025-04-26 오후 3 34 26" src="https://github.com/user-attachments/assets/31b913a5-e165-4126-a26b-b4eca3f0204b" />

#### Example 10.2 (Classification by Using a Binary Decision Tree)

<img width="730" alt="스크린샷 2025-04-26 오후 3 34 44" src="https://github.com/user-attachments/assets/2f8b3479-99d3-4d67-a7b4-ec114ff58557" />

강력한 분류기를 정의하기 위해서는 의사 결정 트리 집합(포레스트라고 함)이 필요합니다.

#### Observation 10.1
단일 결정 트리는 여러 영역(즉, 클래스)에서 디스크립터 공간을 분할하는 방법을 제공합니다. 선형 분리로 정의된 이진 분류기를 적용할 때는 여러 영역에서 디스크립터 공간을 유사하게 분할하기 위해 여러 가지를 결합해야 합니다.

#### Learning
학습은 일련의 설명자를 기반으로 분류기를 정의하거나 훈련하는 과정입니다.  
분류는 실제로 분류기를 적용하는 것입니다. 분류 과정에서 잘못된 행동(예: "추정된" 잘못된 분류)을 식별할 수도 있으며, 이는 다시 학습의 또 다른 단계로 이어질 수 있습니다.  
학습에 사용되는 설명자 집합은 사전 분류될 수도 있고 그렇지 않을 수도 있습니다.

#### Supervised Learning
지도 학습에서 우리는 전문 지식을 바탕으로 "수동적으로" 설명하기 위해 클래스 번호를 할당합니다. (예: "예, 이 이미지에서 운전자는 눈을 감았습니다.").  
그 결과, 우리는 Rn에서 최적화된 분리 매니폴드를 찾아 설명자 집합을 정의할 수 있습니다. 

#### Unsupervised Learning
비지도 학습에서는 디스크립터의 클래스 멤버십에 대한 사전 지식이 없습니다.  
디스크립터 공간에서의 분리(예시 10.1과 유사)를 목표로 할 때, 주어진 디스크립터 집합에 대해 클러스터링 알고리즘을 적용하여 Rn을 클래스로 분리하는 것을 식별할 수 있습니다. 

#### Combined Learning Approaches 
지도 학습과 비지도 학습에서 알려진 전략을 결합할 수 있는 경우도 있습니다. 예를 들어, 주어진 이미지 창, 즉 경계 상자가 보행자를 나타내는지 여부를 결정할 수 있으며, 이는 학습에서 지도된 부분을 정의합니다. 

<img width="730" alt="스크린샷 2025-04-26 오후 3 39 55" src="https://github.com/user-attachments/assets/acde9e21-8224-4f81-94ec-e32f7bc6e23a" />

경계 상자의 하위 창으로서 패치가 보행자의 것인지 여부를 결정할 수도 있습니다.  
예를 들어, 그림 10.6에서는 자전거 운전자의 머리도 보행자의 것으로 간주됩니다.  
경계 상자나 패치에 대한 설명자(예: 선택된 픽셀 위치에서 측정된 이미지 나이 강도)를 생성할 때, 각 개별 설명자에 대해 보행자의 특성인지 여부를 더 이상 수동으로 결정할 수 없습니다.  
예를 들어, 주어진 이미지 창 세트에 대해 우리는 이들이 모두 보행자의 일부라는 것을 알고 있으며, 분류기를 생성하기 위해 설계된 알고리즘은 어느 시점에서 해당 창의 특정 특징을 사용하여 추가 처리를 결정합니다.  
그러나 이 특정 특징은 보행자의 일부를 보여주는 창과 보행자의 일부를 보여주지 않는 창을 분리한다는 점에서 일반적이지 않을 수 있습니다.  
분류기를 생성하는 프로그램의 이러한 "내부" 메커니즘은 학습에서 비지도 부분을 정의합니다. 전체 작업은 분류기를 생성할 때 사용 가능한 감독과 비지도 데이터 분석을 결합하는 것입니다.

### 10.1.2 Performance of Object Detectors
#### Precision (PR) Versus Recall (RC) 
정밀도(Precision (PR))는 모든 탐지와 비교한 진양성의 비율입니다. 재현율(또는 민감도, Recall (RC))은 잠재적으로 가능한 모든 탐지와 비교한 진양성의 비율(즉, 모든 눈에 보이는 물체의 수)입니다. 공식적으로,

<img width="318" alt="스크린샷 2025-04-26 오후 3 43 45" src="https://github.com/user-attachments/assets/fa483c1c-0e99-4f49-989e-8a20d6fd311d" />

PR= 1은 거짓양성이 감지되지 않는다는 것을 의미합니다. RC= 1은 이미지의 모든 눈에 보이는 물체가 감지되고 거짓음성이 없다는 것을 의미합니다.

#### Miss Rate (MR) Versus False-Positives per Image (FPPI) 
미스율(Miss Rate (MR))은 이미지의 모든 객체와 비교한 거짓 음성의 비율입니다. 이미지 이미지당 거짓 양성(False-Positives per Image (FPPI))은 모든 감지된 객체와 비교한 거짓 양성의 비율입니다. 공식적으로,

<img width="325" alt="스크린샷 2025-04-26 오후 3 44 58" src="https://github.com/user-attachments/assets/6e336326-2d5b-4b72-87db-e509ac5efc18" />

#### True-Negative Rate (TNR) Versus Accuracy (AC) 
이 측정값들은 또한 tn이라는 숫자를 사용합니다. 참-부정 비율(또는 특이성, True-Negative Rate (TNR))은 "객체 없음" 영역의 모든 결정과 비교한 참-부정 비율입니다. 정확성(Accuracy (AC))은 모든 결정과 비교한 올바른 결정의 비율입니다. 공식적으로,

<img width="410" alt="스크린샷 2025-04-26 오후 3 46 16" src="https://github.com/user-attachments/assets/bf5865c5-1c26-4a63-b300-727b12fb1287" />

#### Detected? 
탐지된 객체가 진양성(True-positive)인지 여부를 어떻게 결정하나요? 이미지의 객체가 바운딩 박스를 통해 수동으로 로컬로 식별되었다고 가정하여 실제 사실로 간주합니다. 

<img width="161" alt="스크린샷 2025-04-26 오후 3 47 26" src="https://github.com/user-attachments/assets/bf98c77b-6ccb-4031-b5e5-e48a775bd76f" />

여기서 A는 이미지에서 영역의 면적을 나타내고(섹션 3.2.1 참조), D는 객체의 감지된 경계 상자, T는 일치하는 지상 진실 상자의 경계 상자의 면적을 나타냅니다. ao가 임계값 T보다 크면 T= 0.5라고 가정하면 감지된 객체는 진양성으로 간주됩니다.

### 10.1.3 Histogra mof Oriented Gradients
방향성 그래디언트 히스토그램(HoG)은 객체 후보에 대한 바운딩 박스의 디스크립터를 도출하는 일반적인 방법입니다.  
예를 들어, 예상 바운딩 박스 크기의 창이 이미지를 통과할 수 있으며, 스캔은 스테레오 비전(예: 주어진 거리에서 객체의 예상 크기) 또는 특징 검출기에 의해 제공된 결과에 의해 중지될 수 있습니다. 

#### Algorithm for Calculating the HoG Descriptor

<img width="729" alt="스크린샷 2025-04-26 오후 3 49 29" src="https://github.com/user-attachments/assets/15293fee-d369-4c21-8054-686045ee5378" />

1. Preprocessing. 강도 정규화(예: 섹션 2.1.1 참조)와 주어진 이미지 창 I.
2. Calculate an edge map. x 방향과 y 방향의 방향 도함수를 추정하고 각 픽셀의 기울기 크기와 기울기 각도를 도출하여 크기 맵 Im(그림 10.7, 오른쪽 참조)과 각도 맵 Ia.
3. Spatial binning. 다음 두 단계를 수행합니다: (a) 겹치지 않는 셀에서 픽셀 그룹화(예: 8 × 8); (b) 맵 Im과 Ia를 사용하여 크기 값을 방향 빈(예: 전체 180도 범위를 덮는 경우 각 셀에 대한 투표 벡터(예: 길이 9의 빈)를 얻기 위해 지도 Im과 Ia를 사용합니다. 적분 이미지는 이러한 합계를 시간 효율적으로 계산하는 데 사용할 수 있습니다.
4. 설명자를 생성하기 위해 투표 값을 정규화합니다. 두 단계를 수행합니다: (a) 셀 그룹화(예: 2 × 2)을 하나의 블록으로 정규화하고 각 블록에 대한 투표 벡터를 하나의 블록 벡터로 결합합니다(예: 4개의 셀 벡터를 길이 36의 블록 벡터로).
5. 모든 블록 벡터를 연속적으로 보강하여 최종 HoG 설명자를 생성합니다. 예를 들어, 블록이 4개의 셀로 구성되고 바운딩 박스 크기가 64 × 128인 경우, HoG 설명자는 3,780개의 요소를 가지며, 이 설명자 벡터를 하나의 설명자 행렬 B(예: 크기 420 × 9)로 재배열하는 것이 편리할 수 있습니다. 보행자 감지 또는 분류를 위한 훈련 또는 적용에 사용되는 바운딩 박스는 일반적으로 동일한 크기(예: 64 × 192, 숫자에 대한 아이디어를 제공하기 위해 32의 배수)로 정규화됩니다. 서로 다른 셀 크기(예: 8 × 8, 16 × 16, 32 × 32 × 32)를 채택하여 HoG 설명자 벡터를 생성할 수 있습니다.

<img width="729" alt="스크린샷 2025-04-26 오후 3 54 40" src="https://github.com/user-attachments/assets/52899073-f119-4b6c-9b7c-5652ee8e0a94" />

(Insert 10.1 (Origin of the Use of HoG Descriptors) Histograms of oriented gradients have been proposed in [N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In Proc. Computer Vision Pattern Recognition, 886–893, 2005]) 

### 10.1.4 Haar Wavelets and Haar Features
#### Haar Wavelets 
<img width="729" alt="스크린샷 2025-04-26 오후 3 57 36" src="https://github.com/user-attachments/assets/c1042c0a-9811-41e6-bcb3-78f32c7a1c0a" />

이러한 웨이블릿의 흰색 픽셀은 가중치 +1을 정의하고, 검은색 픽셀 가중치-1을 정의합니다.  
이러한 웨이블릿은 이미지에서 이러한 패턴과 "rough 밝기 유사성"을 테스트하는 데 사용됩니다.  
그림 10.9, 오른쪽을 참조하여 이미지에서 개별 Haar 웨이블릿을 위치시키는 방법을 설명합니다.  
예를 들어, 두 개의 흰색 영역 W1과 W2, 하나의 검은색 영역 B로 정의된 Haar 웨이블릿 ψ = [W1, W2, B]를 고려해 봅시다.  
예를 들어, 각 Haar 웨이블릿에는 왼쪽 하단 모서리와 같은 기준점이 있다고 가정해 봅시다.  
우리는 이 웨이블릿을 이미지 I로 변환하여 그 기준점을 픽셀 위치 p에 배치합니다. 현재 우리는 Haar 웨이블릿 $ψ_p$(이미지 I은 고정된 것으로 간주되며 표기법에 포함되지 않습니다)를 배치했는데, 여기서 W1은 직사각형 이미지 영역 W1(p) ⊂ ω을 차지하고, W2는 W2(p) ⊂ ω을 덮고, B는 이제 B(p) ⊂ ω 부분 집합입니다.

<img width="143" alt="스크린샷 2025-04-26 오후 3 59 57" src="https://github.com/user-attachments/assets/2236366e-027d-44b6-b437-948dfd6e0e86" />

W ⊂ ω 세트 내의 모든 이미지 값의 합입니다.

#### Value of a Haar Wavelet 
참조 픽셀 p에서 Haar 웨이블릿 ψ의 값은 다음과 같은 합으로 정의될 수 있습니다

<img width="229" alt="스크린샷 2025-04-26 오후 4 01 21" src="https://github.com/user-attachments/assets/fe806186-528b-4676-96cf-cfabdd347b27" />

그림 10.9, 오른쪽은 사람의 얼굴에서 이마, 눈, 눈 아래 부분의 이미지 강도가 왼쪽 얼굴의 (약간 회전된) 패턴에 해당함을 보여줍니다.  
사람의 눈, 코를 가로지르는 눈의 강도 분포는 왼쪽에서 오른쪽으로, 입꼬리의 강도 분포는 가운데 얼굴의 경우와 오른쪽 얼굴의 개별 눈 밝기 패턴에 해당합니다.  
이 모든 경우, 배치된 Haar 웨이블릿의 검은색 영역은 이미지의 어두운 영역 위에, 흰색 영역은 이미지의 밝은 영역 위에 위치합니다.  
따라서 우리는 SW1과 SW2에서 높은 값(즉, Gmax에 가까운 값)을 추가하고 SB에서 작은 값(즉, 0에 가까운 값)만 뺍니다.

Haar 웨이블릿 ψ에서 흰색 또는 검은색 영역의 크기는 값 V (ψp )를 "균형 맞추기" 위해 고려되어야 합니다.  
예를 들어, 두 개의 큰 흰색 영역이나 하나의 작은 검은색 영역에서 작은 검은색 영역의 가중치를 증가시켜 값이 "공정하게" 나눌 수 있는 가능성이 있습니다. 

<img width="351" alt="스크린샷 2025-04-26 오후 4 05 31" src="https://github.com/user-attachments/assets/8f226072-5eea-46e4-871f-4288584c20e1" />

2D 푸리에 변환과 유사하게, 2D Haar 변환은 서로 다른 파장과 방향의 2D 기본 함수 집합에 대해 주어진 행렬(우리의 맥락에서 이미지의)의 표현을 계산합니다.  
Haar 변환은 "실수 영역에 머무르며", 비실수 복소수를 사용하거나 생성하지 않습니다. 

Hadamard–Rademacher–Walsh 변환은 사용된 기본 함수와 관련하여 유사한 단순성을 가지며, 프랑스 수학자인 J. Hadamard (1865–1963), 독일 수학자 H. Rademacher (1892–1969), 미국 수학자 J.L. Walsh (1895–1973)의 이름을 따서 명명되었습니다.  
Haar 웨이블릿을 유도하기 위해, 이산 크레타 Haar 변환이나 이산 Hadamard–Rademacher–Walsh 변환에서 사용되는 2D 파형은 "+1" ("로 표현됨) 또는 "-1" ("로 표현됨) 값을 가진 단순화된 것으로 볼 수 있습니다.  
Haar는 일반적인 Haar 또는 직사각형 웨이블릿 또는 "Black"으로만 볼 수 있습니다. 이 논문은 오늘날 시간 효율적이고 정확한 얼굴 인식을 제공하기 위한 "랜드마크"를 정의합니다.

#### Value Calculation by Using Integral Images 
2.2.1장에서 논의한 바와 같이, 합 SW의 계산은 주어진 입력 이미지 I에 대해 먼저 적분 이미지 Iint를 생성함으로써 시간 효율적으로 수행될 수 있습니다. 

우리는 등방성 직사각형 영역에 대해서만 합을 지정했습니다. 이는 회전된 직사각형 영역으로 일반화할 수 있습니다. 선택된 회전 a-gle ϕ에 대해 x축에 대해 회전된 적분 이미지도 계산합니다. 예를 들어, ϕ = π/4의 경우, 적분 이미지 I ϕ의 계산은 간단히 다음과 같이 주어집니다

<img width="351" alt="스크린샷 2025-04-26 오후 4 14 07" src="https://github.com/user-attachments/assets/68b2ec45-9624-4e36-80c6-094397b7071d" />

여기서 (x, y)는 모서리 점 (1, 1) 및 (Ncols, Nrows)로 정의된 실제 등방성 직사각형의 임의의 점이 될 수 있으며, (i, j )는 이미지 캐리어 ω의 픽셀 위치입니다. 그림 10.10, 왼쪽을 참조하세요.

<img width="716" alt="스크린샷 2025-04-26 오후 4 14 48" src="https://github.com/user-attachments/assets/7b8328b1-fa09-4b02-a889-c7ddd9aa15e9" />

직사각형 영역 W가 x축에 대해 각도 ϕ로 회전하고 모서리 픽셀 위치 p와 q, 계산된 모서리 점 r과 s(그림 10.10, 오른쪽 참조)에 의해 정의되는 경우 다음과 같은 결과를 얻을 수 있습니다

<img width="315" alt="스크린샷 2025-04-26 오후 4 16 09" src="https://github.com/user-attachments/assets/8d8fa6b1-e9dd-4395-9184-dc102f64c7e9" />

#### Haar Features 
이제 배치된 Haar 웨이블릿 ψp의 값을 사용하여 이미지 I의 이 위치에 Haar 특징이 있는지 여부를 결정합니다. 결정하기 위해 패리티 ρ ∈ {-1, +1}과 임계값 θ를 사용합니다:

<img width="315" alt="스크린샷 2025-04-26 오후 4 16 45" src="https://github.com/user-attachments/assets/947c9023-1bc1-424b-b685-a17a152baed3" />

만약 F(ψp)=1이라면, 우리는 p에서 Haar 특징이 감지됩니다. Haar 웨이블릿의 검은색 영역이 어두운 픽셀(따라서 흰색 영역에서 밝은 픽셀)에 해당한다고 가정하면, 우리는 패리티 ρ = -1을 사용합니다.

### 10.1.5 Viola–Jones Technique
마스크(mask)는 두세 개의 하르 웨이블릿과 같은 소수의 하르 웨이블릿이 포함된 창입니다.  
그림 10.11은 이미지에서 동일한 크기의 서로 다른 세 개의 마스크(여기서는 정사각형이 아닌)가 동일한 위치에 배치되는 것을 보여줍니다.

<img width="718" alt="스크린샷 2025-04-26 오후 4 17 44" src="https://github.com/user-attachments/assets/76fc4dfd-d0d9-4b0e-9fd6-93dcf25cc77c" />

#### Haar Descriptors 
예를 들어 세 개의 Haar 웨이블릿을 포함하는 마스크 M = [ψ1, ψ2, ψ3]을 가정해 보겠습니다.  
이 마스크의 왼쪽 하단 모서리에 기준점이 있습니다. 우리는 이 기준점을 픽셀 위치 p로 이동시켜 이미지 I에서 마스크를 배치하고, 간단히 하기 위해 p도 관련된 세 개의 Haar 웨이블릿의 기준점으로 삼습니다.  
이제 이는 Haar 디스크립터를 정의합니다

<img width="376" alt="스크린샷 2025-04-26 오후 4 38 15" src="https://github.com/user-attachments/assets/8bafaaf3-4675-4d81-a2b0-1dc34bab0595" />

#### Weak Classifier
이제 임계값 τ > 0이 이진 값을 할당하는 데 최종적으로 사용됩니다

<img width="275" alt="스크린샷 2025-04-26 오후 4 38 28" src="https://github.com/user-attachments/assets/30804d9b-388a-4195-a46f-fef27f8d261b" />

예를 들어, 그림 10.11은 동일한 크기의 서로 다른 배치된 마스크 M1,p, M2,p, M3,p (같은 크기)가 동일한 기준 픽셀 p에서 사용되는 경우를 보여줍니다. 이는 동일한 창 Wp에 대해 세 가지 약한 분류기 h(M1,p), h(M2,p), h(M3,p)를 정의합니다.

#### Sliding Masks 
적용된 슬라이딩 검색(sliding search)의 목표는 적용된 마스크의 크기를 정의하는 슬라이딩 창에서 객체를 감지하는 것입니다. 두 가지 옵션이 있습니다: 
1. 먼저 이미지 피라미드(섹션 2.2.2 참조)를 생성한 다음 피라미드의 다양한 층에 일정한 크기의 마스크를 슬라이드합니다. 
2. 입력 이미지는 주어진 크기로만 사용하되 슬라이딩 마스크의 크기는 변경합니다. 
스케일 공간 기법과 달리 여기서는 두 번째 옵션을 선택해 보겠습니다.
이미지 크기를 일정하게 유지하고, 더 작거나 큰 물체를 감지하기 위해 다양한 크기의 마스크를 사용합니다. 그림 10.12를 참조하세요.

<img width="704" alt="스크린샷 2025-04-26 오후 4 40 43" src="https://github.com/user-attachments/assets/90ee74e8-fffd-4a6b-8339-125fa38bdb01" />

일반적으로 관심 있는 물체의 최소 크기와 최대 크기에 대한 추정치가 있습니다. 사용된 마스크 세트는 처음에 하나의 창 크기에 대해 정의됩니다.  
각 창 크기에 대해 입력 이미지를 완전히 스캔하고, 상하좌우로 이동하여 배치된 각 마스크에 대한 Haar 설명자를 계산합니다.  
따라서 약한 분류기는 강력한 분류기로 매핑되며, 이는 물체가 감지되었는지 여부를 알려줍니다. 그런 다음 슬라이딩 창으로 이동하여 다음 창 위치에 있는 모든 마스크를 다시 적용합니다.  
이미지의 왼쪽 하단 모서리에 도착하면 이미지의 왼쪽 상단 모서리에 있는 검색 창 크기를 수정하여 모든 창 크기가 관련성이 있는 것으로 간주될 때까지 다시 시작합니다.  
그림 10.13은 직사각형 슬라이딩 창 크기가 δz= 1.1배 증가한 것을 보여줍니다. 

<img width="704" alt="스크린샷 2025-04-26 오후 4 41 33" src="https://github.com/user-attachments/assets/c73a78e5-b7b3-4b8b-a7df-c4bbbb7a9d8f" />

슬라이딩 창의 너비와 높이가 최소 10% 증가하면 시간 효율성이 보장됩니다. 백분율이 클수록 감지의 정확도가 감소하므로 이는 고려해야 할 트레이드오프입니다.

#### Scan Orders 
슬라이딩 검색은 모든 눈에 보이는 객체를 감지하는 것을 목표로 합니다.  
이미지의 왼쪽 상단 모서리에서 오른쪽 하단 모서리로 위에서 제안한 바와 같이, x 방향과 y 방향으로 스케일링 팩터 δz를 사용하여 마스크가 정의된 최소 크기에서 정의된 최대 크기로 이동하도록 합니다.

#### The Viola–Jones Object Detection Technique
2001년에 제안된 이 기술(삽입 10.2 참조)은 주로 얼굴 감지에 의해 동기 부여되었지만, "일반적인 음영 패턴"으로 특징지어지는 다른 종류의 물체에도 적용할 수 있습니다. 이 기술은 다음과 같은 조합을 가지고 있습니다:   
1. w개의 약한 분류기 hj, 1 ≤ j ≤ w의 생성은 각각 w개의 주어진 마스크 중 하나로 정의됩니다. 각 마스크는 kj(예: 2~4) Haar 웨이블릿을 포함하며, 마스크는 크기가 체계적으로 다양하고 입력 이미지를 통해 슬라이드됩니다. 
2. 통계 부스팅 알고리즘을 사용하여 약한 분류기 h1, . . , hw를 하나의 강한 분류기 H(다음 섹션의 주제)로 조립합니다. 
3. 객체 감지를 위한 약한 분류기의 조립된 캐스케이드의 적용. 이 과정에는 여러 가지 매개변수가 포함됩니다.

먼저, "마이크로 스케일"에서는 사용된 각 Haar 웨이블릿이 등방성 또는 각도 ϕ만큼 회전할 때, 검정 또는 흰색 직사각형의 영향을 조정하는 가중치 ωi > 0, "검정-흰색"이 "어두운–밝음" 또는 "밝음–어두운" 중 하나와 일치해야 하는지를 정의하는 패리티 ρ ∈ {-1, +1}, 그리고 Haar 특징을 감지하기 위한 Haar 웨이블릿의 민감도를 정의하는 임계값 θ > 0이 있습니다.  
두 번째로, "macro 스케일"에서는 각 마스크 Mj , 1 ≤ j ≤ w에 대해 Haar 기술자 D(Mj,p)가 값 hj = +1을 정의하는 시점을 정의하는 임계값 τj가 있습니다. 이 경우 약한 분류기 hj는 물체(예: 얼굴)가 있을 수 있음을 나타냅니다.

#### Face Detection and Post-Processing
배치된 창에서 약한 분류기 h1, . . , hw의 w 결과는 얼굴 또는 얼굴 없는 상황을 감지하기 위해 훈련된 강한 분류기로 전달됩니다.  
얼굴이 감지되면 현재 사용 중인 창의 직사각형 상자와 그 위치를 식별합니다.  
분류 후에는 일반적으로 눈에 보이는 물체 주변에 서로 다른 위치와 크기의 객체가 여러 개 겹쳐서 감지됩니다.  
후처리는 각 객체에 대해 단일 감지를 다시 수행합니다. 후처리에 적용되는 방법은 일반적으로 휴리스틱(예: 감지된 직사각형 상자에 대해 일종의 평균을 취하는 것)입니다.  
이 최종 후처리 단계에 대한 설명은 그림 10.14를 참조하세요.

<img width="704" alt="스크린샷 2025-04-26 오후 4 46 29" src="https://github.com/user-attachments/assets/3658cbe9-4705-49eb-80bd-2ea88d8d0f14" />

## 10.2 AdaBoost

## 10.3 RandomDecisionForests

## 10.4 PedestrianDetection
